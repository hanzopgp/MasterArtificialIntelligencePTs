{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "iztRBK1MQ8GW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easypip\n",
        "\n",
        "from easypip import easyimport\n",
        "import functools\n",
        "import time\n",
        "\n",
        "easyimport(\"importlib_metadata==4.13.0\")\n",
        "OmegaConf = easyimport(\"omegaconf\").OmegaConf\n",
        "bbrl_gym = easyimport(\"bbrl_gym\")\n",
        "bbrl = easyimport(\"bbrl>=0.1.6\")\n",
        "\n",
        "import os\n",
        "import copy\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Normal\n",
        "\n",
        "import gym\n",
        "from bbrl.agents.agent import Agent\n",
        "from bbrl import get_arguments, get_class, instantiate_class\n",
        "from bbrl.workspace import Workspace\n",
        "from bbrl.agents import Agents, RemoteAgent, TemporalAgent\n",
        "from bbrl.agents.gymb import AutoResetGymAgent, NoAutoResetGymAgent\n",
        "from bbrl.visu.play import load_agent, play\n",
        "from bbrl.utils.replay_buffer import ReplayBuffer\n",
        "\n",
        "!git clone https://github.com/EmbersArc/gym-rocketlander\n",
        "!pip install -e ./gym-rocketlander"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pilwHVaQ8Km",
        "outputId": "004ac975-c155-4e75-8934-0258418aa083"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: easypip in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from easypip) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->easypip) (3.0.9)\n",
            "Cloning into 'gym-rocketlander'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (2/2), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "Unpacking objects: 100% (13/13), done.\n",
            "remote: Total 13 (delta 0), reused 0 (delta 0), pack-reused 11\u001b[K\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/gym-rocketlander\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from gym-rocketlander==0.0.1) (0.21.0)\n",
            "Requirement already satisfied: Box2D in /usr/local/lib/python3.7/dist-packages (from gym-rocketlander==0.0.1) (2.3.10)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym->gym-rocketlander==0.0.1) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym->gym-rocketlander==0.0.1) (4.13.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->gym-rocketlander==0.0.1) (1.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.1->gym->gym-rocketlander==0.0.1) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.1->gym->gym-rocketlander==0.0.1) (3.10.0)\n",
            "Installing collected packages: gym-rocketlander\n",
            "  Running setup.py develop for gym-rocketlander\n",
            "Successfully installed gym-rocketlander-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RocketLander"
      ],
      "metadata": {
        "id": "nYnAk4MvQ8Rb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RocketLanderWrapper(gym.Wrapper):\n",
        "    \"\"\"\n",
        "    Specific wrapper to shape the reward of the rocket lander environment\n",
        "    \"\"\"\n",
        "    def __init__(self, env):\n",
        "        super(RocketLanderWrapper, self).__init__(env)\n",
        "        self.env = env\n",
        "        self.prev_shaping = None\n",
        "        \n",
        "    def reset(self):\n",
        "        self.prev_shaping = None\n",
        "        return self.env.reset()\n",
        "\n",
        "    def step(self, action):\n",
        "        d = 1\n",
        "        next_state, reward, done, info = self.env.step(action)\n",
        "        # reward shaping\n",
        "        \"\"\"\n",
        "        shaping = -0.5 * (self.env.distance + self.env.speed + abs(self.env.angle) ** 2)\n",
        "        shaping += 0.1 * (\n",
        "            self.env.legs[0].ground_contact + self.env.legs[1].ground_contact\n",
        "        )\n",
        "        if self.prev_shaping is not None:\n",
        "            reward += shaping - self.prev_shaping\n",
        "        self.prev_shaping = shaping\n",
        "        \"\"\"\n",
        "        # print (\"distance\", self.env.distance)\n",
        "        \n",
        "        # shaping = 0.02\n",
        "        shaping = 0.008 * (1 - self.env.distance)\n",
        "        # shaping = 0.1 * (self.env.groundcontact - self.env.speed)\n",
        "        if (\n",
        "            self.env.legs[0].ground_contact > 0\n",
        "            and self.env.legs[1].ground_contact > 0\n",
        "            and self.env.speed < 0.1\n",
        "        ):\n",
        "            d = d * 2\n",
        "            print(\"landed !\")\n",
        "            print (\"speed\", self.env.speed)\n",
        "            shaping += 6.0 * d / self.env.speed\n",
        "        else:\n",
        "          d = 1\n",
        "        reward += shaping\n",
        "        return next_state, reward, done, info\n",
        "\n",
        "    def old_step(self, action):\n",
        "        next_state, reward, done, info = self.env.step(action)\n",
        "        # reward shaping\n",
        "        # shaping = -0.5 * (self.env.distance + self.env.speed + abs(self.env.angle) ** 2)\n",
        "        # shaping += 0.1 * (self.env.legs[0].ground_contact + self.env.legs[1].ground_contact)\n",
        "        shaping = 0\n",
        "        if self.prev_shaping is not None:\n",
        "            reward += shaping - self.prev_shaping\n",
        "        self.prev_shaping = shaping\n",
        "\n",
        "        return next_state, reward, done, info\n",
        "\n",
        "\n",
        "\n",
        "class FrameSkip(gym.Wrapper):\n",
        "    \"\"\"\n",
        "    Return only every ``skip``-th frame (frameskipping)\n",
        "    :param env: the environment\n",
        "    :param skip: number of ``skip``-th frame\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, env: gym.Env, skip: int = 1):\n",
        "        super().__init__(env)\n",
        "        self._skip = skip\n",
        "\n",
        "    def step(self, action: np.ndarray):\n",
        "        \"\"\"\n",
        "        Step the environment with the given action\n",
        "        Repeat action, sum reward, and max over last observations.\n",
        "        :param action: the action\n",
        "        :return: observation, reward, done, information\n",
        "        \"\"\"\n",
        "        total_reward = 0.0\n",
        "        done = None\n",
        "        for i in range(self._skip):\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        return obs, total_reward, done, info\n",
        "\n",
        "    def reset(self):\n",
        "        return self.env.reset()"
      ],
      "metadata": {
        "id": "pKR4bKBbQ8Wo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rocket_env = gym.make(\"RocketLander-v0\")\n",
        "rocket_env = RocketLanderWrapper(rocket_env)\n",
        "rocket_env = FrameSkip(rocket_env, skip=1)"
      ],
      "metadata": {
        "id": "KDJaBxo3Tf1V"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAC"
      ],
      "metadata": {
        "id": "WZZnmiEiQ8bi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LbIL63_tQ8gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROCKETLANDER / SAC"
      ],
      "metadata": {
        "id": "QUJjPFppYCje"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "noe7Eu6EYCqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FfNk_iNKYCsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E69CMfNwYCuf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}