{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommenders 3 -- Sequence Recommenders (45m) \n",
    "\n",
    "## Goals of this practical:\n",
    "\n",
    "- Understand the sequence recommendation framework (~5min)\n",
    "- Load/Format dataset (~5min)\n",
    "- Understand/train the prod2vec model (~10min)\n",
    "- Evaluate (~10min)\n",
    "- Visualize (~10min)\n",
    "- Fiddle (~5min)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\danse\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\users\\danse\\anaconda3\\lib\\site-packages (from gensim) (0.29.23)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\danse\\anaconda3\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\danse\\anaconda3\\lib\\site-packages (from gensim) (1.22.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\danse\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install gensim --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Recommenders:\n",
    "\n",
    "> What will you click next ?\n",
    "\n",
    "The sequence recommendation setting is a particular case of the implicit collaborative filtering setting. Given a sequence of items $i_0,i_1,...,i_n$ the goal is to predict the $i_{(n+1)},...$ items the user will consume. Playlist continuation is a neat use case of sequence recommenders. You've been listening to those songs, what can you listen to now ?\n",
    "\n",
    "\n",
    "This setting differs from the classical collaborative filtering because the history is the recent trace and not the full saved interactions. Also, it's possible to do sequence recommendation without any specific latent user profile. \n",
    "\n",
    "####Â Here we propose to explore this unpersonalized sequence recommandation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data used : [smallest movie-lens dataset](https://grouplens.org/datasets/movielens/)\n",
    "\n",
    "Here we'll use the same data as before but instead of seeing $(user,item,rating)$ triplets or a $(user,item)$ interaction , we'll see item sequences: $user: [item, item,...]$\n",
    "\n",
    "## Loading Data (same as before but in chronological order):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(100836, 4)\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"dataset/ratings.csv\")\n",
    "ratings = ratings.sort_values(\"timestamp\",ascending=True)\n",
    "print(ratings.iloc[0][\"timestamp\"] < ratings.iloc[-1][\"timestamp\"] ) # just checking \n",
    "print(ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610\n",
      "9724\n"
     ]
    }
   ],
   "source": [
    "print(len(set(ratings[\"userId\"])))\n",
    "print(len(set(ratings[\"movieId\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66719</th>\n",
       "      <td>429</td>\n",
       "      <td>595</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66716</th>\n",
       "      <td>429</td>\n",
       "      <td>588</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66717</th>\n",
       "      <td>429</td>\n",
       "      <td>590</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66718</th>\n",
       "      <td>429</td>\n",
       "      <td>592</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66712</th>\n",
       "      <td>429</td>\n",
       "      <td>432</td>\n",
       "      <td>3.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating  timestamp\n",
       "66719     429      595     5.0  828124615\n",
       "66716     429      588     5.0  828124615\n",
       "66717     429      590     5.0  828124615\n",
       "66718     429      592     5.0  828124615\n",
       "66712     429      432     3.0  828124615"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toy Story (1995)'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we also load titles and create an id2title dictionnary\n",
    "titleCSV = pd.read_csv(\"dataset/movies.csv\")\n",
    "id2title = titleCSV[[\"movieId\",\"title\"]].set_index(\"movieId\").to_dict()[\"title\"]\n",
    "id2title[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titleCSV.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Create sequence datasets:\n",
    "For this task, we need sequences of items as data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Todo): extract all movie sequences (in chronological order) from the dataset:\n",
    "\n",
    "\n",
    "In this dataset, each user has seen at least 20 movies.\n",
    "\n",
    "\n",
    "- We need to extract all movie rating sequences (there is one per user) from the dataset:\n",
    "\n",
    "`sequence_of_movies = [[movieid,...],[movieid,...],...]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_of_movies = [i[1].tolist() for i in ratings.groupby([\"userId\"])[\"movieId\"]]\n",
    "len(sequences_of_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Todo): Create a train/test dataset\n",
    "\n",
    "Here, we propose as task to predict the last 5 items of each sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq,test_seq = [],[]\n",
    "\n",
    "for seq in sequences_of_movies:\n",
    "    train_seq.append(seq[:-5])\n",
    "    test_seq.append(seq[-5:])\n",
    "    \n",
    "last_consumed_item = [seq[-1] for seq in train_seq] # We save the last consumed item for each list\n",
    "                                                    # We'll use it as a starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Todo): Create the list of the most popular movies\n",
    "\n",
    "- Here, popular is the number of times the movie appears in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 356,  318,  296, 2571,  593,  260,  480,  110,  589,    1])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter( [id for list_id in train_seq for id in list_id ])\n",
    "most_popular = np.array(counts.most_common())[:,0]\n",
    "num_items = len(most_popular)\n",
    "most_popular[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "#Most popular looks like this:\n",
    "[356,318,296,2571,593,260,480,110,589,...]\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec skip-gram <=> Prod2Vec\n",
    "\n",
    "\n",
    "### Word2Vec\n",
    "\n",
    "The MAIN idea of word2vec is to maximise the similarity (dot product) between the vectors for words which appear close together (in the context of each other) in text, and minimise the similarity of words that do not. \n",
    "\n",
    "This can be applied to products instead of words: it clusters similar products together.\n",
    "\n",
    "\n",
    "#### Paper Abstract:\n",
    "> In recent years online advertising has become increasingly ubiquitous and effective. Advertisements shown to visitors fund sites and apps that publish digital content, manage social networks, and operate e-mail services. Given such large variety of internet resources, determining an appropriate type of advertising for a given platform has become critical to financial success. Native advertisements, namely ads that are similar in look and feel to content, have had great success in news and social feeds. However, to date there has not been a winning formula for ads in e-mail clients. In this paper we describe a system that leverages user purchase history determined from e-mail receipts to deliver highly personalized product ads to Yahoo Mail users. We propose to use a novel neural language-based algorithm specifically tailored for delivering effective product recommendations, which was evaluated against baselines that included showing popular products and products predicted based on co-occurrence. We conducted rigorous offline testing using a large-scale product purchase data set, covering purchases of more than 29 million users from 172 e-commerce websites. Ads in the form of product recommendations were successfully tested on online traffic, where we observed a steady 9% lift in click-through rates over other ad formats in mail, as well as comparable lift in conversion rates. Following successful tests, the system was launched into production during the holiday season of 2014\n",
    "\n",
    "[Prod2Vec Model](https://arxiv.org/abs/1606.07154)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim has the best python implementation of word2vec's algorithms:\n",
    "\n",
    "We can just use these raw implementations. The only thing to do is to consider items as words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 15:21:55,337 : INFO : collecting all words and their counts\n",
      "2022-02-23 15:21:55,340 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-02-23 15:21:55,376 : INFO : collected 9616 word types from a corpus of 97786 raw words and 610 sentences\n",
      "2022-02-23 15:21:55,376 : INFO : Creating a fresh vocabulary\n",
      "2022-02-23 15:21:55,423 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 9616 unique words (100.0%% of original 9616, drops 0)', 'datetime': '2022-02-23T15:21:55.423200', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "2022-02-23 15:21:55,424 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 97786 word corpus (100.0%% of original 97786, drops 0)', 'datetime': '2022-02-23T15:21:55.424145', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "2022-02-23 15:21:55,494 : INFO : deleting the raw counts dictionary of 9616 items\n",
      "2022-02-23 15:21:55,495 : INFO : sample=0.001 downsamples 5 most-common words\n",
      "2022-02-23 15:21:55,495 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 97657.99863393226 word corpus (99.9%% of prior 97786)', 'datetime': '2022-02-23T15:21:55.495954', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "2022-02-23 15:21:55,583 : INFO : estimated required memory for 9616 words and 50 dimensions: 8654400 bytes\n",
      "2022-02-23 15:21:55,583 : INFO : resetting layer weights\n",
      "2022-02-23 15:21:55,600 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-02-23T15:21:55.600279', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'build_vocab'}\n",
      "2022-02-23 15:21:55,601 : INFO : Word2Vec lifecycle event {'msg': 'training model with 10 workers on 9616 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2022-02-23T15:21:55.601292', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'train'}\n",
      "2022-02-23 15:21:56,028 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:21:56,042 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:21:56,087 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:21:56,110 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:21:56,114 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:21:56,119 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:21:56,121 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:21:56,134 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:21:56,139 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:21:56,142 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:21:56,143 : INFO : EPOCH - 1 : training on 97786 raw words (97673 effective words) took 0.5s, 186267 effective words/s\n",
      "2022-02-23 15:21:56,603 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:21:56,622 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:21:56,651 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:21:56,657 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:21:56,664 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:21:56,678 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:21:56,679 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:21:56,682 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:21:56,682 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:21:56,719 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:21:56,720 : INFO : EPOCH - 2 : training on 97786 raw words (97662 effective words) took 0.6s, 171631 effective words/s\n",
      "2022-02-23 15:21:57,195 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:21:57,219 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:21:57,230 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:21:57,233 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:21:57,237 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:21:57,249 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:21:57,276 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:21:57,277 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:21:57,281 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:21:57,308 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:21:57,309 : INFO : EPOCH - 3 : training on 97786 raw words (97647 effective words) took 0.6s, 169930 effective words/s\n",
      "2022-02-23 15:21:57,819 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:21:57,835 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:21:57,835 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:21:57,851 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:21:57,851 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:21:57,851 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:21:57,851 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:21:57,867 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:21:57,873 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:21:57,895 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:21:57,896 : INFO : EPOCH - 4 : training on 97786 raw words (97674 effective words) took 0.6s, 168521 effective words/s\n",
      "2022-02-23 15:21:58,388 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:21:58,402 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:21:58,405 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:21:58,405 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:21:58,420 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:21:58,436 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:21:58,437 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:21:58,438 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:21:58,446 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:21:58,458 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:21:58,459 : INFO : EPOCH - 5 : training on 97786 raw words (97648 effective words) took 0.6s, 176143 effective words/s\n",
      "2022-02-23 15:21:58,877 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:21:58,894 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:21:58,895 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:21:58,901 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:21:58,995 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:21:59,006 : INFO : worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 15:21:59,008 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:21:59,043 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:21:59,049 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:21:59,082 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:21:59,083 : INFO : EPOCH - 6 : training on 97786 raw words (97654 effective words) took 0.6s, 158317 effective words/s\n",
      "2022-02-23 15:21:59,556 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:21:59,556 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:21:59,586 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:21:59,599 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:21:59,606 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:21:59,615 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:21:59,615 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:21:59,631 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:21:59,636 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:21:59,659 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:21:59,660 : INFO : EPOCH - 7 : training on 97786 raw words (97660 effective words) took 0.6s, 171719 effective words/s\n",
      "2022-02-23 15:22:00,123 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:00,170 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:00,175 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:00,189 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:00,197 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:00,200 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:00,202 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:00,210 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:00,216 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:00,229 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:00,230 : INFO : EPOCH - 8 : training on 97786 raw words (97652 effective words) took 0.6s, 173683 effective words/s\n",
      "2022-02-23 15:22:00,658 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:00,666 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:00,666 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:00,676 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:00,765 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:00,791 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:00,792 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:00,793 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:00,804 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:00,805 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:00,805 : INFO : EPOCH - 9 : training on 97786 raw words (97685 effective words) took 0.6s, 172534 effective words/s\n",
      "2022-02-23 15:22:01,272 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:01,290 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:01,317 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:01,323 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:01,325 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:01,336 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:01,344 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:01,345 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:01,349 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:01,367 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:01,367 : INFO : EPOCH - 10 : training on 97786 raw words (97650 effective words) took 0.6s, 175665 effective words/s\n",
      "2022-02-23 15:22:01,837 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:01,852 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:01,852 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:01,873 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:01,884 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:01,885 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:01,887 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:01,900 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:01,904 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:01,913 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:01,913 : INFO : EPOCH - 11 : training on 97786 raw words (97642 effective words) took 0.5s, 177875 effective words/s\n",
      "2022-02-23 15:22:02,335 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:02,335 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:02,348 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:02,353 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:02,430 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:02,450 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:02,453 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:02,461 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:02,472 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:02,479 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:02,479 : INFO : EPOCH - 12 : training on 97786 raw words (97642 effective words) took 0.6s, 176684 effective words/s\n",
      "2022-02-23 15:22:02,911 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:02,936 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:02,942 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:02,959 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:02,975 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:03,004 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:03,034 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:03,040 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:03,042 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:03,048 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:03,050 : INFO : EPOCH - 13 : training on 97786 raw words (97677 effective words) took 0.6s, 172987 effective words/s\n",
      "2022-02-23 15:22:03,458 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:03,493 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:03,497 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:03,501 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:03,564 : INFO : worker thread finished; awaiting finish of 5 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 15:22:03,584 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:03,597 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:03,599 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:03,622 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:03,625 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:03,625 : INFO : EPOCH - 14 : training on 97786 raw words (97634 effective words) took 0.6s, 171454 effective words/s\n",
      "2022-02-23 15:22:04,079 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:04,133 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:04,141 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:04,151 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:04,170 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:04,176 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:04,178 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:04,182 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:04,186 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:04,191 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:04,191 : INFO : EPOCH - 15 : training on 97786 raw words (97667 effective words) took 0.6s, 174257 effective words/s\n",
      "2022-02-23 15:22:04,640 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:04,642 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:04,646 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:04,655 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:04,757 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:04,761 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:04,762 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:04,766 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:04,783 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:04,799 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:04,800 : INFO : EPOCH - 16 : training on 97786 raw words (97675 effective words) took 0.6s, 161598 effective words/s\n",
      "2022-02-23 15:22:05,286 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:05,301 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:05,301 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:05,310 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:05,322 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:05,329 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:05,340 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:05,346 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:05,349 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:05,353 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:05,354 : INFO : EPOCH - 17 : training on 97786 raw words (97672 effective words) took 0.5s, 178477 effective words/s\n",
      "2022-02-23 15:22:05,770 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:05,786 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:05,787 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:05,791 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:05,891 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:05,898 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:05,900 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:05,902 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:05,904 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:05,925 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:05,925 : INFO : EPOCH - 18 : training on 97786 raw words (97662 effective words) took 0.6s, 173050 effective words/s\n",
      "2022-02-23 15:22:06,338 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:06,338 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:06,354 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:06,362 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:06,445 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:06,454 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:06,469 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:06,481 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:06,488 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:06,498 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:06,499 : INFO : EPOCH - 19 : training on 97786 raw words (97662 effective words) took 0.6s, 173933 effective words/s\n",
      "2022-02-23 15:22:06,920 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:06,920 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:06,920 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:06,936 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:07,010 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:07,033 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:07,041 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:07,042 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:07,045 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:07,055 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:07,056 : INFO : EPOCH - 20 : training on 97786 raw words (97665 effective words) took 0.6s, 177215 effective words/s\n",
      "2022-02-23 15:22:07,517 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:07,548 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:07,557 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:07,567 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:07,577 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:07,581 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:07,585 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:07,585 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:07,591 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:07,608 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:07,608 : INFO : EPOCH - 21 : training on 97786 raw words (97650 effective words) took 0.5s, 178679 effective words/s\n",
      "2022-02-23 15:22:08,027 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:08,027 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:08,044 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:08,051 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 15:22:08,134 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:08,138 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:08,156 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:08,164 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:08,167 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:08,176 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:08,176 : INFO : EPOCH - 22 : training on 97786 raw words (97643 effective words) took 0.6s, 173835 effective words/s\n",
      "2022-02-23 15:22:08,618 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:08,657 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:08,676 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:08,686 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:08,690 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:08,694 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:08,701 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:08,705 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:08,716 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:08,722 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:08,722 : INFO : EPOCH - 23 : training on 97786 raw words (97655 effective words) took 0.5s, 180848 effective words/s\n",
      "2022-02-23 15:22:09,135 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:09,141 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:09,149 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:09,152 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:09,226 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:09,245 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:09,251 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:09,259 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:09,265 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:09,283 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:09,284 : INFO : EPOCH - 24 : training on 97786 raw words (97653 effective words) took 0.6s, 175814 effective words/s\n",
      "2022-02-23 15:22:09,686 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:09,702 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:09,706 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:09,712 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:09,791 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:09,810 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:09,820 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:09,825 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:09,828 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:09,843 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:09,844 : INFO : EPOCH - 25 : training on 97786 raw words (97644 effective words) took 0.5s, 177920 effective words/s\n",
      "2022-02-23 15:22:10,284 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:10,331 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:10,341 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:10,342 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:10,355 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:10,358 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:10,360 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:10,380 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:10,383 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:10,388 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:10,389 : INFO : EPOCH - 26 : training on 97786 raw words (97643 effective words) took 0.5s, 181291 effective words/s\n",
      "2022-02-23 15:22:10,834 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:10,850 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:10,869 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:10,893 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:10,904 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:10,905 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:10,909 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:10,910 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:10,920 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:10,942 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:10,942 : INFO : EPOCH - 27 : training on 97786 raw words (97676 effective words) took 0.5s, 178282 effective words/s\n",
      "2022-02-23 15:22:11,382 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:11,416 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:11,432 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:11,451 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:11,452 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:11,453 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:11,456 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:11,468 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:11,483 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:11,487 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:11,488 : INFO : EPOCH - 28 : training on 97786 raw words (97693 effective words) took 0.5s, 180730 effective words/s\n",
      "2022-02-23 15:22:11,954 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:11,965 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:11,980 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:11,982 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:11,989 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:12,012 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:12,014 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:12,021 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:12,024 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:12,038 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:12,038 : INFO : EPOCH - 29 : training on 97786 raw words (97663 effective words) took 0.5s, 178953 effective words/s\n",
      "2022-02-23 15:22:12,467 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:12,475 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:12,478 : INFO : worker thread finished; awaiting finish of 7 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 15:22:12,489 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:12,557 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:12,574 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:12,581 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:12,591 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:12,597 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:12,599 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:12,600 : INFO : EPOCH - 30 : training on 97786 raw words (97646 effective words) took 0.6s, 175719 effective words/s\n",
      "2022-02-23 15:22:13,020 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:13,060 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:13,083 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:13,084 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:13,104 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:13,118 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:13,121 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:13,128 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:13,137 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:13,160 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:13,161 : INFO : EPOCH - 31 : training on 97786 raw words (97657 effective words) took 0.6s, 175395 effective words/s\n",
      "2022-02-23 15:22:13,649 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:13,677 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:13,688 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:13,699 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:13,703 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:13,705 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:13,709 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:13,724 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:13,734 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:13,762 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:13,762 : INFO : EPOCH - 32 : training on 97786 raw words (97669 effective words) took 0.6s, 164134 effective words/s\n",
      "2022-02-23 15:22:14,229 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:14,259 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:14,264 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:14,266 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:14,277 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:14,278 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:14,278 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:14,284 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:14,304 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:14,305 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:14,306 : INFO : EPOCH - 33 : training on 97786 raw words (97667 effective words) took 0.5s, 181420 effective words/s\n",
      "2022-02-23 15:22:14,718 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:14,718 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:14,718 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:14,744 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:14,807 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:14,820 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:14,835 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:14,843 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:14,851 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:14,853 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:14,853 : INFO : EPOCH - 34 : training on 97786 raw words (97650 effective words) took 0.5s, 180113 effective words/s\n",
      "2022-02-23 15:22:15,328 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:15,342 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:15,343 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:15,353 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:15,367 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:15,379 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:15,380 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:15,384 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:15,384 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:15,405 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:15,406 : INFO : EPOCH - 35 : training on 97786 raw words (97663 effective words) took 0.5s, 178323 effective words/s\n",
      "2022-02-23 15:22:15,817 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:15,817 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:15,831 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:15,836 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:15,923 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:15,932 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:15,944 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:15,949 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:15,952 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:15,960 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:15,960 : INFO : EPOCH - 36 : training on 97786 raw words (97654 effective words) took 0.5s, 178094 effective words/s\n",
      "2022-02-23 15:22:16,426 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:16,480 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:16,484 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:16,486 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:16,489 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:16,492 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:16,493 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:16,497 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:16,500 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:16,511 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:16,511 : INFO : EPOCH - 37 : training on 97786 raw words (97672 effective words) took 0.5s, 178806 effective words/s\n",
      "2022-02-23 15:22:16,980 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:17,023 : INFO : worker thread finished; awaiting finish of 8 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 15:22:17,035 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:17,059 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:17,116 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:17,118 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:17,123 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:17,128 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:17,131 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:17,140 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:17,140 : INFO : EPOCH - 38 : training on 97786 raw words (97657 effective words) took 0.6s, 156583 effective words/s\n",
      "2022-02-23 15:22:17,650 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:17,664 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:17,691 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:17,692 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:17,695 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:17,704 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:17,708 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:17,709 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:17,718 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:17,723 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:17,724 : INFO : EPOCH - 39 : training on 97786 raw words (97657 effective words) took 0.6s, 168710 effective words/s\n",
      "2022-02-23 15:22:18,146 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:18,168 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:18,169 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:18,188 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:18,254 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:18,271 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:18,285 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:18,307 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:18,313 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:18,316 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:18,317 : INFO : EPOCH - 40 : training on 97786 raw words (97657 effective words) took 0.6s, 170081 effective words/s\n",
      "2022-02-23 15:22:18,715 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:18,746 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:18,746 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:18,746 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:18,851 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:18,861 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:18,866 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:18,871 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:18,886 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:18,892 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:18,893 : INFO : EPOCH - 41 : training on 97786 raw words (97646 effective words) took 0.6s, 171270 effective words/s\n",
      "2022-02-23 15:22:19,360 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:19,400 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:19,410 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:19,422 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:19,436 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:19,443 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:19,447 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:19,448 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:19,456 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:19,470 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:19,471 : INFO : EPOCH - 42 : training on 97786 raw words (97654 effective words) took 0.6s, 171159 effective words/s\n",
      "2022-02-23 15:22:19,958 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:19,965 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:19,966 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:19,987 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:19,997 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:20,006 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:20,018 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:20,024 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:20,026 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:20,047 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:20,048 : INFO : EPOCH - 43 : training on 97786 raw words (97658 effective words) took 0.6s, 171514 effective words/s\n",
      "2022-02-23 15:22:20,462 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:20,475 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:20,475 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:20,490 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:20,552 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:20,601 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:20,602 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:20,609 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:20,625 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:20,635 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:20,636 : INFO : EPOCH - 44 : training on 97786 raw words (97656 effective words) took 0.6s, 167869 effective words/s\n",
      "2022-02-23 15:22:21,108 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:21,138 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:21,153 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:21,157 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:21,162 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:21,163 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:21,167 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:21,172 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:21,175 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:21,196 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:21,197 : INFO : EPOCH - 45 : training on 97786 raw words (97673 effective words) took 0.6s, 176280 effective words/s\n",
      "2022-02-23 15:22:21,658 : INFO : worker thread finished; awaiting finish of 9 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 15:22:21,684 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:21,697 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:21,722 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:21,723 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:21,726 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:21,733 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:21,736 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:21,738 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:21,748 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:21,748 : INFO : EPOCH - 46 : training on 97786 raw words (97640 effective words) took 0.5s, 179203 effective words/s\n",
      "2022-02-23 15:22:22,225 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:22,256 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:22,256 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:22,261 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:22,265 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:22,271 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:22,279 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:22,285 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:22,286 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:22,303 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:22,304 : INFO : EPOCH - 47 : training on 97786 raw words (97664 effective words) took 0.5s, 177935 effective words/s\n",
      "2022-02-23 15:22:22,759 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:22,787 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:22,804 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:22,821 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:22,824 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:22,843 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:22,846 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:22,853 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:22,855 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:22,856 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:22,857 : INFO : EPOCH - 48 : training on 97786 raw words (97660 effective words) took 0.5s, 178522 effective words/s\n",
      "2022-02-23 15:22:23,323 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:23,323 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:23,347 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:23,375 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:23,381 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:23,389 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:23,390 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:23,397 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:23,405 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:23,419 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:23,419 : INFO : EPOCH - 49 : training on 97786 raw words (97668 effective words) took 0.6s, 175774 effective words/s\n",
      "2022-02-23 15:22:23,843 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 15:22:23,850 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 15:22:23,853 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 15:22:23,861 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 15:22:23,932 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 15:22:23,965 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 15:22:23,983 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 15:22:23,984 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 15:22:23,987 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 15:22:23,994 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 15:22:23,995 : INFO : EPOCH - 50 : training on 97786 raw words (97659 effective words) took 0.6s, 171537 effective words/s\n",
      "2022-02-23 15:22:23,996 : INFO : Word2Vec lifecycle event {'msg': 'training on 4889300 raw words (4882950 effective words) took 28.4s, 171971 effective words/s', 'datetime': '2022-02-23T15:22:23.996587', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'train'}\n",
      "2022-02-23 15:22:23,997 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=9616, vector_size=50, alpha=0.025)', 'datetime': '2022-02-23T15:22:23.997585', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "train_seq_str = [list(map(str,seq)) for seq in train_seq] # we just say that our items id's are strings..\n",
    "    \n",
    "\n",
    "# the following configuration is the default configuration\n",
    "w2v = gensim.models.word2vec.Word2Vec(sentences=train_seq_str,\n",
    "                                vector_size=50, window=10,               ### here we train a cbow model \n",
    "                                min_count=0,                      \n",
    "                                sample=0.001, ns_exponent=0.75, workers=10,\n",
    "                                sg=1, hs=0, negative=15,          ### set sg to 1 to train a sg model => Prod2Vec\n",
    "                                cbow_mean=0,\n",
    "                                epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.27825177  0.05073303 -0.30350322  0.49897218 -0.43219474 -0.3556385\n",
      "  0.28310165  0.5208147  -0.39110366 -0.52834207 -0.15466134 -0.75271803\n",
      " -0.26825935  0.42898378 -0.01368484  0.39651856  0.4827199  -0.19683474\n",
      " -0.3760517  -0.7158907   0.1067467   0.02812896  0.962306   -0.4048893\n",
      "  0.18964584  0.17758189 -0.6085433   0.70119095 -0.13911028 -0.12139854\n",
      "  0.09713151 -0.03532421  0.22046252  0.32695717 -0.23656611  0.05698903\n",
      " -0.13464738  0.4866654   0.07209812 -0.51379585  0.37555242 -0.17435944\n",
      " -0.38007522  0.5301092   0.05459659  0.22382212 -0.08039364 -0.28165382\n",
      "  0.49696276  0.27662408]\n",
      "356\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(w2v.wv.vectors[0])              # The vector of index 0\n",
    "print(w2v.wv.index_to_key[0])           # codes for the movieId 356  : index2word -> index_to_key\n",
    "print(w2v.wv.key_to_index[\"356\"] )      # Inverse mapping :  vocab -> key_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting similar items:\n",
    "\n",
    "The heart of the algorithm is in the similar item search. As in word2vec, we simply use cosine distance between items to find \"similar items\"\n",
    "\n",
    "### We can search by id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26142, 66915, 27829, 26195, 228]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_similar_ids(w2vmodel,iid,num=5):\n",
    "    \n",
    "    if str(iid) in w2vmodel.wv.key_to_index:\n",
    "        return [int(iid) for iid,_ in w2vmodel.wv.most_similar(str(iid),topn=num)] \n",
    "    else:\n",
    "        return []\n",
    "\n",
    "get_similar_ids(w2v,last_consumed_item[0],num=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or by vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09873178,  1.0231442 , -0.07677509,  0.21820693,  0.19420545,\n",
       "       -0.99418104, -0.11817683,  0.9886847 , -0.10364438,  0.721734  ,\n",
       "        0.01292138, -0.22700045, -0.34948814,  0.4857323 ,  0.6686215 ,\n",
       "       -0.7163373 ,  0.6335093 ,  0.41135943, -1.2004654 , -0.80307186,\n",
       "        0.20577149, -0.49734357,  0.5995932 , -0.5055137 , -1.2243613 ,\n",
       "        0.29595345,  0.12054698,  0.6420872 , -1.0629041 ,  0.18982516,\n",
       "       -0.4757336 ,  0.66419184,  0.27802587,  1.2994084 , -0.28180864,\n",
       "        0.30063114, -0.05716378, -0.06702942, -0.8282801 , -0.4500681 ,\n",
       "        0.2749277 , -0.43798903, -0.35724545,  1.1578708 ,  1.0002444 ,\n",
       "        0.04804122,  0.6924802 , -1.4123019 ,  0.0496449 , -0.03420306],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv[str(last_consumed_item[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[157, 26142, 66915, 27829, 26195]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_similar_vectors(w2vmodel,vec,num=5):\n",
    "        return [int(iid) for iid,_ in w2vmodel.wv.most_similar(positive=[vec],topn=num)] \n",
    "\n",
    "get_similar_vectors(w2v,w2v.wv[str(last_consumed_item[0])],num=5) # items are strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see if this works\n",
    "\n",
    "We can query by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies similar to:  Toy Story (1995)\n",
      "\n",
      "-->  Forrest Gump (1994)\n",
      "-->  Aladdin (1992)\n",
      "-->  Toy Story 2 (1999)\n"
     ]
    }
   ],
   "source": [
    "ID = 1\n",
    "NUM_SIM = 3\n",
    "\n",
    "print(\"Movies similar to: \", id2title[ID])\n",
    "print(\"\")\n",
    "for x in get_similar_ids(w2v,ID,NUM_SIM):\n",
    "    print(\"--> \",id2title[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also query by vector\n",
    "\n",
    "**NOTE:** the 1st results can be the item(s) you've used to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies similar to:  Toy Story (1995)\n",
      "\n",
      "-->  Toy Story (1995)\n",
      "-->  Forrest Gump (1994)\n",
      "-->  Aladdin (1992)\n",
      "-->  Toy Story 2 (1999)\n"
     ]
    }
   ],
   "source": [
    "ID = 1\n",
    "NUM_SIM = 4\n",
    "print(\"Movies similar to: \", id2title[ID])\n",
    "print(\"\")\n",
    "for x in get_similar_vectors(w2v,w2v.wv[str(ID)],NUM_SIM):\n",
    "    print(\"--> \",id2title[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our result was the following (for ID = 1 & NUM_SIM = 3)\n",
    "\n",
    ">Movies similar to:  Toy Story (1995)\n",
    ">-  Beauty and the Beast (1991)\n",
    "-   Toy Story 2 (1999)\n",
    "-   Lion King, The (1994)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using vectors enables operations like additions to be made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies similar to:  Matrix, The (1999) + Terminator 2: Judgment Day (1991)\n",
      "\n",
      "-->  Matrix, The (1999)\n",
      "-->  Saving Private Ryan (1998)\n",
      "-->  Terminator 2: Judgment Day (1991)\n",
      "-->  Terminator, The (1984)\n",
      "-->  Star Wars: Episode V - The Empire Strikes Back (1980)\n",
      "-->  Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n",
      "-->  Seven (a.k.a. Se7en) (1995)\n",
      "-->  Braveheart (1995)\n",
      "-->  Fuzz (1972)\n",
      "-->  Speed (1994)\n"
     ]
    }
   ],
   "source": [
    "ID1 = 2571\n",
    "ID2 = 589\n",
    "NUM_SIM = 10\n",
    "\n",
    "vec = np.max([w2v.wv[str(ID1)],w2v.wv[str(ID2)]],axis=0)# + w2v.wv[str(318)]\n",
    "\n",
    "print(\"Movies similar to: \", id2title[ID1] , \"+\",  id2title[ID2] )\n",
    "print(\"\")\n",
    "for x in get_similar_vectors(w2v,vec ,NUM_SIM):\n",
    "    print(\"--> \",id2title[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we now have a good base for our sequence recommendation algorithm, let's write something to evaluate our predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Todo) write a `get_relevance_list(proposed_ids,real_ids)` function:\n",
    "\n",
    "This function will be used to compare proposed items w/ real items:\n",
    "\n",
    "\n",
    "- A relevant item is an item which is in the ground truth\n",
    "- It returns a list which length is the number of proposed items filled of 0's and 1's : 0 means the item is not relevant, 1 means it's relevant.\n",
    "\n",
    "- get_relevance_list([1,2,3,4],[1,4,5,6]) should returns [1,0,0,1]  because items 1 and 4 are relevant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_relevance_list(proposed_ids,real_ids):\n",
    "    real_ids = set(real_ids)\n",
    "    return [1 if i in real_ids else 0 for i in proposed_ids]\n",
    "\n",
    "get_relevance_list([1,2,3,4],[1,4,5,6]) #returns [1,0,0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's test our function on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relevance_list(most_popular[:25],test_seq[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relevance_list(get_similar_ids(w2v,last_consumed_item[0],25),test_seq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok, now, let's write prediction funtions:\n",
    "\n",
    "- `predict_pop` will recommend the k's most popular items\n",
    "- `predict_w2v` will recommend the k's most similar items to the last one consumed\n",
    "\n",
    "#### (TODO) : complete those functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pop(last_seen,k,popular=most_popular):\n",
    "    return popular[:k]\n",
    "\n",
    "def predict_w2v(last_seen,k,w2vmodel=w2v):\n",
    "    return  get_similar_ids(w2vmodel,last_seen,num=k)\n",
    "\n",
    "#data is list of last_consumed:\n",
    "def get_predictions(predict_func,data,truth,k=5):\n",
    "    if k == -1 or k == 0:\n",
    "        k = num_items\n",
    "    return [get_relevance_list(predict_func(last_seen,k),will_see) for last_seen,will_see in zip(data,truth)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The `get_predictions(...)` function returns the relevant list associated to predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following cells should return list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[157, 80906, 688, 4641, 475]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_consumed_item[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1445, 553, 2478, 2012, 2492],\n",
       " [89774, 1704, 122882, 114060, 80489],\n",
       " [3949, 2090, 527, 5048, 2424],\n",
       " [4273, 4381, 4741, 4896, 4246],\n",
       " [266, 534, 300, 247, 474]]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n",
      "80906\n",
      "688\n",
      "4641\n",
      "475\n",
      "[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]\n",
      "157\n",
      "80906\n",
      "688\n",
      "4641\n",
      "475\n",
      "[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(get_predictions(predict_pop,last_consumed_item[:5],test_seq[:5],3))\n",
    "print(get_predictions(predict_w2v,last_consumed_item[:5],test_seq[:5],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expected output: \n",
    "```\n",
    "[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]\n",
    "[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The return of the MRR and nDCG functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [[0,0,1],[0,1,0],[1,0,0],[0,0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4583333333333333"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rr(list_items):\n",
    "    relevant_indexes = np.asarray(list_items).nonzero()[0]\n",
    "    \n",
    "    if len(relevant_indexes) > 0:\n",
    "        return 1/(relevant_indexes[0]+1) # arrays are indexed from 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def mrr(list_list_items):\n",
    "    return np.mean([rr(list_item) for list_item in list_list_items])\n",
    "\n",
    "mrr(test_list) #0.4583333333333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "4.2618595071429155\n"
     ]
    }
   ],
   "source": [
    "# The dcg@k is the sum of the relevance, penalized gradually\n",
    "def dcg_at_k(r, k):\n",
    "    \"\"\"Score is discounted cumulative gain (dcg)\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        \n",
    "    \"\"\"\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        \n",
    "    return 0.\n",
    "\n",
    "# test values\n",
    "# r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "# dcg_at_k(r, 1) => 3.0\n",
    "# dcg_at_k(r, 2) => 4.2618595071429155\n",
    "r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "print(dcg_at_k(r, 1))\n",
    "print(dcg_at_k(r, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7942854176010882"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And it's normalized version\n",
    "def ndcg_at_k(r, k):\n",
    "    \"\"\"\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "    \"\"\"\n",
    "    dcg_max =  dcg_at_k(sorted(r)[::-1],k) \n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k) / dcg_max\n",
    "\n",
    "# test values\n",
    "# r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "# ndcg_at_k(r, 1) => 1.0\n",
    "# ndcg_at_k(r, 4) => 0.794285\n",
    "    \n",
    "r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]    \n",
    "ndcg_at_k(r, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_dcg(rel_lists,k):\n",
    "    return np.mean([dcg_at_k(rel_list,k) for rel_list in rel_lists])\n",
    "\n",
    "def mean_ndcg(rel_lists,k):\n",
    "    return np.mean([ndcg_at_k(rel_list,k) for rel_list in rel_lists])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see how this naÃ¯ve way of predicting items to show works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/MRR\n",
      "18.089018857528632\n",
      "11.60834039203516\n",
      "\n",
      "DCG\n",
      "0.0507673354188168\n",
      "0.08805951910386073\n",
      "\n",
      "nDCG\n",
      "0.01745016484461114\n",
      "0.03017633559831179\n"
     ]
    }
   ],
   "source": [
    "pop_preds = get_predictions(predict_pop,last_consumed_item,test_seq,-1)\n",
    "w2v_preds = get_predictions(predict_w2v,last_consumed_item,test_seq,-1)\n",
    "\n",
    "print(\"1/MRR\")\n",
    "print(1/mrr(pop_preds))\n",
    "print(1/mrr(w2v_preds))\n",
    "print(\"\")\n",
    "print(\"DCG\")\n",
    "print(mean_dcg(pop_preds,5))\n",
    "print(mean_dcg(w2v_preds,5))\n",
    "print(\"\")\n",
    "print(\"nDCG\")\n",
    "print(mean_ndcg(pop_preds,5))\n",
    "print(mean_ndcg(w2v_preds,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) Can we do better ?\n",
    "\n",
    "Now, try a different strategy: \n",
    "\n",
    "\n",
    "- History should be discarded from prediction\n",
    "- Instead of basing the prediction on the last seen item, we'll take all the `seen[-n:]` ones (horizon) into account\n",
    "- To aggregate all items, we'll simply take the min rank to take into account the history offset.\n",
    "- Equal scores can be handled using the history offset.\n",
    "Example: \n",
    "\n",
    "> Let's say you chose to use the two last seen items `[item 44, Item 398]` to predict the following items\n",
    "\n",
    "Therefore, using `get_similar_ids` method on both items will yield two lists of **similar** ranked item id's:\n",
    " - Similar to item 44: `[item 1, item 33, item 5]`\n",
    " - Similar to item 398: `[item 25, item 1, item 5]`\n",
    " scores (rank,offset):\n",
    " ```\n",
    " scores := {item 1: (0,0), item 33: (1,0), item 5: (2,0) , item 25: (0,1)}```\n",
    " \n",
    " \n",
    "Then, aggregation by best rank should yield: `[1,25,33,5]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_max_w2v(seen,k,horizon=2,w2vmodel=w2v):\n",
    "    \n",
    "   \n",
    "    dico = dict()\n",
    "    id_items = seen[-horizon:]\n",
    "\n",
    "    for id in id_items :\n",
    "        list_item = get_similar_ids(w2vmodel,id,num=k)\n",
    "        \n",
    "        for i,item in enumerate(list_item) :\n",
    "            if item not in dico.keys() :\n",
    "                dico[item] = i\n",
    "    \n",
    "    return [i[1] for i in sorted(dico.items(),key=lambda x : x[1])]\n",
    "\n",
    "w2v_best_preds = get_predictions(predict_max_w2v,train_seq,test_seq,-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.72668807608646\n",
      "0.00869195918810561\n",
      "0.0029479666624677926\n"
     ]
    }
   ],
   "source": [
    "print(1/mrr(w2v_best_preds))\n",
    "print(mean_dcg(w2v_best_preds,5))\n",
    "print(mean_ndcg(w2v_best_preds,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### => Not really better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's visualize learned embeddings\n",
    "\n",
    "Just like in the 1st practical, we propose to visualize learnt items embeddings with the [Tensorflow projector](https://projector.tensorflow.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function saves embeddings (a numpy array) and associated labels into tsv files.\n",
    "\n",
    "def save_embeddings(embs,dict_label,path=\"saved_word_vectors\"):\n",
    "    \"\"\"\n",
    "    embs is Numpy.array(N,size)\n",
    "    dict_label is {str(word)->int(idx)} or {int(idx)->str(word)}\n",
    "    \"\"\"\n",
    "    def int_first(k,v):\n",
    "        if type(k) == int:\n",
    "            return (k,v)\n",
    "        else:\n",
    "            return (v,k)\n",
    "\n",
    "    np.savetxt(f\"{path}_vectors.tsv\", embs, delimiter=\"\\t\")\n",
    "\n",
    "    #labels \n",
    "    if dict_label:\n",
    "        sorted_labs = np.array([lab for idx,lab in sorted([int_first(k,v) for k,v in dict_label.items()])])\n",
    "        print(sorted_labs)\n",
    "        with open(f\"{path}_metadata.tsv\",\"w\") as metadata_file:\n",
    "            for x in sorted_labs: #hack for space\n",
    "                if len(x.strip()) == 0:\n",
    "                    x = f\"space-{len(x)}\"\n",
    "                    \n",
    "                metadata_file.write(f\"{x}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec2title = {i:id2title[int(mid)] for i,mid in enumerate(w2v.wv.index_to_key)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Forrest Gump (1994)' 'Shawshank Redemption, The (1994)'\n",
      " 'Pulp Fiction (1994)' ...\n",
      " 'Weekend (a.k.a. Le Week-end) (Week End) (1967)' 'Mischief (1985)'\n",
      " 'Splinter (2008)']\n"
     ]
    }
   ],
   "source": [
    "save_embeddings(w2v.wv.vectors,vec2title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to:\n",
    "\n",
    "- Now, [open this link](https://projector.tensorflow.org/), and select \"load\".\n",
    "- look for saved_word_vectors_vectors.tsv and saved_word_vectors_metadata.tsv. \n",
    "\n",
    "=> These are respectively, the items latent representations and their labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters matter when using Word2Vec for Item recommendation:\n",
    "\n",
    "\n",
    "> Skip-gram with negative sampling, a popular variant of Word2vec originally designed and tuned to create word embeddings for Natural Language Processing, has been used to create item embeddings with successful applications in recommendation. While these fields do not share the same type of data, neither evaluate on the same tasks, recommendation applications tend to use the same already tuned hyperparameters values, even if optimal hyperparameters values are often known to be data and task dependent. We thus investigate the marginal importance of each hyperparameter in a recommendation setting through large hyperparameter grid searches on various datasets. Results reveal that optimizing neglected hyperparameters, namely negative sampling distribution, number of epochs, subsampling parameter and window-size, significantly improves performance on a recommendation task, and can increase it by an order of magnitude. Importantly, we find that optimal hyperparameters configurations for Natural Language Processing tasks and Recommendation tasks are noticeably different. \n",
    "\n",
    "[Hyperparameters matter](https://arxiv.org/abs/1804.04212)\n",
    "\n",
    "#### It turns out that  hyperparameters are really important for this task: especially the sampling parameter.  Try and learn multiple models to see how the ns_exponent parameter modifies the results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 19:10:07,099 : INFO : collecting all words and their counts\n",
      "2022-02-23 19:10:07,101 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-02-23 19:10:07,120 : INFO : collected 9616 word types from a corpus of 97786 raw words and 610 sentences\n",
      "2022-02-23 19:10:07,121 : INFO : Creating a fresh vocabulary\n",
      "2022-02-23 19:10:07,159 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 9616 unique words (100.0%% of original 9616, drops 0)', 'datetime': '2022-02-23T19:10:07.159296', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "2022-02-23 19:10:07,161 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 97786 word corpus (100.0%% of original 97786, drops 0)', 'datetime': '2022-02-23T19:10:07.161248', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "2022-02-23 19:10:07,216 : INFO : deleting the raw counts dictionary of 9616 items\n",
      "2022-02-23 19:10:07,217 : INFO : sample=0.001 downsamples 5 most-common words\n",
      "2022-02-23 19:10:07,217 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 97657.99863393226 word corpus (99.9%% of prior 97786)', 'datetime': '2022-02-23T19:10:07.217141', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "2022-02-23 19:10:07,304 : INFO : estimated required memory for 9616 words and 50 dimensions: 8654400 bytes\n",
      "2022-02-23 19:10:07,304 : INFO : resetting layer weights\n",
      "2022-02-23 19:10:07,307 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-02-23T19:10:07.307702', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'build_vocab'}\n",
      "2022-02-23 19:10:07,308 : INFO : Word2Vec lifecycle event {'msg': 'training model with 10 workers on 9616 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=3 shrink_windows=True', 'datetime': '2022-02-23T19:10:07.308694', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'train'}\n",
      "2022-02-23 19:10:07,481 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:07,486 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:07,492 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:07,494 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:07,506 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:07,509 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:07,510 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:07,511 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:07,512 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:07,513 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:07,514 : INFO : EPOCH - 1 : training on 97786 raw words (97660 effective words) took 0.2s, 489667 effective words/s\n",
      "2022-02-23 19:10:07,668 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:07,684 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:07,698 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:07,699 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:07,726 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:07,729 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:07,732 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:07,733 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:07,740 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:07,742 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:07,743 : INFO : EPOCH - 2 : training on 97786 raw words (97670 effective words) took 0.2s, 437460 effective words/s\n",
      "2022-02-23 19:10:07,917 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:07,924 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:07,941 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:07,943 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:07,945 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:07,946 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:07,963 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:07,968 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:07,973 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:07,983 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:07,984 : INFO : EPOCH - 3 : training on 97786 raw words (97637 effective words) took 0.2s, 412482 effective words/s\n",
      "2022-02-23 19:10:08,178 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:08,181 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:08,186 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:08,194 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:08,195 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:08,200 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:08,204 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:08,214 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:08,215 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:08,218 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:08,219 : INFO : EPOCH - 4 : training on 97786 raw words (97659 effective words) took 0.2s, 424087 effective words/s\n",
      "2022-02-23 19:10:08,381 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:08,386 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:08,416 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:08,418 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:08,422 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:08,429 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:08,432 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:08,434 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:08,455 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:08,460 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:08,461 : INFO : EPOCH - 5 : training on 97786 raw words (97648 effective words) took 0.2s, 413973 effective words/s\n",
      "2022-02-23 19:10:08,616 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:08,623 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:08,623 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:08,623 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:08,666 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:08,668 : INFO : worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 19:10:08,669 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:08,679 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:08,679 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:08,683 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:08,684 : INFO : EPOCH - 6 : training on 97786 raw words (97646 effective words) took 0.2s, 447722 effective words/s\n",
      "2022-02-23 19:10:08,832 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:08,850 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:08,851 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:08,861 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:08,863 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:08,880 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:08,884 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:08,887 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:08,889 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:08,902 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:08,903 : INFO : EPOCH - 7 : training on 97786 raw words (97670 effective words) took 0.2s, 461057 effective words/s\n",
      "2022-02-23 19:10:09,052 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:09,052 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:09,071 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:09,072 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:09,084 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:09,088 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:09,092 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:09,113 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:09,116 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:09,118 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:09,118 : INFO : EPOCH - 8 : training on 97786 raw words (97673 effective words) took 0.2s, 463412 effective words/s\n",
      "2022-02-23 19:10:09,265 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:09,281 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:09,290 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:09,293 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:09,301 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:09,303 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:09,304 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:09,305 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:09,308 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:09,318 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:09,319 : INFO : EPOCH - 9 : training on 97786 raw words (97666 effective words) took 0.2s, 494971 effective words/s\n",
      "2022-02-23 19:10:09,466 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:09,466 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:09,476 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:09,478 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:09,490 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:09,497 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:09,502 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:09,505 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:09,530 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:09,533 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:09,534 : INFO : EPOCH - 10 : training on 97786 raw words (97661 effective words) took 0.2s, 464140 effective words/s\n",
      "2022-02-23 19:10:09,682 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:09,698 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:09,705 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:09,713 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:09,714 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:09,714 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:09,718 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:09,723 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:09,723 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:09,732 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:09,733 : INFO : EPOCH - 11 : training on 97786 raw words (97670 effective words) took 0.2s, 500074 effective words/s\n",
      "2022-02-23 19:10:09,877 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:09,895 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:09,896 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:09,900 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:09,920 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:09,925 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:09,926 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:09,928 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:09,943 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:09,946 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:09,947 : INFO : EPOCH - 12 : training on 97786 raw words (97649 effective words) took 0.2s, 466893 effective words/s\n",
      "2022-02-23 19:10:10,117 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:10,121 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:10,123 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:10,125 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:10,129 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:10,141 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:10,142 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:10,151 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:10,153 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:10,157 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:10,158 : INFO : EPOCH - 13 : training on 97786 raw words (97660 effective words) took 0.2s, 473924 effective words/s\n",
      "2022-02-23 19:10:10,288 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:10,320 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:10,321 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:10,324 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:10,350 : INFO : worker thread finished; awaiting finish of 5 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 19:10:10,352 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:10,356 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:10,358 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:10,361 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:10,372 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:10,373 : INFO : EPOCH - 14 : training on 97786 raw words (97668 effective words) took 0.2s, 463578 effective words/s\n",
      "2022-02-23 19:10:10,562 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:10,567 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:10,571 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:10,575 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:10,581 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:10,584 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:10,590 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:10,602 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:10,611 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:10,621 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:10,622 : INFO : EPOCH - 15 : training on 97786 raw words (97670 effective words) took 0.2s, 403153 effective words/s\n",
      "2022-02-23 19:10:10,810 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:10,810 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:10,812 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:10,819 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:10,824 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:10,832 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:10,835 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:10,847 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:10,850 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:10,851 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:10,851 : INFO : EPOCH - 16 : training on 97786 raw words (97643 effective words) took 0.2s, 436629 effective words/s\n",
      "2022-02-23 19:10:11,015 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:11,021 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:11,030 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:11,036 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:11,044 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:11,049 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:11,049 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:11,056 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:11,063 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:11,065 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:11,066 : INFO : EPOCH - 17 : training on 97786 raw words (97643 effective words) took 0.2s, 467025 effective words/s\n",
      "2022-02-23 19:10:11,216 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:11,221 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:11,221 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:11,233 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:11,234 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:11,237 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:11,261 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:11,264 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:11,272 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:11,278 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:11,279 : INFO : EPOCH - 18 : training on 97786 raw words (97657 effective words) took 0.2s, 467343 effective words/s\n",
      "2022-02-23 19:10:11,416 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:11,416 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:11,416 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:11,442 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:11,457 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:11,462 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:11,477 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:11,478 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:11,479 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:11,481 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:11,481 : INFO : EPOCH - 19 : training on 97786 raw words (97655 effective words) took 0.2s, 491882 effective words/s\n",
      "2022-02-23 19:10:11,601 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:11,638 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:11,640 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:11,647 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:11,659 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:11,672 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:11,673 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:11,678 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:11,682 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:11,691 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:11,691 : INFO : EPOCH - 20 : training on 97786 raw words (97647 effective words) took 0.2s, 474330 effective words/s\n",
      "2022-02-23 19:10:11,847 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:11,858 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:11,869 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:11,871 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:11,877 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:11,878 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:11,879 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:11,884 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:11,889 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:11,894 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:11,895 : INFO : EPOCH - 21 : training on 97786 raw words (97671 effective words) took 0.2s, 491727 effective words/s\n",
      "2022-02-23 19:10:12,032 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:12,048 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:12,053 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:12,054 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 19:10:12,063 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:12,083 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:12,086 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:12,089 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:12,098 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:12,111 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:12,112 : INFO : EPOCH - 22 : training on 97786 raw words (97659 effective words) took 0.2s, 460233 effective words/s\n",
      "2022-02-23 19:10:12,266 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:12,285 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:12,287 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:12,288 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:12,294 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:12,295 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:12,298 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:12,299 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:12,301 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:12,307 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:12,308 : INFO : EPOCH - 23 : training on 97786 raw words (97663 effective words) took 0.2s, 507525 effective words/s\n",
      "2022-02-23 19:10:12,448 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:12,463 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:12,470 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:12,476 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:12,486 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:12,494 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:12,499 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:12,503 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:12,507 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:12,514 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:12,514 : INFO : EPOCH - 24 : training on 97786 raw words (97665 effective words) took 0.2s, 484600 effective words/s\n",
      "2022-02-23 19:10:12,663 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-23 19:10:12,663 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-23 19:10:12,682 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-23 19:10:12,696 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-23 19:10:12,697 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-23 19:10:12,700 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-23 19:10:12,701 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-23 19:10:12,703 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-23 19:10:12,706 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-23 19:10:12,712 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-23 19:10:12,712 : INFO : EPOCH - 25 : training on 97786 raw words (97668 effective words) took 0.2s, 503125 effective words/s\n",
      "2022-02-23 19:10:12,713 : INFO : Word2Vec lifecycle event {'msg': 'training on 2444650 raw words (2441478 effective words) took 5.4s, 451774 effective words/s', 'datetime': '2022-02-23T19:10:12.713380', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'train'}\n",
      "2022-02-23 19:10:12,713 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=9616, vector_size=50, alpha=0.025)', 'datetime': '2022-02-23T19:10:12.713380', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# the following configuration is the default configuration\n",
    "w2v = gensim.models.word2vec.Word2Vec(sentences=train_seq_str,\n",
    "                                vector_size=50, window=3,               ### here we train a cbow model \n",
    "                                min_count=0,                      \n",
    "                                sample=0.001, ns_exponent=-0.4, workers=10,\n",
    "                                sg=1, hs=0, negative=15,          ### set sg to 1 to train a sg model => Prod2Vec\n",
    "                                cbow_mean=0,\n",
    "                                epochs=25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_preds = get_predictions(predict_pop,last_consumed_item,test_seq,-1)\n",
    "w2v_preds = get_predictions(predict_w2v,last_consumed_item,test_seq,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.089018857528632\n",
      "11.744708220632175\n",
      "0.0507673354188168\n",
      "0.09221702700701417\n",
      "0.01745016484461114\n",
      "0.03162255943287431\n"
     ]
    }
   ],
   "source": [
    "print(1/mrr(pop_preds))\n",
    "print(1/mrr(w2v_preds))\n",
    "\n",
    "print(mean_dcg(pop_preds,5))\n",
    "print(mean_dcg(w2v_preds,5))\n",
    "\n",
    "print(mean_ndcg(pop_preds,5))\n",
    "print(mean_ndcg(w2v_preds,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Still got time ? Try making a more clever item selection mechanism:\n",
    "\n",
    "- You could, for example, cluster items in groups (using k-means) and propose the most popular items of the last seen group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
