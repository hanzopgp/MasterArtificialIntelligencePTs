{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f10829be-fb69-46f2-a83d-fe8aa7b68b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mltools import plot_data, plot_frontiere, make_grid, gen_arti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f421fbb-ecbc-441c-b065-607059500ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(w,x,y):\n",
    "    if len(x) != 2:\n",
    "        return np.mean((x@w - y)**2)\n",
    "    else:\n",
    "        return np.mean((x*w-y)**2)\n",
    "\n",
    "def mse_grad(w,x,y):\n",
    "    if len(x) != 2:\n",
    "        return np.mean(1/x.shape[0] * 2 * (x.T @ x @ w - x.T @ y))\n",
    "    else:\n",
    "        return np.mean(2 * (w*x**2 - x*y))\n",
    "\n",
    "def reglog(w,x,y):\n",
    "    return np.mean(np.log(1 + np.exp(-y * (x @ w))))\n",
    "\n",
    "def reglog_grad(w,x,y):\n",
    "    return np.mean(1 / (1+np.exp(-y*(x@w))) * (-y*x) * np.exp(-y * (x@w)), axis=0).reshape(-1,1)\n",
    "\n",
    "def perceptron_loss():\n",
    "    pass\n",
    "\n",
    "def perceptron_grad():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6760ad44-87e5-487b-89b3-beb28da77c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descente_gradient(x, y, f_loss, f_grad, eps, n_iter):\n",
    "    list_w = []\n",
    "    list_l = []\n",
    "    w = np.random.randn(datax.shape[1], 1)\n",
    "    for _ in tqdm(range(n_iter)):\n",
    "        w = w - eps * f_grad(w, x, y)\n",
    "        list_w.append(w)\n",
    "        list_l.append(f_loss(w, x, y))\n",
    "    return list_w, list_l, w\n",
    "\n",
    "def descente_gradient_stoch(x, y, f_loss, f_grad, eps, n_iter):\n",
    "    list_w = []\n",
    "    list_l = []\n",
    "    n = x.shape[0]\n",
    "    w = np.random.randn(datax.shape[1], 1)\n",
    "    for _ in tqdm(range(n_iter)):\n",
    "        for _ in range(n):\n",
    "            rand_idx = np.random.randint(n)\n",
    "            w = w - eps * f_grad(w, x[rand_idx], y[rand_idx])\n",
    "        list_w.append(w)\n",
    "        list_l.append(f_loss(w, x, y))\n",
    "    return list_w, list_l, w\n",
    "\n",
    "def descente_gradient_minibatch(x, y, f_loss, f_grad, eps, n_iter):\n",
    "    list_w = []\n",
    "    list_l = []\n",
    "    n = x.shape[0]\n",
    "    w = np.random.randn(x.shape[1], 1)\n",
    "    n_batch = 20\n",
    "    batch_size = n//n_batch\n",
    "    for _ in tqdm(range(n_iter)):\n",
    "        for _ in range(n_batch):\n",
    "            rand_idx = np.random.randint(1, n_batch-1)\n",
    "            w = w - eps * f_grad(w, x[rand_idx*batch_size:rand_idx*(batch_size+1)], y[rand_idx*batch_size:rand_idx*(batch_size+1)])\n",
    "        list_w.append(w)\n",
    "        list_l.append(f_loss(w, x, y))\n",
    "    return list_w, list_l, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6111182b-620a-4704-af89-f104807147f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lineaire(object):\n",
    "    def __init__(self,loss=perceptron_loss,loss_g=perceptron_grad,max_iter=100,eps=0.01):\n",
    "        self.max_iter, self.eps = max_iter,eps\n",
    "        self.w = None\n",
    "        self.loss,self.loss_g = loss,loss_g\n",
    "        \n",
    "    def fit(self,datax,datay):\n",
    "        pass\n",
    "\n",
    "    def predict(self,datax):\n",
    "        pass\n",
    "\n",
    "    def score(self,datax,datay):\n",
    "        pass\n",
    "\n",
    "def load_usps(fn):\n",
    "    with open(fn,\"r\") as f:\n",
    "        f.readline()\n",
    "        data = [[float(x) for x in l.split()] for l in f if len(l.split())>2]\n",
    "    tmp=np.array(data)\n",
    "    return tmp[:,1:],tmp[:,0].astype(int)\n",
    "\n",
    "def get_usps(l,datax,datay):\n",
    "    if type(l)!=list:\n",
    "        resx = datax[datay==l,:]\n",
    "        resy = datay[datay==l]\n",
    "        return resx,resy\n",
    "    tmp =   list(zip(*[get_usps(i,datax,datay) for i in l]))\n",
    "    tmpx,tmpy = np.vstack(tmp[0]),np.hstack(tmp[1])\n",
    "    return tmpx,tmpy\n",
    "\n",
    "def show_usps(data):\n",
    "    plt.imshow(data.reshape((16,16)),interpolation=\"nearest\",cmap=\"gray\")\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    uspsdatatrain = \"../data/USPS_train.txt\"\n",
    "    uspsdatatest = \"../data/USPS_test.txt\"\n",
    "    alltrainx,alltrainy = load_usps(uspsdatatrain)\n",
    "    alltestx,alltesty = load_usps(uspsdatatest)\n",
    "    neg = 5\n",
    "    pos = 6\n",
    "    datax,datay = get_usps([neg,pos],alltrainx,alltrainy)\n",
    "    testx,testy = get_usps([neg,pos],alltestx,alltesty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19557551-bd15-47ec-a6e0-ace59bb31446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
