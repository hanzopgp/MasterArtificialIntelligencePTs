{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a2ee77-b525-45b9-ae3b-fc60ecfe82bd",
   "metadata": {},
   "source": [
    "# I) General"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d94991-0b5a-4f2c-ae45-4ef4e3044fc9",
   "metadata": {},
   "source": [
    "## 1. Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2624ab3-0e87-4aec-965a-0c167f72b323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import re\n",
    "import os.path\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import unicodedata\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "import sklearn.naive_bayes as nb\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn() # Should speed up learning somehow \n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e47be5-218d-4c0f-8466-cb4909407d97",
   "metadata": {},
   "source": [
    "# II) First data set french presidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14039a68-9a44-4cad-8d4a-ee31bd1b4daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pres(fname):\n",
    "    alltxts = []\n",
    "    alllabs = []\n",
    "    s=codecs.open(fname, 'r','utf-8')\n",
    "    while True:\n",
    "        txt = s.readline()\n",
    "        if(len(txt))<5:\n",
    "            break\n",
    "        lab = re.sub(r\"<[0-9]*:[0-9]*:(.)>.*\",\"\\\\1\",txt)\n",
    "        txt = re.sub(r\"<[0-9]*:[0-9]*:.>(.*)\",\"\\\\1\",txt)\n",
    "        if lab.count('M') >0:\n",
    "            alllabs.append(-1)\n",
    "        else: \n",
    "            alllabs.append(1)\n",
    "        alltxts.append(txt)\n",
    "    return alltxts,alllabs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d23de8a-b2a7-487d-a3d1-1ec6569dc8fe",
   "metadata": {},
   "source": [
    "## 2. Features and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f73ba526-ea80-42ed-b487-086291f9e3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_balancing(X, Y):\n",
    "    label, count = np.unique(Y, return_counts=True)\n",
    "    idx_pos = np.where(Y == 1, True, False)\n",
    "    Y_pos = Y[idx_pos]\n",
    "    Y_pos = Y_pos[:count.min()]\n",
    "    idx_neg = np.where(Y == -1, True, False)\n",
    "    Y_neg = Y[idx_neg]\n",
    "    new_Y = np.concatenate((Y_pos, Y_neg))\n",
    "    new_X = np.concatenate((X[:count.min()], X[idx_neg]))    \n",
    "    tmp = list(zip(new_X, new_Y))\n",
    "    random.shuffle(tmp)\n",
    "    new_X, new_Y = zip(*tmp)  \n",
    "    label, count = np.unique(new_Y, return_counts=True)\n",
    "    print(label, count)\n",
    "    return new_X, new_Y\n",
    "\n",
    "def get_all_data_vectorized(X, X_test, Y, Y_test, vectorizer, transformer=None):\n",
    "    X_vector = vectorizer.fit_transform(X)\n",
    "    if transformer is not None:\n",
    "        transformer = transformer.fit(X_vector)\n",
    "        X_final = transformer.transform(X_vector)\n",
    "    else:\n",
    "        X_final = X_vector\n",
    "    X_test_vector = vectorizer.transform(X_test)\n",
    "    return X_final, X_test_vector, Y, Y_test\n",
    "\n",
    "def get_inf_acc(predictions, Y_test):\n",
    "    idx_inf = np.where(predictions==-1, True, False)\n",
    "    tmp_pred = predictions[idx_inf]\n",
    "    tmp_real = Y_test[idx_inf]\n",
    "    cpt = 0\n",
    "    for i in range(len(tmp_pred)):\n",
    "        if tmp_pred[i] == tmp_real[i]:\n",
    "            cpt += 1\n",
    "    return np.round((cpt/len(tmp_pred))*100, 2)\n",
    "\n",
    "def get_sup_acc(predictions, Y_test):\n",
    "    idx_inf = np.where(predictions==1, True, False)\n",
    "    tmp_pred = predictions[idx_inf]\n",
    "    tmp_real = Y_test[idx_inf]\n",
    "    cpt = 0\n",
    "    for i in range(len(tmp_pred)):\n",
    "        if tmp_pred[i] == tmp_real[i]:\n",
    "            cpt += 1\n",
    "    return np.round((cpt/len(tmp_pred))*100, 2)\n",
    "\n",
    "def display_infos(clf, X_test, Y_test):\n",
    "    # Check le nombre de predictions pour chaque label\n",
    "    predictions = clf.predict(X_test)\n",
    "    unique, counts = np.unique(predictions, return_counts=True)\n",
    "    print(\"/!\\ Prediction counts for label \", unique, \" --> \", counts)\n",
    "    # Check le nombre de predictions pour chaque label\n",
    "    unique, counts = np.unique(Y_test, return_counts=True)\n",
    "    print(\"/!\\ Ground truth counts for label \", unique, \" --> \", counts)\n",
    "    # Check la precision du label en inferiorite\n",
    "    acc = get_inf_acc(predictions, Y_test)\n",
    "    print(\"/!\\ Accuracy of inferior label :\", acc, \"%\")\n",
    "    # Check la precision du label en superiorite\n",
    "    acc = get_sup_acc(predictions, Y_test)\n",
    "    print(\"/!\\ Accuracy of superior label :\", acc, \"%\\n\")\n",
    "    \n",
    "def display_model_scores(model, X_test, Y_test, search=True):\n",
    "    if search:\n",
    "        best_parameters = model.best_estimator_.get_params()\n",
    "        for param_name in sorted(best_parameters.keys()):\n",
    "            print(\"--->%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        # print(model.best_score_)\n",
    "    grid_predictions = model.predict(X_test)\n",
    "    print(confusion_matrix(Y_test, grid_predictions))\n",
    "    print(classification_report(Y_test, grid_predictions))\n",
    "    \n",
    "def stemm(X):\n",
    "    stemmer = SnowballStemmer(\"french\")\n",
    "    stem = stemmer.stem(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaaa19b-3d06-4215-beec-ef2b8247525d",
   "metadata": {},
   "source": [
    "### --> Loading and splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d7dc8537-0303-4c38-ba50-8809c3d5f31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34447\n",
      "22966\n"
     ]
    }
   ],
   "source": [
    "fname = \"./data/corpus.tache1.learn.utf8\"\n",
    "alltxts, alllabs = load_pres(fname)\n",
    "X = np.array(alltxts)\n",
    "Y = np.array(alllabs)\n",
    "# new_X, new_Y = naive_balancing(X,Y) # not a good idea in this project\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=False)\n",
    "train_size = len(X_train)\n",
    "test_size = len(X_test)\n",
    "print(train_size)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7ea3b5-4819-4df4-9682-595978e58abd",
   "metadata": {},
   "source": [
    "### --> Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1f2db072-2ff9-4a52-9ec2-c465a5090161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(X_train))\n",
    "# stemmer = snowballstemmer.stemmer('french');\n",
    "# for i in range(len(X_train)):\n",
    "#     stemmer.stemWords(X_train[i].split()[j] for j in range(len(X_train[i].split())))\n",
    "# print(np.array(X_train).shape)\n",
    "# for i in range(len(X_test)):\n",
    "#     stemmer.stemWords(X_test[i].split()[j] for j in range(len(X_test[i].split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece7252b-9395-4062-9f86-b120bda61e56",
   "metadata": {},
   "source": [
    "### --> Feature selection depending the model selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6d043459-0dc2-4e8e-aa58-49c041fa63bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = False\n",
    "sw = stopwords.words('french')\n",
    "\n",
    "if search :\n",
    "    \n",
    "    pipeline_svc = Pipeline(\n",
    "        [\n",
    "            (\"vect\", TfidfVectorizer(max_features=100_000)), # avoids overfit on train set (having more features than individuals is bad most of the time)\n",
    "            (\"clf\", LinearSVC(class_weight=\"balanced\",       # balanced class weight parameter is mandatory in our case\n",
    "                              max_iter=1000,                 # also avoids overfit\n",
    "                              C=100))                        # regularization so the model doesn't predict only one class  \n",
    "        ]\n",
    "    )\n",
    "    # pipeline_nb = Pipeline(\n",
    "    #     [\n",
    "    #         (\"vect\", TfidfVectorizer(max_features=80_000)),\n",
    "    #         (\"clf\", MultinomialNB())      \n",
    "    #     ]\n",
    "    # )\n",
    "    # pipeline_lr = Pipeline(\n",
    "    #     [\n",
    "    #         (\"vect\", TfidfVectorizer(max_features=50_000)),\n",
    "    #         (\"clf\", LogisticRegression(class_weight=\"balanced\",\n",
    "    #                                    max_iter=1000,\n",
    "    #                                    C=100))        \n",
    "    #     ]\n",
    "    # )\n",
    "    parameters_vectorizer = {\n",
    "        \"vect__lowercase\": (False,),\n",
    "        \"vect__stop_words\": (None,),\n",
    "        \"vect__strip_accents\": (\"ascii\",),\n",
    "        \"vect__use_idf\": (True,),\n",
    "        \"vect__smooth_idf\": (False,),\n",
    "        \"vect__sublinear_tf\": (True,),\n",
    "        \n",
    "        \"vect__min_df\": (1,),\n",
    "        \"vect__max_df\": np.arange(0.4,0.6,0.05),\n",
    "        \"vect__ngram_range\": [(1, 2),],\n",
    "        }\n",
    "    \n",
    "    strat_kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "    grid_search_parameters_svc = GridSearchCV(pipeline_svc, \n",
    "                                              parameters_vectorizer, \n",
    "                                              scoring=\"f1_micro\", # test \"rog_auc\", \"f1_micro\"\n",
    "                                              n_jobs=8, \n",
    "                                              verbose=3, \n",
    "                                              cv=strat_kfold,\n",
    "                                              refit=True\n",
    "                                              )\n",
    "    # grid_search_parameters_nb = GridSearchCV(pipeline_nb, \n",
    "    #                                           parameters_vectorizer, \n",
    "    #                                           scoring=\"f1\",\n",
    "    #                                           n_jobs=8, \n",
    "    #                                           verbose=3, \n",
    "    #                                           cv=strat_kfold,\n",
    "    #                                           refit=True\n",
    "    #                                           )\n",
    "    # grid_search_parameters_lr = GridSearchCV(pipeline_lr, \n",
    "    #                                           parameters_vectorizer, \n",
    "    #                                           scoring=\"f1\", \n",
    "    #                                           n_jobs=8, \n",
    "    #                                           verbose=3, \n",
    "    #                                           cv=strat_kfold,\n",
    "    #                                           refit=True\n",
    "    #                                           )\n",
    "    \n",
    "    print(\"============================================= SVC + VECTORIZER =============================================\")\n",
    "    t0 = time()\n",
    "    grid_search_parameters_svc.fit(X_train, Y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    display_model_scores(grid_search_parameters_svc, X_train, Y_train) # check overfit X_train\n",
    "    display_model_scores(grid_search_parameters_svc, X_test, Y_test)\n",
    "    \n",
    "#     print(\"============================================= NB + VECTORIZER =============================================\")\n",
    "#     t0 = time()\n",
    "#     grid_search_parameters_nb.fit(X_train, Y_train)\n",
    "#     print(\"done in %0.3fs\" % (time() - t0))\n",
    "#     display_model_scores(grid_search_parameters_nb, X_train, Y_train)\n",
    "#     display_model_scores(grid_search_parameters_nb, X_test, Y_test) \n",
    "    \n",
    "    # print(\"============================================= LR + VECTORIZER =============================================\")\n",
    "    # t0 = time()\n",
    "    # grid_search_parameters_lr.fit(X_train, Y_train)\n",
    "    # print(\"done in %0.3fs\" % (time() - t0))\n",
    "    # display_model_scores(grid_search_parameters_lr, X_train, Y_train)\n",
    "    # display_model_scores(grid_search_parameters_lr, X_test, Y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c0330726-67ec-419b-914a-6d42e4e27396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_model_scores(grid_search_parameters_svc, X_test, Y_test)\n",
    "# display_model_scores(grid_search_parameters_nb, X_test, Y_test)\n",
    "# display_model_scores(grid_search_parameters_lr, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0829553-7d75-4619-ae11-a2b9bdf6b67e",
   "metadata": {},
   "source": [
    "### --> Building optimal vectorizer for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0dbc5c7a-2a6b-44d4-823a-9e95a4dd584e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34447, 100000)\n",
      "(34447, 9927)\n",
      "(34447, 100000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer_svc = TfidfVectorizer(lowercase=False,       # Almost false everytime in our case\n",
    "                                 stop_words=None,       # Never remove stopwords\n",
    "                                 strip_accents=\"ascii\", # Sometimes none sometimes ascii, doesn't really matter\n",
    "                                 use_idf=True,          # Always true\n",
    "                                 smooth_idf=False,      # Sometimes true sometimes false, doesn't really matter\n",
    "                                 sublinear_tf=True,     # Sometimes true sometimes false, doesn't really matter\n",
    "                             \n",
    "                                 max_features=100_000,  # Avoids overfit and reduce noise\n",
    "                                 min_df=1,              # Always 1, meaning we don't remove anything\n",
    "                                 max_df=0.55,           # One of the most meaningful parameters, can be 0.05, 0.9 ...\n",
    "                                 ngram_range=(1,2),     # Always unigram + bigram\n",
    "                                 )\n",
    "\n",
    "vectorizer_nb = TfidfVectorizer(lowercase=False,\n",
    "                                stop_words=None,\n",
    "                                strip_accents=None,\n",
    "                                use_idf=True,\n",
    "                                smooth_idf=True,\n",
    "                                sublinear_tf=False,\n",
    "                             \n",
    "                                max_features=100_000,\n",
    "                                min_df=15,\n",
    "                                max_df=0.05,\n",
    "                                ngram_range=(1,2),\n",
    "                                )\n",
    "\n",
    "vectorizer_lr = TfidfVectorizer(lowercase=False,\n",
    "                                stop_words=None,\n",
    "                                strip_accents=\"ascii\",\n",
    "                                use_idf=True,\n",
    "                                smooth_idf=False,\n",
    "                                sublinear_tf=False,\n",
    "                             \n",
    "                                max_features=100_000,\n",
    "                                min_df=1,\n",
    "                                max_df=0.5,\n",
    "                                ngram_range=(1,2),\n",
    "                                )\n",
    "\n",
    "# Remove comment for stemming\n",
    "# print(len(X_train))\n",
    "# stemmer = snowballstemmer.stemmer('french');\n",
    "# for i in range(len(X_train)):\n",
    "#     stemmer.stemWords(X_train[i].split()[j] for j in range(len(X_train[i].split())))\n",
    "# print(np.array(X_train).shape)\n",
    "\n",
    "X_train_vector_svc, X_test_vector_svc, Y_train_svc, Y_test_svc = get_all_data_vectorized(X_train, X_test, Y_train, Y_test, vectorizer_svc)\n",
    "print(X_train_vector_svc.shape)\n",
    "X_train_vector_nb, X_test_vector_nb, Y_train_nb, Y_test_nb = get_all_data_vectorized(X_train, X_test, Y_train, Y_test, vectorizer_nb)\n",
    "print(X_train_vector_nb.shape)\n",
    "X_train_vector_lr, X_test_vector_lr, Y_train_lr, Y_test_lr = get_all_data_vectorized(X_train, X_test, Y_train, Y_test, vectorizer_lr)\n",
    "print(X_train_vector_lr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa31fed-288f-499e-84c5-f89456e562e4",
   "metadata": {},
   "source": [
    "### --> Model selection SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ecb67c3d-60a3-4ba0-a2d3-dd2956fbb625",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = False\n",
    "if search:\n",
    "    parameters = {\n",
    "        'C': np.arange(3.2,4,0.05)  \n",
    "    }\n",
    "    \n",
    "    strat_kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    optimal_svc = GridSearchCV(LinearSVC(class_weight=\"balanced\",\n",
    "                                         max_iter=2000),\n",
    "                               parameters, \n",
    "                               scoring=\"f1\",\n",
    "                               n_jobs=8, \n",
    "                               verbose=3, \n",
    "                               cv=strat_kfold,\n",
    "                               refit=True\n",
    "                               )\n",
    "\n",
    "    t0 = time()\n",
    "    optimal_svc.fit(X_train_vector_svc, Y_train_svc)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    \n",
    "    display_model_scores(optimal_svc, X_train_vector_svc, Y_train_svc)\n",
    "    display_model_scores(optimal_svc, X_test_vector_svc, Y_test_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69a5a43-a39d-4378-9e23-2a1bb5c282c3",
   "metadata": {},
   "source": [
    "### --> Model selection NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e76a57ee-371e-4e50-a131-ee8b24a871ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = False\n",
    "if search:\n",
    "    parameters = {\n",
    "        'alpha': np.arange(0, 1, 0.05),\n",
    "    }\n",
    "    \n",
    "    strat_kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    optimal_nb = GridSearchCV(MultinomialNB(),\n",
    "                              parameters, \n",
    "                              scoring=\"f1\",\n",
    "                              n_jobs=8, \n",
    "                              verbose=3, \n",
    "                              cv=strat_kfold,\n",
    "                              refit=True\n",
    "                              )\n",
    "\n",
    "    t0 = time()\n",
    "    optimal_nb.fit(X_train_vector_nb, Y_train_nb)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    \n",
    "    display_model_scores(optimal_nb, X_train_vector_nb, Y_train_nb)\n",
    "    display_model_scores(optimal_nb, X_test_vector_nb, Y_test_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1557da0e-f6ea-43ac-ae92-4a1dc1167b3a",
   "metadata": {},
   "source": [
    "### --> Model selection LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e30b4ac9-5f14-499d-aa23-0b26a3777cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = False\n",
    "if search:\n",
    "    parameters = {\n",
    "        'C': (40,44,46) \n",
    "    }\n",
    "    \n",
    "    strat_kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    optimal_lr = GridSearchCV(LogisticRegression(class_weight=\"balanced\",\n",
    "                                                      max_iter=2000),\n",
    "                               parameters, \n",
    "                               scoring=\"f1\",\n",
    "                               n_jobs=8, \n",
    "                               verbose=3, \n",
    "                               cv=strat_kfold,\n",
    "                               refit=True\n",
    "                               )\n",
    "\n",
    "    t0 = time()\n",
    "    optimal_lr.fit(X_train_vector_lr, Y_train_lr)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    \n",
    "    display_model_scores(optimal_lr, X_train_vector_lr, Y_train_lr)\n",
    "    display_model_scores(optimal_lr, X_test_vector_lr, Y_test_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d992e59b-f003-447a-ba8e-be40f59b4b71",
   "metadata": {},
   "source": [
    "### --> Test 3 optimal models without max_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c0339ed0-79ea-48bd-929a-6096f1e47e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.165s\n",
      "[[ 5264     2]\n",
      " [    8 29173]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00      5266\n",
      "           1       1.00      1.00      1.00     29181\n",
      "\n",
      "    accuracy                           1.00     34447\n",
      "   macro avg       1.00      1.00      1.00     34447\n",
      "weighted avg       1.00      1.00      1.00     34447\n",
      "\n",
      "[[ 1325   932]\n",
      " [ 1328 19381]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      0.59      0.54      2257\n",
      "           1       0.95      0.94      0.94     20709\n",
      "\n",
      "    accuracy                           0.90     22966\n",
      "   macro avg       0.73      0.76      0.74     22966\n",
      "weighted avg       0.91      0.90      0.91     22966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# final_svc = LinearSVC(class_weight=\"balanced\",\n",
    "#                       max_iter=10_000,\n",
    "#                       C=1.15)\n",
    "\n",
    "final_svc = LinearSVC(class_weight=\"balanced\",\n",
    "                      max_iter=10_000,\n",
    "                      C=3.95)\n",
    "\n",
    "t0 = time()\n",
    "final_svc.fit(X_train_vector_svc, Y_train_svc)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "    \n",
    "display_model_scores(final_svc, X_train_vector_svc, Y_train_svc, search=False)\n",
    "display_model_scores(final_svc, X_test_vector_svc, Y_test_svc, search=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "902acf2b-ba70-427f-bd09-a6e6ff09d650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.008s\n",
      "[[ 2436  2830]\n",
      " [  382 28799]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.46      0.60      5266\n",
      "           1       0.91      0.99      0.95     29181\n",
      "\n",
      "    accuracy                           0.91     34447\n",
      "   macro avg       0.89      0.72      0.77     34447\n",
      "weighted avg       0.90      0.91      0.89     34447\n",
      "\n",
      "[[  764  1493]\n",
      " [  414 20295]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.34      0.44      2257\n",
      "           1       0.93      0.98      0.96     20709\n",
      "\n",
      "    accuracy                           0.92     22966\n",
      "   macro avg       0.79      0.66      0.70     22966\n",
      "weighted avg       0.90      0.92      0.90     22966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_nb = MultinomialNB(alpha=0.1)\n",
    "\n",
    "t0 = time()\n",
    "final_nb.fit(X_train_vector_nb, Y_train_nb)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "    \n",
    "display_model_scores(final_nb, X_train_vector_nb, Y_train_nb, search=False)\n",
    "display_model_scores(final_nb, X_test_vector_nb, Y_test_nb, search=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fd64d29e-bea4-4d12-949d-8567052db71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 4.627s\n",
      "[[ 5264     2]\n",
      " [   12 29169]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00      5266\n",
      "           1       1.00      1.00      1.00     29181\n",
      "\n",
      "    accuracy                           1.00     34447\n",
      "   macro avg       1.00      1.00      1.00     34447\n",
      "weighted avg       1.00      1.00      1.00     34447\n",
      "\n",
      "[[ 1408   849]\n",
      " [ 1476 19233]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.49      0.62      0.55      2257\n",
      "           1       0.96      0.93      0.94     20709\n",
      "\n",
      "    accuracy                           0.90     22966\n",
      "   macro avg       0.72      0.78      0.75     22966\n",
      "weighted avg       0.91      0.90      0.90     22966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_lr = LogisticRegression(class_weight=\"balanced\",\n",
    "                              max_iter=10_000,\n",
    "                              C=44)\n",
    "\n",
    "t0 = time()\n",
    "final_lr.fit(X_train_vector_lr, Y_train_lr)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "    \n",
    "display_model_scores(final_lr, X_train_vector_lr, Y_train_lr, search=False)\n",
    "display_model_scores(final_lr, X_test_vector_lr, Y_test_lr, search=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483eecb9-e46d-428f-a1af-375eb6233a3f",
   "metadata": {},
   "source": [
    "### --> Testing voting classifier test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "309288e4-7e1c-48ac-b8bb-d7ae267d25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d22fdbe6-4848-4010-b8cd-9f1d6b17caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_for_vote = SVC(kernel='linear', # VotingClassifier doesn't work with linearSVC() module if voting=\"soft\"\n",
    "                   probability=True,\n",
    "                   class_weight=\"balanced\",\n",
    "                   max_iter=10_000,\n",
    "                   C=3.95,\n",
    "                   verbose=3)\n",
    "\n",
    "voting_clf_soft = VotingClassifier(estimators=[\n",
    "                                            ('lr', final_lr), \n",
    "                                            # ('nb', final_nb),\n",
    "                                            ('svc', svc_for_vote)\n",
    "                                            ],\n",
    "                                  voting='soft',\n",
    "                                  n_jobs=1,\n",
    "                                  verbose=3)\n",
    "\n",
    "if test:\n",
    "    t0 = time()\n",
    "    voting_clf_soft.fit(X_train_vector_svc, Y_train_svc)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "    display_model_scores(voting_clf_soft, X_train_vector_svc, Y_train_svc, search=False)\n",
    "    display_model_scores(voting_clf_soft, X_test_vector_svc, Y_test_svc, search=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "470bb705-4c91-4027-8a8a-eaa43576b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf_hard = VotingClassifier(estimators=[\n",
    "                                            ('lr', final_lr), \n",
    "                                            # ('nb', final_nb),\n",
    "                                            ('svc', final_svc)\n",
    "                                            ],\n",
    "                                  voting='hard',\n",
    "                                  n_jobs=1)\n",
    "\n",
    "if test:\n",
    "    t0 = time()\n",
    "    voting_clf_hard.fit(X_train_vector_svc, Y_train_svc)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "    display_model_scores(voting_clf_hard, X_train_vector_svc, Y_train_svc, search=False)\n",
    "    display_model_scores(voting_clf_hard, X_test_vector_svc, Y_test_svc, search=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52049d5-b2ab-4f3a-b201-45d5e7c38e87",
   "metadata": {},
   "source": [
    "## 3. Final training on whole train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "68020fdf-0cb8-459b-9e57-d488ddeb65f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    fname = \"./data/corpus.tache1.learn.utf8\"\n",
    "    alltxts_train_final, alllabs_train_final = load_pres(fname)\n",
    "    X_train_final = np.array(alltxts_train_final)\n",
    "    Y_train_final = np.array(alllabs_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a7976729-ca7c-4047-bc9d-aa8c55c7f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    X_final_vector_svc = vectorizer_svc.fit_transform(X_train_final)\n",
    "    X_final_vector_nb = vectorizer_nb.fit_transform(X_train_final)\n",
    "    X_final_vector_lr = vectorizer_lr.fit_transform(X_train_final)\n",
    "\n",
    "    t0 = time()\n",
    "    final_svc.fit(X_final_vector_svc,  Y_train_final)\n",
    "    print(\" done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "    t0 = time()\n",
    "    final_nb.fit(X_final_vector_nb,  Y_train_final)\n",
    "    print(\" done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "    t0 = time()\n",
    "    final_lr.fit(X_final_vector_lr,  Y_train_final)\n",
    "    print(\" done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "    t0 = time()\n",
    "    voting_clf_soft.fit(X_final_vector_svc,  Y_train_final)\n",
    "    print(\" done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "    t0 = time()\n",
    "    voting_clf_hard.fit(X_final_vector_svc,  Y_train_final)\n",
    "    print(\" done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d11fef9-7dbb-4f4f-aa2d-82aaa289fc70",
   "metadata": {},
   "source": [
    "## 4. Computing final test predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1dd116e2-ce41-4133-b360-5fc462244ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0a7b98b3-ae1e-47cb-82a0-213956ece836",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    fname =\"./data/corpus.tache1.test.utf8\"\n",
    "    alltxts_test_final, _ = load_pres(fname)\n",
    "    X_test_final = np.array(alltxts_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "642630d1-95f1-4e0b-85ec-dc5bdd81b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    X_test_vector_svc = vectorizer_svc.transform(X_test_final)\n",
    "    final_pred_svc = final_svc.predict(X_test_vector_svc)\n",
    "\n",
    "    X_test_vector_nb = vectorizer_nb.transform(X_test_final)\n",
    "    final_pred_nb = final_nb.predict(X_test_vector_nb)\n",
    "\n",
    "    X_test_vector_lr = vectorizer_lr.transform(X_test_final)\n",
    "    final_pred_lr = final_lr.predict(X_test_vector_lr)\n",
    "\n",
    "    X_test_vector_soft = vectorizer_svc.transform(X_test_final)\n",
    "    final_pred_soft = voting_clf_soft.predict(X_test_vector_soft)\n",
    "\n",
    "    X_test_vector_hard = vectorizer_svc.transform(X_test_final)\n",
    "    final_pred_hard = voting_clf_hard.predict(X_test_vector_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f6b87f1e-1bad-4599-9f15-4f9bd1196449",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    print(final_pred_svc.shape)\n",
    "    print(final_pred_nb.shape)\n",
    "    print(final_pred_lr.shape)\n",
    "    print(final_pred_soft.shape)\n",
    "    print(final_pred_hard.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf2dcc-5191-4aff-8c05-98f20bc00c15",
   "metadata": {},
   "source": [
    "## 5. Post processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fbf548-9ed2-4d62-8db8-29f3c9a0bb49",
   "metadata": {},
   "source": [
    "### --> Train our best model with our best vectorizer and check our f1 score before postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "26f04100-b75a-4815-8eed-fef17e59df42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34447, 100000)\n",
      "(34447, 100000)\n",
      "done in 1.285s\n",
      "done in 4.525s\n",
      "[[ 1325   932]\n",
      " [ 1328 19381]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      0.59      0.54      2257\n",
      "           1       0.95      0.94      0.94     20709\n",
      "\n",
      "    accuracy                           0.90     22966\n",
      "   macro avg       0.73      0.76      0.74     22966\n",
      "weighted avg       0.91      0.90      0.91     22966\n",
      "\n",
      "[[ 1408   849]\n",
      " [ 1476 19233]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.49      0.62      0.55      2257\n",
      "           1       0.96      0.93      0.94     20709\n",
      "\n",
      "    accuracy                           0.90     22966\n",
      "   macro avg       0.72      0.78      0.75     22966\n",
      "weighted avg       0.91      0.90      0.90     22966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer_svc = TfidfVectorizer(lowercase=False,\n",
    "                                 stop_words=None,\n",
    "                                 strip_accents=\"ascii\",\n",
    "                                 use_idf=True,\n",
    "                                 smooth_idf=False,\n",
    "                                 sublinear_tf=True,\n",
    "                             \n",
    "                                 max_features=100_000,\n",
    "                                 min_df=1,\n",
    "                                 max_df=0.55,\n",
    "                                 ngram_range=(1,2),\n",
    "                                 )\n",
    "\n",
    "X_train_vector_svc, X_test_vector_svc, Y_train_svc, Y_test_svc = get_all_data_vectorized(X_train, X_test, Y_train, Y_test, vectorizer_svc)\n",
    "print(X_train_vector_svc.shape)\n",
    "X_train_vector_lr, X_test_vector_lr, Y_train_lr, Y_test_lr = get_all_data_vectorized(X_train, X_test, Y_train, Y_test, vectorizer_lr)\n",
    "print(X_train_vector_lr.shape)\n",
    "\n",
    "final_svc = LinearSVC(class_weight=\"balanced\",\n",
    "                      max_iter=10_000,\n",
    "                      C=3.95)\n",
    "\n",
    "final_lr = LogisticRegression(class_weight=\"balanced\",\n",
    "                              max_iter=10_000,\n",
    "                              C=44)\n",
    "\n",
    "voting_clf_soft = VotingClassifier(estimators=[\n",
    "                                            ('lr', final_lr), \n",
    "                                            # ('nb', final_nb),\n",
    "                                            ('svc', svc_for_vote)\n",
    "                                            ],\n",
    "                                  voting='soft',\n",
    "                                  n_jobs=1,\n",
    "                                  verbose=3)\n",
    "\n",
    "t0 = time()\n",
    "final_svc.fit(X_train_vector_svc, Y_train_svc)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "t0 = time()\n",
    "final_lr.fit(X_train_vector_lr, Y_train_lr)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "# t0 = time()\n",
    "# voting_clf_soft.fit(X_train_vector_svc, Y_train_svc)\n",
    "# print(\"done in %0.3fs\" % (time() - t0))\n",
    "    \n",
    "display_model_scores(final_svc, X_test_vector_svc, Y_test_svc, search=False)\n",
    "display_model_scores(final_lr, X_test_vector_lr, Y_test_lr, search=False)\n",
    "# display_model_scores(voting_clf_soft, X_test_vector_svc, Y_test_svc, search=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc192d1-be1b-400e-a78b-200ad1c21e0c",
   "metadata": {},
   "source": [
    "### --> Preprocessing optimization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f7c47db2-99c5-45a7-a7cc-d4fddb1071fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(pred, window_size, Y_test, threshold):\n",
    "    uni, cpt = np.unique(pred, return_counts=True)\n",
    "    prob_mit = cpt[0]/len(pred)\n",
    "    prob_chi = cpt[1]/len(pred)\n",
    "    new_final_pred = pred.copy()\n",
    "    # Hard smoothing until it converges\n",
    "    while True: \n",
    "        new_final_pred_tmp = hard_smoothing(pred, new_final_pred, window_size, threshold)\n",
    "        if np.array_equiv(new_final_pred_tmp, new_final_pred):\n",
    "            break\n",
    "    new_final_pred = new_final_pred_tmp\n",
    "    # Making sure to delete all solo values\n",
    "    while True: \n",
    "        new_final_pred_tmp = soft_smoothing(new_final_pred)\n",
    "        if np.array_equiv(new_final_pred_tmp, new_final_pred):\n",
    "            break\n",
    "    # Re balance minority class\n",
    "    # new_final_pred = cheat_smoothing(new_final_pred_tmp, add)\n",
    "    # return new_final_pred, float(classification_report(new_final_pred, Y_test)[90:100]) # Trick to get the minority class f1 score\n",
    "    return new_final_pred, f1_score(new_final_pred, Y_test, average=\"binary\")\n",
    "\n",
    "# Smoothing values with a rolling window\n",
    "def hard_smoothing(pred, new_final_pred, window_size, threshold):\n",
    "    for i in range(window_size, len(new_final_pred) - window_size):\n",
    "        neighbors = pred[int(i-window_size/2):int(i+window_size/2)] # Here we need to use pred and now new_final_pred_svc !!!\n",
    "        unique, counts = np.unique(neighbors, return_counts=True)\n",
    "\n",
    "        if len(unique) == 1:\n",
    "            if unique[0] == 1:\n",
    "                unique = np.append(unique,-1)\n",
    "                counts = np.append(counts,0)\n",
    "            else:\n",
    "                unique = np.append(unique,1)\n",
    "                counts = np.append(counts,0)\n",
    "                \n",
    "        # Probability smoothing learning\n",
    "        if counts[0]/(counts[0]+counts[1]) > threshold: # This one seems useless after testing results\n",
    "            new_final_pred[i] = int(unique[0])\n",
    "        else:\n",
    "            new_final_pred[i] = int(unique[1])\n",
    "        if counts[1]/(counts[0]+counts[1]) > threshold: # Learning a threshold there instead of using prob_chi might be an error\n",
    "            new_final_pred[i] = int(unique[1])\n",
    "        else:\n",
    "            new_final_pred[i] = int(unique[0])\n",
    "        \n",
    "    return new_final_pred\n",
    "\n",
    "# Smoothing solo values\n",
    "def soft_smoothing(pred):\n",
    "    for i in range(1, len(pred)-1):\n",
    "        if (pred[i-1] == -1 and pred[i+1] == -1):\n",
    "            pred[i] = -1\n",
    "        elif (pred[i-1] == 1 and pred[i+1] == 1):\n",
    "            pred[i] = 1\n",
    "    return pred\n",
    "\n",
    "# Smoothing tri values\n",
    "def soft_smoothing_3(pred):\n",
    "    for i in range(3, len(pred)-3):\n",
    "        if (pred[i-3:i-2] and pred[i+2:i+3] == -1):\n",
    "            pred[i-1:i+1] = -1\n",
    "        elif (pred[i-3:i-2] == 1 and pred[i+2:i+3] == 1):\n",
    "            pred[i-1:i+1] = 1\n",
    "    return pred\n",
    "\n",
    "# Rebalance our minority class\n",
    "# Seems like this one is useless because the hard_smoothing function does kind of the same job\n",
    "def cheat_smoothing(pred, add):\n",
    "    for _ in range(add):\n",
    "        for i in range(add, len(pred)-add):\n",
    "            if pred[i] == 1 and pred[i+1] == -1:\n",
    "                pred[i] = -1\n",
    "            elif pred[i] == -1 and pred[i+1] == 1:\n",
    "                pred[i+1] = -1\n",
    "    return pred\n",
    "\n",
    "def optimize_postprocessing(preds, Y_test):\n",
    "    maxi = 0\n",
    "    for window_size in tqdm(range(8,13,1)):\n",
    "        for threshold in np.arange(0,1,0.1):\n",
    "            new_preds, score = postprocessing(preds, window_size, Y_test, threshold)\n",
    "            if score > maxi:\n",
    "                print(\"Update score :\", score, \"for ws:\", window_size, \"and threshold:\", threshold)\n",
    "                maxi = score\n",
    "                best_ws = window_size\n",
    "                best_thresh = threshold\n",
    "                best_preds = new_preds\n",
    "    return maxi, best_ws, best_thresh, best_preds\n",
    "\n",
    "def final_postprocessing_test(pred, window_size, threshold):\n",
    "    uni, cpt = np.unique(pred, return_counts=True)\n",
    "    prob_mit = cpt[0]/len(pred)\n",
    "    prob_chi = cpt[1]/len(pred)\n",
    "    new_final_pred = pred.copy()\n",
    "    new_final_pred = soft_smoothing(new_final_pred)\n",
    "    new_final_pred = hard_smoothing(pred, new_final_pred, window_size, threshold)\n",
    "    new_final_pred = soft_smoothing(new_final_pred)\n",
    "    return new_final_pred\n",
    "\n",
    "def final_postprocessing(pred, window_size, threshold):\n",
    "    new_final_pred = pred.copy()\n",
    "    # new_final_pred = soft_smoothing(new_final_pred) # No idea if it's a good idea\n",
    "    # Hard smoothing until it converges\n",
    "    while True: \n",
    "        new_final_pred_tmp = hard_smoothing(pred, new_final_pred, window_size, threshold)\n",
    "        if np.array_equiv(new_final_pred_tmp, new_final_pred):\n",
    "            break\n",
    "    new_final_pred = new_final_pred_tmp\n",
    "    # Making sure to delete all solo values\n",
    "    while True: \n",
    "        new_final_pred_tmp = soft_smoothing(new_final_pred)\n",
    "        if np.array_equiv(new_final_pred_tmp, new_final_pred):\n",
    "            break\n",
    "    new_final_pred = new_final_pred_tmp\n",
    "    return new_final_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50bc47e-c2ec-4e38-90d8-e8fe0d5272c9",
   "metadata": {},
   "source": [
    "## 6. Computing final test predictions after postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfb5c98-951d-480d-a487-e4c6e0405886",
   "metadata": {},
   "source": [
    "### --> Find our best model for the smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1df7d99-0a65-480d-86cc-da4ba7df96dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make crossvalidation to get better parameter estimation\n",
    "# The window should slide on both side and compare the values\n",
    "# Test before hard smoothing :\n",
    "# while True: \n",
    "#         new_final_pred_tmp = soft_smoothing(new_final_pred)\n",
    "#         if np.array_equiv(new_final_pred_tmp, new_final_pred):\n",
    "#             break\n",
    "#     new_final_pred = new_final_pred_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e60970e1-a68f-4250-b78b-cc55563372cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update score : 0.9492574257425742 for ws: 8 and threshold: 0.0\n",
      "Update score : 0.9531239212978944 for ws: 8 and threshold: 0.2\n",
      "Update score : 0.9609153785452352 for ws: 8 and threshold: 0.30000000000000004\n",
      "Update score : 0.9703969763128859 for ws: 8 and threshold: 0.4\n",
      "Update score : 0.9762970014278914 for ws: 8 and threshold: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:17<00:11,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update score : 0.9768339768339769 for ws: 11 and threshold: 0.6000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:23<00:05,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update score : 0.9776117616071642 for ws: 12 and threshold: 0.6000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:28<00:00,  5.75s/it]\n"
     ]
    }
   ],
   "source": [
    "X_test_vector_final = X_test_vector_svc\n",
    "Y_test_final = Y_test_svc\n",
    "\n",
    "maxi_svc, best_ws_svc, best_thresh_svc, best_preds_svc = optimize_postprocessing(final_svc.predict(X_test_vector_final), Y_test_final)\n",
    "\n",
    "# print(\"===========================================================================================\")\n",
    "\n",
    "# maxi_soft, best_ws_soft, best_thresh_soft, best_preds_soft = optimize_postprocessing(voting_clf_soft.predict(X_test_vector_final), Y_test_final) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ffbd78-e550-43b4-a888-86e6ff4becf8",
   "metadata": {},
   "source": [
    "### --> Displaying our f1 score after postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92b9ee14-f1f1-4e06-86f5-460502cbd313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: 0.976384755687818 12 0.6000000000000001 [1 1 1 ... 1 1 1]\n",
      "------------------------------before------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      0.51      0.55      1364\n",
      "           1       0.93      0.95      0.94     10119\n",
      "\n",
      "    accuracy                           0.90     11483\n",
      "   macro avg       0.76      0.73      0.75     11483\n",
      "weighted avg       0.89      0.90      0.90     11483\n",
      "\n",
      "------------------------------after------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.85      0.77       969\n",
      "           1       0.99      0.97      0.98     10514\n",
      "\n",
      "    accuracy                           0.96     11483\n",
      "   macro avg       0.85      0.91      0.87     11483\n",
      "weighted avg       0.96      0.96      0.96     11483\n",
      "\n",
      "===========================================================================================\n",
      "best parameters: 0.9761402836335761 12 0.6000000000000001 [1 1 1 ... 1 1 1]\n",
      "------------------------------before------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      0.54      0.56      1258\n",
      "           1       0.94      0.95      0.95     10225\n",
      "\n",
      "    accuracy                           0.91     11483\n",
      "   macro avg       0.76      0.75      0.75     11483\n",
      "weighted avg       0.90      0.91      0.91     11483\n",
      "\n",
      "------------------------------after------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.86      0.76       931\n",
      "           1       0.99      0.97      0.98     10552\n",
      "\n",
      "    accuracy                           0.96     11483\n",
      "   macro avg       0.84      0.91      0.87     11483\n",
      "weighted avg       0.96      0.96      0.96     11483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"best parameters:\", maxi_svc, best_ws_svc, best_thresh_svc, best_preds_svc)\n",
    "print(\"------------------------------before------------------------------\")\n",
    "print(classification_report(final_svc.predict(X_test_vector_final), Y_test_final))\n",
    "print(\"------------------------------after------------------------------\")\n",
    "print(classification_report(best_preds_svc, Y_test_final))\n",
    "\n",
    "# print(\"===========================================================================================\")\n",
    "\n",
    "# print(\"best parameters:\", maxi_soft, best_ws_soft, best_thresh_soft, best_preds_soft)\n",
    "# print(\"------------------------------before------------------------------\")\n",
    "# print(classification_report(voting_clf_soft.predict(X_test_vector_final), Y_test_final))\n",
    "# print(\"------------------------------after------------------------------\")\n",
    "# print(classification_report(best_preds_soft, Y_test_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "845852fd-f4e1-4774-b7b4-19ad8ee91d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with svc : 0.77, 0.98, 0.96 on test\n",
    "# with soft : 0.75, 0.98, 0.96 on test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f8ac6a-da91-4894-ac80-cdeccc44d146",
   "metadata": {},
   "source": [
    "### --> Results after postprocessing (svc exemple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cec717d-adf0-495e-a5f3-b67232489bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------before------------------------------\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1\n",
      "  1  1  1  1 -1  1  1  1 -1  1  1  1  1  1  1  1 -1  1  1  1  1  1 -1  1\n",
      "  1  1  1  1  1  1  1  1 -1  1 -1  1  1 -1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1 -1  1  1 -1  1  1 -1  1 -1  1  1 -1  1\n",
      " -1  1 -1  1 -1  1 -1  1 -1 -1 -1 -1  1  1  1 -1 -1 -1  1 -1  1 -1  1  1\n",
      "  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1\n",
      "  1 -1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1 -1 -1  1  1\n",
      " -1  1 -1 -1 -1  1 -1  1 -1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1 -1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1 -1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      "------------------------------after------------------------------\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------before------------------------------\")\n",
    "print(final_svc.predict(X_test_vector_final)[:500])\n",
    "print(\"------------------------------after------------------------------\")\n",
    "print(final_postprocessing(final_svc.predict(X_test_vector_final)[:500], best_ws_svc, best_thresh_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d3a07c-9e6f-4574-8bea-fc170353d177",
   "metadata": {},
   "source": [
    "### --> Training on whole dataset now that we learnt the best postprocessing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa9f0eac-7591-4d01-83ee-6225f115de0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./data/corpus.tache1.learn.utf8\"\n",
    "alltxts_train_final, alllabs_train_final = load_pres(fname)\n",
    "X_train_final = np.array(alltxts_train_final)\n",
    "Y_train_final = np.array(alllabs_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42c22746-6c7e-440e-bf83-8e83703c055d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done in 1.992s\n",
      "[Voting] ....................... (1 of 2) Processing lr, total=   7.5s\n",
      "[LibSVM][Voting] ...................... (2 of 2) Processing svc, total=25.9min\n",
      " done in 1562.248s\n"
     ]
    }
   ],
   "source": [
    "X_final_vector_svc = vectorizer_svc.fit_transform(X_train_final)\n",
    "\n",
    "t0 = time()\n",
    "final_svc.fit(X_final_vector_svc,  Y_train_final)\n",
    "print(\" done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "# t0 = time()\n",
    "# voting_clf_soft.fit(X_final_vector_svc,  Y_train_final)\n",
    "# print(\" done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fad3fe7-69bc-4fef-bd7e-7e78d5db5346",
   "metadata": {},
   "source": [
    "### --> Computing final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0806c53a-775c-4d16-8488-dc1522df267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./data/corpus.tache1.test.utf8\"\n",
    "alltxts_test_final, _ = load_pres(fname)\n",
    "X_test_final = np.array(alltxts_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0f97849-e248-4cda-9887-f6d97d498237",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vector_svc = vectorizer_svc.transform(X_test_final)\n",
    "final_pred_svc = final_svc.predict(X_test_vector_svc)\n",
    "\n",
    "# X_test_vector_svc = vectorizer_svc.transform(X_test_final)\n",
    "# final_pred_soft = voting_clf_soft.predict(X_test_vector_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a476929-aa72-46ca-84af-1f202bb415a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_final_pred_svc = final_postprocessing(final_pred_svc, best_ws_svc, best_thresh_svc)\n",
    "\n",
    "# new_final_pred_soft = final_postprocessing(final_pred_soft, best_ws_soft, best_thresh_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f8526ef-a6ca-4adc-ab8b-50b83b8eb5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27162,)\n",
      "(27162,)\n"
     ]
    }
   ],
   "source": [
    "print(new_final_pred_svc.shape)\n",
    "\n",
    "# print(new_final_pred_soft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14ea84fb-7628-4dd1-be6f-fe59bdaf2eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE:\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1 -1  1 -1  1  1\n",
      " -1 -1 -1  1  1 -1  1 -1 -1  1  1 -1  1 -1 -1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1 -1 -1  1  1  1  1 -1  1  1 -1  1  1  1 -1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1 -1 -1  1  1  1  1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1 -1  1  1  1  1  1 -1 -1 -1  1 -1  1 -1 -1 -1  1 -1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1\n",
      " -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      "AFTER:\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "print(\"BEFORE:\")\n",
    "print(final_pred_svc[500:1000])\n",
    "print(\"AFTER:\")\n",
    "print(new_final_pred_svc[500:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "207dd213-2111-4e0a-af6b-3e0319b80bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1 -1 -1 -1 -1  1  1 -1  1  1 -1  1 -1  1 -1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 -1 -1 -1  1  1  1 -1 -1  1 -1  1\n",
      "  1  1  1  1  1 -1  1  1 -1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1 -1  1  1  1  1 -1  1  1  1 -1  1 -1  1 -1 -1  1 -1 -1 -1 -1 -1 -1\n",
      "  1 -1  1 -1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1 -1 -1 -1  1  1  1  1 -1 -1\n",
      "  1 -1 -1 -1 -1 -1 -1 -1  1 -1  1 -1  1  1  1  1  1  1  1 -1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1\n",
      "  1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      "[ 1  1  1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "# print(final_pred_soft[:500])\n",
    "# print(new_final_pred_soft[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4619f0ab-4259-4a93-9f67-24ffd2d1a638",
   "metadata": {},
   "outputs": [],
   "source": [
    "save=False\n",
    "if save :\n",
    "    f = open(\"../TME1/output/president_pred_svc.txt\", \"w\")\n",
    "    preds = \"\"\n",
    "    for i in range(len(new_final_pred_svc)):\n",
    "        preds += str(new_final_pred_svc[i]) + \"\\n\"\n",
    "    f.write(preds)\n",
    "    f.close()\n",
    "\n",
    "    f = open(\"../TME1/output/president_pred_soft.txt\", \"w\")\n",
    "    preds = \"\"\n",
    "    for i in range(len(new_final_pred_soft)):\n",
    "        preds += str(new_final_pred_soft[i]) + \"\\n\"\n",
    "    f.write(preds)\n",
    "    f.close()\n",
    "    \n",
    "    f = open(\"../TME1/output/president_pred_soft_3.txt\", \"w\")\n",
    "    preds = \"\"\n",
    "    for i in range(len(new_final_pred_soft_)):\n",
    "        preds += str(new_final_pred_soft_[i]) + \"\\n\"\n",
    "    f.write(preds)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a548c-93f9-4d34-bfc4-d2fcf82b93f1",
   "metadata": {},
   "source": [
    "## 7. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ba8d28c-1fdf-43e1-aab3-5a67d521014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST PERFORMANCE SVC : 79% ACC ON TEST F1_MIT \n",
    "# BEST PERFORMANCE SOFT : 78% ACC ON TEST F1_MIT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
