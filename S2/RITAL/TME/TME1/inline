{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9daec5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipython\n",
    "# !pip install nbconvert\n",
    "# !jupyter nbconvert --to python classifDoc_2021.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "156881a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb9ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données:\n",
    "def load_pres(fname):\n",
    "    alltxts = []\n",
    "    alllabs = []\n",
    "    s=codecs.open(fname, 'r','utf-8') # pour régler le codage\n",
    "    while True:\n",
    "        txt = s.readline()\n",
    "        if(len(txt))<5:\n",
    "            break\n",
    "        lab = re.sub(r\"<[0-9]*:[0-9]*:(.)>.*\",\"\\\\1\",txt)\n",
    "        txt = re.sub(r\"<[0-9]*:[0-9]*:.>(.*)\",\"\\\\1\",txt)\n",
    "        if lab.count('M') >0:\n",
    "            alllabs.append(-1)\n",
    "        else: \n",
    "            alllabs.append(1)\n",
    "        alltxts.append(txt)\n",
    "    return alltxts,alllabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c0ebcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"data/corpus.tache1.learn.utf8\"\n",
    "\n",
    "alltxts, alllabs = load_pres(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3624f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(alltxts),len(alllabs))\n",
    "print(alltxts[0])\n",
    "print(alllabs[0])\n",
    "print(alltxts[-1])\n",
    "print(alllabs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b1c2657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_movies(path2data): # 1 classe par répertoire\n",
    "#     alltxts = [] # init vide\n",
    "#     labs = []\n",
    "#     cpt = 0\n",
    "#     for cl in os.listdir(path2data): # parcours des fichiers d'un répertoire\n",
    "#         for f in os.listdir(path2data+cl):\n",
    "#             txt = open(path2data+cl+'/'+f).read()\n",
    "#             alltxts.append(txt)\n",
    "#             labs.append(cpt)\n",
    "#         cpt+=1 # chg répertoire = cht classe\n",
    "#     return alltxts,labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf9f543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"movies1000/\"\n",
    "\n",
    "# alltxts,alllabs = load_movies(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca982aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(alltxts),len(alllabs))\n",
    "# print(alltxts[0])\n",
    "# print(alllabs[0])\n",
    "# print(alltxts[-1])\n",
    "# print(alllabs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6748e8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import *\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "def preprocessing(X):\n",
    "    res = []\n",
    "    for doc in X:\n",
    "        punc = string.punctuation  # recupération de la ponctuation\n",
    "        punc += '\\n\\r\\t'\n",
    "        doc = doc.translate(str.maketrans(punc, ' ' * len(punc)))\n",
    "        doc = unicodedata.normalize('NFD', doc).encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "        doc = doc.lower()\n",
    "        doc = re.sub('[0-9]+', '', doc)\n",
    "        res.append(doc)\n",
    "    return np.array(res)\n",
    "\n",
    "def formal(X):\n",
    "    stemmer = SnowballStemmer(language='french')\n",
    "#     nltk.download('stopwords')\n",
    "    res = []\n",
    "    stop = stopwords.words('french')\n",
    "    for doc in X:\n",
    "        new_doc = \"\"\n",
    "        for w in doc.split():\n",
    "            if w not in stop:\n",
    "                new_doc += w + \" \"\n",
    "        new_doc = [stemmer.stem(X) for X in new_doc.split()]\n",
    "        new_doc = \" \".join(new_doc)\n",
    "        res.append(new_doc)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec8abdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(alltxts[:1000])\n",
    "Y = np.array(alllabs[:1000])\n",
    "        \n",
    "print(X[0])\n",
    "X_preprocess = preprocessing(X)\n",
    "print(X_preprocess[0])\n",
    "X_train = formal(X_preprocess)\n",
    "print(\"\\n\",X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5d996cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "def flatten(A):\n",
    "    rt = []\n",
    "    for i in A:\n",
    "        if isinstance(i,list): \n",
    "            rt.extend(flatten(i))\n",
    "        else: \n",
    "            rt.append(i)\n",
    "    return rt\n",
    "\n",
    "words = \"\".join(flatten(X))\n",
    "wordcloud = WordCloud(background_color='white', max_words=100).generate(words)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# vectorizer = CountVectorizer()\n",
    "# vector = vectorizer.fit_transform(X).toarray()\n",
    "# names = vectorizer.get_feature_names()\n",
    "# print(vector.shape)\n",
    "# n, m = vector.shape\n",
    "# vector = np.where(vector == 0, 0, 1)\n",
    "# sums = vector.sum(axis=0)\n",
    "# res = np.sort(sums)[sums.size-100:]\n",
    "# print(res)\n",
    "# words = \"\".join(flatten(X))\n",
    "# wordcloud = WordCloud(background_color='white', max_words=100).generate(words)\n",
    "# plt.imshow(wordcloud)\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d6661f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = \"\".join(flatten(X_preprocess[:1000]))\n",
    "unique_words, count = np.unique(words.split(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37702abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = np.where(count > 100, 100, count)\n",
    "count = np.log(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "874533bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words, count = np.unique(words.split(), return_counts=True)\n",
    "\n",
    "count_sort_ind = np.argsort(count)\n",
    "unique_words = unique_words[count_sort_ind]\n",
    "count = np.sort(count)\n",
    "print(count)\n",
    "print(unique_words)\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(np.arange(len(count)),np.log(count))\n",
    "plt.title(\"Log du nombre d'apparition / mot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01a5ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words, count = np.unique(words.split(), return_counts=True)\n",
    "\n",
    "count_sort_ind = np.argsort(count)\n",
    "unique_words = unique_words[count_sort_ind]\n",
    "count = np.sort(count)\n",
    "print(count)\n",
    "print(unique_words)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(unique_words[len(count)-25:],count[len(count)-25:])\n",
    "plt.title(\"Nombre d'apparition / mot les plus frequent\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f931df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut le faire assez facilemment avec sklearn\n",
    "# Cela donne plus de contexte a nos mots mais les probabilites de tri-grammes vont etre tres faible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f5eff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cela prend beaucoup de temps avec des donnees textuels car nous avons un grand nombre de variables\n",
    "# Cela depend fortement de la taille du vocabulaire\n",
    "# La validation est tres pratique car on train nos modeles sur toutes les donnes contrairement au split\n",
    "# Ici on utlise le split car bien plus rapide, on pourra envisager la validation croisee quand on aura deja fait un choix au niveau des modeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d166d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.naive_bayes as nb\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model as lin\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "422b4f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X):\n",
    "    res = []\n",
    "    punc = string.punctuation  \n",
    "    punc += '\\n\\r\\t'\n",
    "    for doc in X:    \n",
    "        doc = doc.translate(str.maketrans(punc, ' ' * len(punc)))\n",
    "        doc = unicodedata.normalize('NFD', doc).encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "        doc = doc.lower()\n",
    "        doc = re.sub('[0-9]+', '', doc)\n",
    "        res.append(doc)\n",
    "    return np.array(res)\n",
    "\n",
    "def formal(X):\n",
    "    stemmer = SnowballStemmer(language='french')\n",
    "#     nltk.download('stopwords')\n",
    "    res = []\n",
    "    stop = stopwords.words('french')\n",
    "    for doc in X:\n",
    "        new_doc = \"\"\n",
    "        for w in doc.split():\n",
    "            if w not in stop:\n",
    "                new_doc += w + \" \"\n",
    "        new_doc = [stemmer.stem(X) for X in new_doc.split()]\n",
    "        new_doc = \" \".join(new_doc)\n",
    "        res.append(new_doc)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f1c0f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"data/corpus.tache1.learn.utf8\"\n",
    "alltxts_test, alllabs_test = load_pres(fname)\n",
    "X = np.array(alltxts)\n",
    "Y = np.array(alllabs)\n",
    "\n",
    "fname_test = \"data/corpus.tache1.test.utf8\"\n",
    "alltxts_test, alllabs_test = load_pres(fname_test)\n",
    "X_test = np.array(alltxts_test)\n",
    "Y_test = np.array(alllabs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ecdb7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"SVC1\", \"SVC0.8\", \"SVC0.6\", \"NB\", \"LR\"]\n",
    "\n",
    "def train_models_and_get_acc(X_train, X_test, Y_train, Y_test, display):\n",
    "    print(\"--> SVC reg=1.0 :\")\n",
    "    clf = svm.LinearSVC(class_weight=\"balanced\", C=1.0)\n",
    "    clf.fit(X_train, Y_train) \n",
    "    acc1 = np.round(clf.score(X_test, Y_test)*100, 2)\n",
    "    print(\"Acc : \", acc1, \" %\")\n",
    "    if display : display_infos(clf, X_test, Y_test)\n",
    "    \n",
    "    print(\"--> SVC reg=0.8 :\")\n",
    "    clf = svm.LinearSVC(class_weight=\"balanced\", C=0.8)\n",
    "    clf.fit(X_train, Y_train) \n",
    "    acc2 = np.round(clf.score(X_test, Y_test)*100, 2)\n",
    "    print(\"Acc : \", acc2, \" %\")\n",
    "    if display : display_infos(clf, X_test, Y_test)\n",
    "    \n",
    "    print(\"--> SVC reg=0.6 :\")\n",
    "    clf = svm.LinearSVC(class_weight=\"balanced\", C=0.6)\n",
    "    clf.fit(X_train, Y_train) \n",
    "    acc3 = np.round(clf.score(X_test, Y_test)*100, 2)\n",
    "    print(\"Acc : \", acc3, \" %\")\n",
    "    if display : display_infos(clf, X_test, Y_test)\n",
    "    \n",
    "    print(\"--> NB :\")\n",
    "    clf = nb.MultinomialNB()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    acc4 = np.round(clf.score(X_test, Y_test)*100, 2)\n",
    "    print(\"Acc : \", acc4, \" %\")\n",
    "    if display : display_infos(clf, X_test, Y_test)\n",
    "    \n",
    "    print(\"--> LR :\")\n",
    "    clf = lin.LogisticRegression(class_weight=\"balanced\")\n",
    "    clf.fit(X_train, Y_train)\n",
    "    acc5 = np.round(clf.score(X_test, Y_test)*100, 2)\n",
    "    print(\"Acc : \", acc5, \" %\") \n",
    "    if display : display_infos(clf, X_test, Y_test)\n",
    "    \n",
    "    return [acc1, acc2, acc3, acc4, acc5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b72d8c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_infos(clf, X_test, Y_test):\n",
    "    # Check le nombre de predictions pour chaque label\n",
    "    predictions = clf.predict(X_test)\n",
    "    unique, counts = np.unique(predictions, return_counts=True)\n",
    "    print(\"/!\\ Prediction counts for label \", unique, \" --> \", counts)\n",
    "    # Check le nombre de predictions pour chaque label\n",
    "    unique, counts = np.unique(Y_test, return_counts=True)\n",
    "    print(\"/!\\ Ground truth counts for label \", unique, \" --> \", counts)\n",
    "    # Check la precision du label en inferiorite\n",
    "    acc = get_inf_acc(predictions, Y_test)\n",
    "    print(\"/!\\ Accuracy of inferior label :\", acc, \"%\")\n",
    "    # Check la precision du label en superiorite\n",
    "    acc = get_sup_acc(predictions, Y_test)\n",
    "    print(\"/!\\ Accuracy of superior label :\", acc, \"%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a96faa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inf_acc(predictions, Y_test):\n",
    "    idx_inf = np.where(predictions==-1, True, False)\n",
    "    tmp_pred = predictions[idx_inf]\n",
    "    tmp_real = Y_test[idx_inf]\n",
    "    cpt = 0\n",
    "    for i in range(len(tmp_pred)):\n",
    "        if tmp_pred[i] == tmp_real[i]:\n",
    "            cpt += 1\n",
    "    return np.round((cpt/len(tmp_pred))*100, 2)\n",
    "\n",
    "def get_sup_acc(predictions, Y_test):\n",
    "    idx_inf = np.where(predictions==1, True, False)\n",
    "    tmp_pred = predictions[idx_inf]\n",
    "    tmp_real = Y_test[idx_inf]\n",
    "    cpt = 0\n",
    "    for i in range(len(tmp_pred)):\n",
    "        if tmp_pred[i] == tmp_real[i]:\n",
    "            cpt += 1\n",
    "    return np.round((cpt/len(tmp_pred))*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce24f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data_vectorized(X, X_test, Y, Y_test, vectorizer, transformer=None):\n",
    "    X_vector = vectorizer.fit_transform(X)\n",
    "    if transformer is not None:\n",
    "        transformer = transformer.fit(X_vector)\n",
    "        X_final = transformer.transform(X_vector)\n",
    "    else:\n",
    "        X_final = X_vector\n",
    "    X_test_vector = vectorizer.transform(X_test)\n",
    "    return X_final, X_test_vector, Y, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb681798",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_models_name = [\"vanilla\", \"ngram22\", \"maxfeat500\", \"stopwords\", \"min2\", \"min3\", \"min4\", \"max0.9\", \"max0.8\", \"max0.7\", \"min3_max0.7\", \"ngram22_maxfeat500\", \"tfidfvectorizer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9365d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_database(X, X_test, Y, Y_test):\n",
    "    database = []\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train_vector, Y_test_vector, Y_train, Y_test = get_all_data_vectorized(X, X_test, Y, Y_test, vectorizer)\n",
    "    database.append([X_train_vector, Y_test_vector, Y_train, Y_test])\n",
    "    \n",
    "    vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "    X_train_vector, Y_test_vector, Y_train, Y_test = get_all_data_vectorized(X, X_test, Y, Y_test, vectorizer)\n",
    "    database.append([X_train_vector, Y_test_vector, Y_train, Y_test])\n",
    "    \n",
    "    vectorizer = CountVectorizer(max_features=500)\n",
    "    X_train_vector, Y_test_vector, Y_train, Y_test = get_all_data_vectorized(X, X_test, Y, Y_test, vectorizer)\n",
    "    database.append([X_train_vector, Y_test_vector, Y_train, Y_test])\n",
    "    \n",
    "    stop = stopwords.words('french')\n",
    "    vectorizer = CountVectorizer(stop_words=stop)\n",
    "    X_train_vector, Y_test_vector, Y_train, Y_test = get_all_data_vectorized(X, X_test, Y, Y_test, vectorizer)\n",
    "    database.append([X_train_vector, Y_test_vector, Y_train, Y_test])\n",
    "    \n",
    "    vectorizer = CountVectorizer(min_df=2)\n",
    "    X_train_vector, Y_test_vector, Y_train, Y_test = get_all_data_vectorized(X, X_test, Y, Y_test, vectorizer)\n",
    "    database.append([X_train_vector, Y_test_vector, Y_train, Y_test])\n",
    "    vectorizer = CountVectorizer(min_df=3)\n",
    "    X_train_vector, Y_test_vector, Y_train, Y_test = get_all_data_vectorized(X, X_test, Y, Y_test, vectorizer)\n",
    "    database.append([X_train_vector, Y_test_vector, Y_train, Y_test])\n",
    "    vectorizer = CountVectorizer(min_df=4)\n",
    "    X_train_vector, Y_test_vector, Y_train, Y_test = get_all_data_vectorized(X, X_test, Y, Y_test, vectorizer)\n",
    "    database.append([X_train_vector, Y_test_vector, Y_train, Y_test])\n",
    "    \n",
    "    vectorizer = CountVectorizer(max_df=0.9)\n",
    "    X_train_vector, Y_test_vector, Y_train, Y_test = get_all_data_vectorized(X, X_test, Y, Y_test, vectorizer)\n",
    "    database.append([X_train_vector, Y_test_vector, Y_train, Y_test])\n",
    "    vectorizer = CountVectorizer(max_df=0.8)\n",
    "    X_train_vector, Y_test_vector, Y_train, Y_test = get_all_data_vectorized(X, X_test, Y, Y_test, vectorizer)\n",
    "    database.append([X_train_vector, Y_test_vector, Y_train, Y_test])\n",
    "    vectorizer = CountVectorizer(max_df=0.7)\n",
    "    X_train_vector, Y_test_vector, Y_train, Y_test = get_all_data_vectorized(X, X_test, Y, Y_test, vectorizer)\n",
    "    database.append([X_train_vector, Y_test_vector, Y_train, Y_test])\n",
    "    \n",
    "    vectorizer = CountVectorizer(max_df=0.7, min_df=3)\n",
    "    X_train_vector, Y_test_vector, Y_train, Y_test = get_all_data_vectorized(X, X_test, Y, Y_test, vectorizer)\n",
    "    database.append([X_train_vector, Y_test_vector, Y_train, Y_test])\n",
    "\n",
    "    vectorizer = CountVectorizer(ngram_range=(2, 2), max_features=500)\n",
    "    X_train_vector, Y_test_vector, Y_train, Y_test = get_all_data_vectorized(X, X_test, Y, Y_test, vectorizer)\n",
    "    database.append([X_train_vector, Y_test_vector, Y_train, Y_test])\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train_vector, Y_test_vector, Y_train, Y_test = get_all_data_vectorized(X, X_test, Y, Y_test, vectorizer)\n",
    "    database.append([X_train_vector, Y_test_vector, Y_train, Y_test])\n",
    "    \n",
    "    return np.array(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d739be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(db, display=False):\n",
    "    metrics = []\n",
    "    for cpt, element in enumerate(db):\n",
    "        print(\"---------------- Testing model : \", database_models_name[cpt], \" ----------------\")\n",
    "        X_train, X_test, Y_train, Y_test = element\n",
    "        metrics.append(train_models_and_get_acc(X_train, X_test, Y_train, Y_test, display))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ba3bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5277801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = build_database(X, X_test, Y, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fd1397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = simulation(db, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a00aefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = np.array(metrics)\n",
    "# n_data, n_model = metrics.shape\n",
    "# print(\"--> Simulation done on\", n_data, \"different data processing and\", n_model, \"different models\")\n",
    "# print(\"--> Metrics :\\n\", metrics)\n",
    "# print(\"--> Best accuracy :\", metrics.max(), \"from data model : '\", database_models_name[metrics.argmax()//n_model], \"' and model :'\", model_names[metrics.argmax()%n_model], \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d90c497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fc0d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"SVC\", \"NB\", \"LR\"]\n",
    "\n",
    "def train_models_and_get_acc_sklearn(X_train, X_test, Y_train, Y_test, display):\n",
    "    print(\"--> SVC :\")\n",
    "    svc = svm.SVC()\n",
    "    parameters = {'kernel':(['linear']), \n",
    "                  'C':[0.5, 1, 2, 5], \n",
    "                  'class_weight':(['balanced'])}\n",
    "    clf = GridSearchCV(svc, parameters, cv=5, verbose=True, n_jobs=-1)\n",
    "    best_clf = clf.fit(X_train, Y_train)\n",
    "    acc1 = np.round(best_clf.score(X_test, Y_test)*100, 2)\n",
    "    print(\"Acc : \", acc1, \" %\")\n",
    "    if display : \n",
    "        display_infos(clf, X_test, Y_test)\n",
    "        performance(best_clf)\n",
    "    \n",
    "    print(\"--> NB :\")\n",
    "    clf = nb.MultinomialNB()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    acc2 = np.round(clf.score(X_test, Y_test)*100, 2)\n",
    "    print(\"Acc : \", acc2, \" %\")\n",
    "    if display : display_infos(clf, X_test, Y_test)\n",
    "    \n",
    "    print(\"--> LR :\")\n",
    "    lr = LogisticRegression()\n",
    "    parameters = {'max_iter' : [2000],\n",
    "                  'penalty' : ['l1', 'l2'],\n",
    "                  'C' : np.logspace(-4, 4, 20),\n",
    "                  'solver' : ['liblinear'],\n",
    "                  'class_weight':(['balanced'])}\n",
    "    clf = GridSearchCV(lr, parameters, cv=5, verbose=True, n_jobs=-1)\n",
    "    best_clf = clf.fit(X_train,Y_train)\n",
    "    acc3 = np.round(clf.score(X_test, Y_test)*100, 2)\n",
    "    print(\"Acc : \", acc3, \" %\") \n",
    "    if display : \n",
    "        display_infos(clf, X_test, Y_test)\n",
    "        performance(best_clf)\n",
    "    \n",
    "    return [acc1, acc2, acc3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccc64bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_sklearn(db, display=False):\n",
    "    metrics = []\n",
    "    for cpt, element in enumerate(db):\n",
    "        print(\"---------------- Testing model : \", database_models_name[cpt], \" ----------------\")\n",
    "        X_train, X_test, Y_train, Y_test = element\n",
    "        metrics.append(train_models_and_get_acc_sklearn(X_train, X_test, Y_train, Y_test, display))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94348bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(clf):\n",
    "    print('Best Score: ' + str(clf.best_score_))\n",
    "    print('Best Parameters: ' + str(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "550e2bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = build_database(X, X_test, Y, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8dddc978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = simulation_sklearn(db, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7200e185",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 10_000 # Taille des data pour le grid search (MAX = 57400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44931885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer()),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        (\"clf\", svm.SVC()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    \"vect__min_df\": (0, 1, 2, 3),\n",
    "    \"vect__max_df\": (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 1000, 2000, 3000),\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2), (1,3)),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': (None, 'l1', 'l2'),\n",
    "    'clf__class_weight':(['balanced']),\n",
    "    'clf__C': (np.arange(0, 1, 0.1)),\n",
    "    'clf__kernel':(['linear'])\n",
    "                         \n",
    "    # \"clf__max_iter\": (20,)\n",
    "    # \"clf__alpha\": (0.00001, 0.000001),\n",
    "    # \"clf__penalty\": (\"l2\", \"elasticnet\"),\n",
    "    # 'clf__max_iter': (10, 50, 80),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8cf4f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search = GridSearchCV(pipeline, parameters, n_jobs=8, verbose=3, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf63a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_select, Y_select = X[:test_size], Y[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5e259a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from time import time\n",
    "\n",
    "# t0 = time()\n",
    "# grid_search.fit(list(X_select), list(Y_select))\n",
    "# print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "458d78bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_parameters = grid_search.best_estimator_.get_params()\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#     print(\"--->%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1bcca630",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"data/corpus.tache1.learn.utf8\"\n",
    "alltxts_test, alllabs_test = load_pres(fname)\n",
    "X = np.array(alltxts)\n",
    "Y = np.array(alllabs)\n",
    "\n",
    "fname_test = \"data/corpus.tache1.test.utf8\"\n",
    "alltxts_test, alllabs_test = load_pres(fname_test)\n",
    "X_test = np.array(alltxts_test)\n",
    "Y_test = np.array(alllabs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "650f147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer(use_idf=True, \n",
    "                               norm=\"l2\")\n",
    "vectorizer = CountVectorizer(max_df=0.75, \n",
    "                             min_df=3, \n",
    "                             max_features=None, \n",
    "                             ngram_range=(1,2)\n",
    "                            )\n",
    "\n",
    "X_train_vector, X_test_vector, Y_train, Y_test = get_all_data_vectorized(X, X_test, Y, Y_test, vectorizer, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "38cde27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Avec parametres : \", X_train_vector.shape[1])\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "test, _, _, _ = get_all_data_vectorized(X, X_test, Y, Y_test, vectorizer)\n",
    "print(\"Sans parametres :\", test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "644abe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En fait le premier grid search le fait deja (je crois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9869395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_select, Y_select = X_train_vector[:test_size], Y_train[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2c15a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc = svm.SVC()\n",
    "# parameters = {'kernel':(['linear']), \n",
    "#               'C':np.arange(0, 1, 0.1), \n",
    "#               'class_weight':(['balanced'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8aff454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t0 = time()\n",
    "# clf = GridSearchCV(svc, parameters, n_jobs=8, cv=5, verbose=3)\n",
    "# best_clf = clf.fit(X_select, Y_select)\n",
    "# print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a13f9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_parameters = clf.best_estimator_.get_params()\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#     print(\"--->%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9bc47097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_size = 10_000\n",
    "\n",
    "# X_select, Y_select = X_train_vector[:test_size], Y_train[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a0db84ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal_model = svm.SVC(C=0.3, \n",
    "#               class_weight=\"balanced\", \n",
    "#               kernel=\"linear\")\n",
    "# optimal_model.fit(X_select, Y_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "85753314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_size = 10_000\n",
    "\n",
    "# X_select, Y_select = X_test_vector[:test_size], Y_test[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97e4b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = np.round(optimal_model.score(X_select, Y_select)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f19dce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Acc : \", acc, \" %\")\n",
    "# display_infos(optimal_model, X_select, Y_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b72d851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mauvais résultat car il faut faire tt l'entrainement après avoir balance le dataset.\n",
    "# Si on ne fait pas ca dans ce sens, les gridsearch qui "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96bfd0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def naive_balancing(X, Y):\n",
    "    label, count = np.unique(Y, return_counts=True)\n",
    "\n",
    "    idx_pos = np.where(Y == 1, True, False)\n",
    "    Y_pos = Y[idx_pos]\n",
    "    Y_pos = Y_pos[:count.min()]\n",
    "\n",
    "    idx_neg = np.where(Y == -1, True, False)\n",
    "    Y_neg = Y[idx_neg]\n",
    "\n",
    "    new_Y = np.concatenate((Y_pos, Y_neg))\n",
    "    new_X = np.concatenate((X[:count.min()], X[idx_neg]))\n",
    "    \n",
    "    tmp = list(zip(new_X, new_Y))\n",
    "    random.shuffle(tmp)\n",
    "    new_X, new_Y = zip(*tmp)\n",
    "    \n",
    "    label, count = np.unique(new_Y, return_counts=True)\n",
    "    print(label, count)\n",
    "\n",
    "    return new_X, new_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc500bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X, new_Y = naive_balancing(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f94a0a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 5_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ba5a81ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer()),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        (\"clf\", svm.SVC()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "sw = stopwords.words('french')\n",
    "\n",
    "weights = np.linspace(0.0, 1.0, 200)\n",
    "\n",
    "parameters = {\n",
    "    \"vect__min_df\": (0, 1, 2),\n",
    "    \"vect__max_df\": (0.25, 0.5, 0.75, 1.0),\n",
    "    \"vect__ngram_range\": [(1, 2), (2,2)],\n",
    "    'vect__max_features': (None, 10_000),\n",
    "    \"vect__strip_accents\": ([\"ascii\"]),\n",
    "    \"vect__stop_words\": ([sw]),\n",
    "    \n",
    "    'tfidf__use_idf': ([True]),\n",
    "    'tfidf__norm': ([None]),\n",
    "    \n",
    "    'clf__C': (np.arange(0, 0.6, 0.2)),\n",
    "    'clf__class_weight':(\"balanced\", [{0:x, 1:1.0-x} for x in weights]),\n",
    "    'clf__kernel':(['linear'])\n",
    "                         \n",
    "    # \"clf__max_iter\": (20,)\n",
    "    # \"clf__alpha\": (0.00001, 0.000001),\n",
    "    # \"clf__penalty\": (\"l2\", \"elasticnet\"),\n",
    "    # 'clf__max_iter': (10, 50, 80),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ac658ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, \n",
    "                           parameters, \n",
    "                           scoring=\"roc_auc\", # test \"f1\"\n",
    "                           n_jobs=8, \n",
    "                           verbose=3, \n",
    "                           cv=5,\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3335cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_select, Y_select = X[:test_size], Y[:test_size] # Test avec new_X et new_Y avec le f1 ou roc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cdefc777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "grid_search.fit(list(X_select), list(Y_select))\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6e5728a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"--->%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "697b368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer(use_idf=True, \n",
    "                               norm=None)\n",
    "vectorizer = CountVectorizer(max_df=0.25,\n",
    "                             min_df=0, \n",
    "                             max_features=None,\n",
    "                             stop_words = sw,\n",
    "                             ngram_range=(1,2),\n",
    "                             strip_accents=\"ascii\"\n",
    "                            )\n",
    "X_train_vector, X_test_vector, Y_train, Y_test = get_all_data_vectorized(new_X, X_test, new_Y, Y_test, vectorizer, transformer)\n",
    "optimal_model = svm.SVC(C=0.2, \n",
    "              class_weight=\"balanced\", \n",
    "              kernel=\"linear\")\n",
    "\n",
    "test_size = 4_000\n",
    "X_select, Y_select = X_train_vector[:test_size], Y_train[:test_size]\n",
    "optimal_model.fit(X_select, Y_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d6851c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 4_000\n",
    "X_select, Y_select = X_test_vector[:test_size], Y_test[:test_size]\n",
    "acc = np.round(optimal_model.score(X_select, Y_select)*100, 2)\n",
    "print(\"Acc : \", acc, \" %\")\n",
    "display_infos(optimal_model, X_select, Y_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dd72af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# confusion_matrix(Y_select, optimal_model.predict(Y_select))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cdab8278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_select, optimal_model.predict(Y_select))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4b46fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_select, optimal_model.predict(X_select))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
