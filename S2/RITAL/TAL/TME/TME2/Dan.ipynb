{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP 2 : Neural Embeddings, Text Classification, Text Generation\n",
    "\n",
    "\n",
    "To use statistical classifiers with text, it is first necessary to vectorize the text. In the first practical session we explored the **bag of word** model. \n",
    "\n",
    "Modern **state of the art** methods uses  embeddings to vectorize the text before classification in order to avoid feature engineering.\n",
    "\n",
    "## Dataset\n",
    "https://github.com/cedias/practicalNLP/tree/master/dataset\n",
    "\n",
    "## \"Modern\" NLP pipeline\n",
    "\n",
    "By opposition to the **bag of word** model, in the modern NLP pipeline everything is **embeddings**. Instead of encoding a text as a **sparse vector** of length $D$ (size of feature dictionnary) the goal is to encode the text in a meaningful dense vector of a small size $|e| <<< |D|$. \n",
    "\n",
    "\n",
    "The raw classification pipeline is then the following:\n",
    "\n",
    "```\n",
    "raw text ---|embedding table|-->  vectors --|Neural Net|--> class \n",
    "```\n",
    "\n",
    "\n",
    "### Using a  language model:\n",
    "\n",
    "How to tokenize the text and extract a feature dictionnary is still a manual task. To directly have meaningful embeddings, it is common to use a pre-trained language model such as `word2vec` which we explore in this practical.\n",
    "\n",
    "In this setting, the pipeline becomes the following:\n",
    "```\n",
    "      \n",
    "raw text ---|(pre-trained) Language Model|--> vectors --|classifier (or fine-tuning)|--> class \n",
    "```\n",
    "\n",
    "\n",
    "- #### Classic word embeddings\n",
    "\n",
    " - [Word2Vec](https://arxiv.org/abs/1301.3781)\n",
    " - [Glove](https://nlp.stanford.edu/projects/glove/)\n",
    "\n",
    "\n",
    "- #### bleeding edge language models techniques (only here for reference)\n",
    "\n",
    " - [UMLFIT](https://arxiv.org/abs/1801.06146)\n",
    " - [ELMO](https://arxiv.org/abs/1802.05365)\n",
    " - [GPT](https://blog.openai.com/language-unsupervised/)\n",
    " - [BERT](https://arxiv.org/abs/1810.04805)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Goal of this session:\n",
    "\n",
    "1. Train word embeddings on training dataset\n",
    "2. Tinker with the learnt embeddings and see learnt relations\n",
    "3. Tinker with pre-trained embeddings.\n",
    "4. Use those embeddings for classification\n",
    "5. Compare different embedding models\n",
    "6. Pytorch first look: learn to generate text.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##  Loading data (same as in nlp 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train reviews :  25000\n",
      "----> # of positive :  12500\n",
      "----> # of negative :  12500\n",
      "\n",
      "[\"The undoubted highlight of this movie is Peter O'Toole's performance. In turn wildly comical and terribly terribly tragic. Does anybody do it better than O'Toole? I don't think so. What a great face that man has!<br /><br />The story is an odd one and quite disturbing and emotionally intense in parts (especially toward the end) but it is also oddly touching and does succeed on many levels. However, I felt the film basically revolved around Peter O'Toole's luminous performance and I'm sure I wouldn't have enjoyed it even half as much if he hadn't been in it.\", 1]\n",
      "\n",
      "Number of test reviews :  25000\n",
      "----> # of positive :  12500\n",
      "----> # of negative :  12500\n",
      "\n",
      "['Although credit should have been given to Dr. Seuess for stealing the story-line of \"Horton Hatches The Egg\", this was a fine film. It touched both the emotions and the intellect. Due especially to the incredible performance of seven year old Justin Henry and a script that was sympathetic to each character (and each one\\'s predicament), the thought provoking elements linger long after the tear jerking ones are over. Overall, superior acting from a solid cast, excellent directing, and a very powerful script. The right touches of humor throughout help keep a \"heavy\" subject from becoming tedious or difficult to sit through. Lastly, this film stands the test of time and seems in no way dated, decades after it was released.', 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "#### /!\\ YOU NEED TO UNZIP dataset/json_pol.zip first /!\\\n",
    "\n",
    "\n",
    "# Loading json\n",
    "with open(\"data/json_pol\",encoding=\"utf-8\") as f:\n",
    "    data = f.readlines()\n",
    "    json_data = json.loads(data[0])\n",
    "    train = json_data[\"train\"]\n",
    "    test = json_data[\"test\"]\n",
    "    \n",
    "\n",
    "# Quick Check\n",
    "counter_train = Counter((x[1] for x in train))\n",
    "counter_test = Counter((x[1] for x in test))\n",
    "print(\"Number of train reviews : \", len(train))\n",
    "print(\"----> # of positive : \", counter_train[1])\n",
    "print(\"----> # of negative : \", counter_train[0])\n",
    "print(\"\")\n",
    "print(train[0])\n",
    "print(\"\")\n",
    "print(\"Number of test reviews : \",len(test))\n",
    "print(\"----> # of positive : \", counter_test[1])\n",
    "print(\"----> # of negative : \", counter_test[0])\n",
    "\n",
    "print(\"\")\n",
    "print(test[0])\n",
    "print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec: Quick Recap\n",
    "\n",
    "**[Word2Vec](https://arxiv.org/abs/1301.3781) is composed of two distinct language models (CBOW and SG), optimized to quickly learn word vectors**\n",
    "\n",
    "\n",
    "given a random text: `i'm taking the dog out for a walk`\n",
    "\n",
    "\n",
    "\n",
    "### (a) Continuous Bag of Word (CBOW)\n",
    "    -  predicts a word given a context\n",
    "    \n",
    "maximizing `p(dog | i'm taking the ___ out for a walk)`\n",
    "    \n",
    "### (b) Skip-Gram (SG)               \n",
    "    -  predicts a context given a word\n",
    "    \n",
    " maximizing `p(i'm taking the out for a walk | dog)`\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: train (or load) a language model (word2vec)\n",
    "\n",
    "Gensim has one of [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html) fastest implementation.\n",
    "\n",
    "\n",
    "### Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 17:40:01,545 : INFO : collecting all words and their counts\n",
      "2022-02-04 17:40:01,547 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-02-04 17:40:03,382 : INFO : PROGRESS: at sentence #10000, processed 2358544 words, keeping 155393 word types\n",
      "2022-02-04 17:40:05,212 : INFO : PROGRESS: at sentence #20000, processed 4675912 words, keeping 243050 word types\n",
      "2022-02-04 17:40:06,148 : INFO : collected 280617 word types from a corpus of 5844680 raw words and 25000 sentences\n",
      "2022-02-04 17:40:06,150 : INFO : Creating a fresh vocabulary\n",
      "2022-02-04 17:40:07,271 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 49345 unique words (17.584465659600095%% of original 280617, drops 231272)', 'datetime': '2022-02-04T17:40:07.270482', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'prepare_vocab'}\n",
      "2022-02-04 17:40:07,272 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 5517507 word corpus (94.40220850414394%% of original 5844680, drops 327173)', 'datetime': '2022-02-04T17:40:07.272477', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'prepare_vocab'}\n",
      "2022-02-04 17:40:08,437 : INFO : deleting the raw counts dictionary of 280617 items\n",
      "2022-02-04 17:40:08,449 : INFO : sample=0.001 downsamples 43 most-common words\n",
      "2022-02-04 17:40:08,451 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4268608.194985565 word corpus (77.4%% of prior 5517507)', 'datetime': '2022-02-04T17:40:08.450939', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'prepare_vocab'}\n",
      "2022-02-04 17:40:10,293 : INFO : estimated required memory for 49345 words and 100 dimensions: 64148500 bytes\n",
      "2022-02-04 17:40:10,294 : INFO : resetting layer weights\n",
      "2022-02-04 17:40:10,363 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-02-04T17:40:10.363060', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'build_vocab'}\n",
      "2022-02-04 17:40:10,364 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 49345 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-02-04T17:40:10.364058', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'train'}\n",
      "2022-02-04 17:40:11,391 : INFO : EPOCH 1 - PROGRESS: at 2.39% examples, 106292 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:12,400 : INFO : EPOCH 1 - PROGRESS: at 4.94% examples, 106302 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:13,500 : INFO : EPOCH 1 - PROGRESS: at 7.62% examples, 107473 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:14,522 : INFO : EPOCH 1 - PROGRESS: at 10.17% examples, 106926 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:15,526 : INFO : EPOCH 1 - PROGRESS: at 12.56% examples, 105557 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:16,589 : INFO : EPOCH 1 - PROGRESS: at 15.25% examples, 105917 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:40:17,619 : INFO : EPOCH 1 - PROGRESS: at 17.75% examples, 105667 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:18,649 : INFO : EPOCH 1 - PROGRESS: at 20.24% examples, 105442 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:19,740 : INFO : EPOCH 1 - PROGRESS: at 22.61% examples, 103773 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:40:20,917 : INFO : EPOCH 1 - PROGRESS: at 25.35% examples, 103138 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:21,999 : INFO : EPOCH 1 - PROGRESS: at 28.06% examples, 104031 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:40:23,121 : INFO : EPOCH 1 - PROGRESS: at 30.95% examples, 104412 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:40:24,125 : INFO : EPOCH 1 - PROGRESS: at 33.36% examples, 104543 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:25,155 : INFO : EPOCH 1 - PROGRESS: at 36.01% examples, 105017 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:26,186 : INFO : EPOCH 1 - PROGRESS: at 38.93% examples, 105879 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:27,188 : INFO : EPOCH 1 - PROGRESS: at 41.71% examples, 106398 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:28,311 : INFO : EPOCH 1 - PROGRESS: at 44.34% examples, 106135 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:29,374 : INFO : EPOCH 1 - PROGRESS: at 46.89% examples, 106232 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:30,392 : INFO : EPOCH 1 - PROGRESS: at 49.34% examples, 106186 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:40:31,437 : INFO : EPOCH 1 - PROGRESS: at 51.49% examples, 105401 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:40:32,454 : INFO : EPOCH 1 - PROGRESS: at 53.42% examples, 104094 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:40:33,604 : INFO : EPOCH 1 - PROGRESS: at 55.78% examples, 103234 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:34,683 : INFO : EPOCH 1 - PROGRESS: at 57.70% examples, 101903 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:40:35,704 : INFO : EPOCH 1 - PROGRESS: at 59.40% examples, 100657 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:36,850 : INFO : EPOCH 1 - PROGRESS: at 61.10% examples, 99230 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:37,900 : INFO : EPOCH 1 - PROGRESS: at 62.94% examples, 98319 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:40:38,921 : INFO : EPOCH 1 - PROGRESS: at 64.89% examples, 97575 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:39,974 : INFO : EPOCH 1 - PROGRESS: at 66.80% examples, 96789 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:41,135 : INFO : EPOCH 1 - PROGRESS: at 69.26% examples, 96423 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:40:42,160 : INFO : EPOCH 1 - PROGRESS: at 71.78% examples, 96491 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:43,263 : INFO : EPOCH 1 - PROGRESS: at 73.61% examples, 95667 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:40:44,284 : INFO : EPOCH 1 - PROGRESS: at 76.00% examples, 95769 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:40:45,369 : INFO : EPOCH 1 - PROGRESS: at 78.62% examples, 95908 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:40:46,418 : INFO : EPOCH 1 - PROGRESS: at 81.07% examples, 95929 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:47,449 : INFO : EPOCH 1 - PROGRESS: at 83.70% examples, 96398 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:48,460 : INFO : EPOCH 1 - PROGRESS: at 85.97% examples, 96488 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:40:49,460 : INFO : EPOCH 1 - PROGRESS: at 88.20% examples, 96431 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:50,493 : INFO : EPOCH 1 - PROGRESS: at 90.38% examples, 96280 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:51,498 : INFO : EPOCH 1 - PROGRESS: at 92.82% examples, 96566 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:40:52,590 : INFO : EPOCH 1 - PROGRESS: at 95.28% examples, 96468 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:40:53,620 : INFO : EPOCH 1 - PROGRESS: at 97.63% examples, 96508 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:54,316 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-04 17:40:54,354 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-04 17:40:54,368 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-04 17:40:54,369 : INFO : EPOCH - 1 : training on 5844680 raw words (4269060 effective words) took 44.0s, 97059 effective words/s\n",
      "2022-02-04 17:40:55,450 : INFO : EPOCH 2 - PROGRESS: at 2.39% examples, 100647 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:40:56,503 : INFO : EPOCH 2 - PROGRESS: at 5.24% examples, 108031 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:57,521 : INFO : EPOCH 2 - PROGRESS: at 7.99% examples, 111431 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:58,545 : INFO : EPOCH 2 - PROGRESS: at 11.05% examples, 115005 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:40:59,576 : INFO : EPOCH 2 - PROGRESS: at 14.06% examples, 116898 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:41:00,647 : INFO : EPOCH 2 - PROGRESS: at 16.95% examples, 116404 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:01,716 : INFO : EPOCH 2 - PROGRESS: at 19.59% examples, 114947 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:02,781 : INFO : EPOCH 2 - PROGRESS: at 22.14% examples, 113035 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:03,882 : INFO : EPOCH 2 - PROGRESS: at 24.69% examples, 111336 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:41:04,900 : INFO : EPOCH 2 - PROGRESS: at 26.74% examples, 109410 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:41:05,975 : INFO : EPOCH 2 - PROGRESS: at 28.89% examples, 107316 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:41:06,985 : INFO : EPOCH 2 - PROGRESS: at 31.30% examples, 106673 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:41:08,003 : INFO : EPOCH 2 - PROGRESS: at 33.97% examples, 107558 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:09,004 : INFO : EPOCH 2 - PROGRESS: at 36.54% examples, 107564 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:10,046 : INFO : EPOCH 2 - PROGRESS: at 39.10% examples, 107249 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:11,051 : INFO : EPOCH 2 - PROGRESS: at 42.04% examples, 108106 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:12,057 : INFO : EPOCH 2 - PROGRESS: at 44.76% examples, 108857 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:13,102 : INFO : EPOCH 2 - PROGRESS: at 47.40% examples, 108911 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:14,188 : INFO : EPOCH 2 - PROGRESS: at 50.18% examples, 109101 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:15,238 : INFO : EPOCH 2 - PROGRESS: at 53.11% examples, 109456 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:16,276 : INFO : EPOCH 2 - PROGRESS: at 55.85% examples, 109493 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:17,342 : INFO : EPOCH 2 - PROGRESS: at 58.20% examples, 108800 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:18,407 : INFO : EPOCH 2 - PROGRESS: at 60.80% examples, 108725 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:41:19,460 : INFO : EPOCH 2 - PROGRESS: at 63.39% examples, 108740 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:20,527 : INFO : EPOCH 2 - PROGRESS: at 66.50% examples, 108991 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:41:21,635 : INFO : EPOCH 2 - PROGRESS: at 69.10% examples, 108529 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:22,666 : INFO : EPOCH 2 - PROGRESS: at 71.78% examples, 108408 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:41:23,724 : INFO : EPOCH 2 - PROGRESS: at 74.48% examples, 108423 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:24,823 : INFO : EPOCH 2 - PROGRESS: at 77.34% examples, 108572 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:25,852 : INFO : EPOCH 2 - PROGRESS: at 80.39% examples, 108941 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:26,945 : INFO : EPOCH 2 - PROGRESS: at 83.05% examples, 108857 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:27,988 : INFO : EPOCH 2 - PROGRESS: at 85.34% examples, 108473 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:41:29,115 : INFO : EPOCH 2 - PROGRESS: at 88.00% examples, 108294 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:30,314 : INFO : EPOCH 2 - PROGRESS: at 90.84% examples, 108096 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:41:31,394 : INFO : EPOCH 2 - PROGRESS: at 93.92% examples, 108466 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:32,443 : INFO : EPOCH 2 - PROGRESS: at 96.28% examples, 108128 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:33,507 : INFO : EPOCH 2 - PROGRESS: at 98.18% examples, 107212 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:41:34,341 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-04 17:41:34,350 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-04 17:41:34,378 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-04 17:41:34,379 : INFO : EPOCH - 2 : training on 5844680 raw words (4269422 effective words) took 40.0s, 106755 effective words/s\n",
      "2022-02-04 17:41:35,517 : INFO : EPOCH 3 - PROGRESS: at 2.08% examples, 92338 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:36,518 : INFO : EPOCH 3 - PROGRESS: at 4.57% examples, 99802 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:41:37,560 : INFO : EPOCH 3 - PROGRESS: at 7.27% examples, 105374 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:41:38,583 : INFO : EPOCH 3 - PROGRESS: at 10.17% examples, 108821 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:39,591 : INFO : EPOCH 3 - PROGRESS: at 13.03% examples, 111128 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:40,617 : INFO : EPOCH 3 - PROGRESS: at 15.73% examples, 111227 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:41,705 : INFO : EPOCH 3 - PROGRESS: at 18.43% examples, 110273 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:42,730 : INFO : EPOCH 3 - PROGRESS: at 21.09% examples, 110361 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:43,762 : INFO : EPOCH 3 - PROGRESS: at 23.77% examples, 110423 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:44,865 : INFO : EPOCH 3 - PROGRESS: at 26.74% examples, 111167 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:45,921 : INFO : EPOCH 3 - PROGRESS: at 29.80% examples, 112189 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:46,968 : INFO : EPOCH 3 - PROGRESS: at 32.76% examples, 113055 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:41:48,006 : INFO : EPOCH 3 - PROGRESS: at 35.32% examples, 112834 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:49,125 : INFO : EPOCH 3 - PROGRESS: at 38.38% examples, 113033 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:41:50,182 : INFO : EPOCH 3 - PROGRESS: at 41.56% examples, 113637 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:41:51,292 : INFO : EPOCH 3 - PROGRESS: at 44.17% examples, 112946 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:41:52,304 : INFO : EPOCH 3 - PROGRESS: at 46.70% examples, 112987 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:53,320 : INFO : EPOCH 3 - PROGRESS: at 49.70% examples, 113745 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:54,356 : INFO : EPOCH 3 - PROGRESS: at 52.34% examples, 113617 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:55,365 : INFO : EPOCH 3 - PROGRESS: at 55.28% examples, 113918 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:41:56,405 : INFO : EPOCH 3 - PROGRESS: at 58.06% examples, 113761 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:57,467 : INFO : EPOCH 3 - PROGRESS: at 60.94% examples, 114094 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:41:58,551 : INFO : EPOCH 3 - PROGRESS: at 63.93% examples, 114333 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:41:59,593 : INFO : EPOCH 3 - PROGRESS: at 67.20% examples, 114764 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:00,600 : INFO : EPOCH 3 - PROGRESS: at 70.20% examples, 115021 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:42:01,649 : INFO : EPOCH 3 - PROGRESS: at 72.96% examples, 114834 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:42:02,773 : INFO : EPOCH 3 - PROGRESS: at 76.00% examples, 114875 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:03,827 : INFO : EPOCH 3 - PROGRESS: at 79.16% examples, 115199 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:04,882 : INFO : EPOCH 3 - PROGRESS: at 82.08% examples, 115259 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:42:05,901 : INFO : EPOCH 3 - PROGRESS: at 84.70% examples, 115219 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:06,951 : INFO : EPOCH 3 - PROGRESS: at 87.48% examples, 115255 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:08,019 : INFO : EPOCH 3 - PROGRESS: at 90.40% examples, 115255 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:09,089 : INFO : EPOCH 3 - PROGRESS: at 93.38% examples, 115458 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:10,153 : INFO : EPOCH 3 - PROGRESS: at 96.44% examples, 115656 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:11,211 : INFO : EPOCH 3 - PROGRESS: at 99.63% examples, 115876 words/s, in_qsize 3, out_qsize 0\n",
      "2022-02-04 17:42:11,277 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-04 17:42:11,279 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-04 17:42:11,292 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-04 17:42:11,294 : INFO : EPOCH - 3 : training on 5844680 raw words (4269284 effective words) took 36.8s, 116075 effective words/s\n",
      "2022-02-04 17:42:12,366 : INFO : EPOCH 4 - PROGRESS: at 2.54% examples, 108061 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:13,440 : INFO : EPOCH 4 - PROGRESS: at 5.54% examples, 114107 words/s, in_qsize 4, out_qsize 1\n",
      "2022-02-04 17:42:14,450 : INFO : EPOCH 4 - PROGRESS: at 8.32% examples, 115958 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:15,462 : INFO : EPOCH 4 - PROGRESS: at 11.22% examples, 116941 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:16,516 : INFO : EPOCH 4 - PROGRESS: at 14.23% examples, 117963 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:17,585 : INFO : EPOCH 4 - PROGRESS: at 17.23% examples, 118356 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:18,585 : INFO : EPOCH 4 - PROGRESS: at 20.11% examples, 118796 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:42:19,625 : INFO : EPOCH 4 - PROGRESS: at 23.10% examples, 119344 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:42:20,646 : INFO : EPOCH 4 - PROGRESS: at 26.02% examples, 119399 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:21,755 : INFO : EPOCH 4 - PROGRESS: at 28.72% examples, 118422 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:22,801 : INFO : EPOCH 4 - PROGRESS: at 31.46% examples, 117600 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:42:23,802 : INFO : EPOCH 4 - PROGRESS: at 33.97% examples, 117271 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:24,834 : INFO : EPOCH 4 - PROGRESS: at 36.68% examples, 116810 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:25,848 : INFO : EPOCH 4 - PROGRESS: at 39.81% examples, 117557 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:26,869 : INFO : EPOCH 4 - PROGRESS: at 42.70% examples, 117666 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:27,891 : INFO : EPOCH 4 - PROGRESS: at 45.58% examples, 118186 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:28,908 : INFO : EPOCH 4 - PROGRESS: at 48.33% examples, 118268 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:29,944 : INFO : EPOCH 4 - PROGRESS: at 51.15% examples, 118298 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:42:30,989 : INFO : EPOCH 4 - PROGRESS: at 54.18% examples, 118512 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:42:32,089 : INFO : EPOCH 4 - PROGRESS: at 57.17% examples, 118108 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:42:33,129 : INFO : EPOCH 4 - PROGRESS: at 59.89% examples, 117757 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:34,168 : INFO : EPOCH 4 - PROGRESS: at 61.92% examples, 116451 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:42:35,181 : INFO : EPOCH 4 - PROGRESS: at 64.51% examples, 116017 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:42:36,189 : INFO : EPOCH 4 - PROGRESS: at 66.70% examples, 114787 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:42:37,308 : INFO : EPOCH 4 - PROGRESS: at 68.92% examples, 113453 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:38,451 : INFO : EPOCH 4 - PROGRESS: at 71.41% examples, 112401 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:39,466 : INFO : EPOCH 4 - PROGRESS: at 74.14% examples, 112445 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:40,560 : INFO : EPOCH 4 - PROGRESS: at 76.51% examples, 111706 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:41,582 : INFO : EPOCH 4 - PROGRESS: at 79.16% examples, 111526 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:42,596 : INFO : EPOCH 4 - PROGRESS: at 81.77% examples, 111386 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:43,626 : INFO : EPOCH 4 - PROGRESS: at 84.19% examples, 111198 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:44,636 : INFO : EPOCH 4 - PROGRESS: at 86.84% examples, 111291 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:45,677 : INFO : EPOCH 4 - PROGRESS: at 89.40% examples, 111076 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:46,684 : INFO : EPOCH 4 - PROGRESS: at 92.00% examples, 111179 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:47,745 : INFO : EPOCH 4 - PROGRESS: at 94.97% examples, 111322 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:48,781 : INFO : EPOCH 4 - PROGRESS: at 97.99% examples, 111712 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:49,324 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-04 17:42:49,348 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-04 17:42:49,381 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-04 17:42:49,383 : INFO : EPOCH - 4 : training on 5844680 raw words (4268466 effective words) took 38.1s, 112113 effective words/s\n",
      "2022-02-04 17:42:50,428 : INFO : EPOCH 5 - PROGRESS: at 2.54% examples, 110120 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:51,458 : INFO : EPOCH 5 - PROGRESS: at 5.54% examples, 117622 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:42:52,462 : INFO : EPOCH 5 - PROGRESS: at 8.13% examples, 116211 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:53,529 : INFO : EPOCH 5 - PROGRESS: at 10.85% examples, 113925 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:42:54,583 : INFO : EPOCH 5 - PROGRESS: at 13.52% examples, 112733 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:42:55,587 : INFO : EPOCH 5 - PROGRESS: at 16.11% examples, 111900 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:42:56,607 : INFO : EPOCH 5 - PROGRESS: at 18.76% examples, 111889 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:57,635 : INFO : EPOCH 5 - PROGRESS: at 21.60% examples, 112613 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:42:58,685 : INFO : EPOCH 5 - PROGRESS: at 24.69% examples, 113803 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:42:59,691 : INFO : EPOCH 5 - PROGRESS: at 27.41% examples, 114516 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:00,730 : INFO : EPOCH 5 - PROGRESS: at 29.80% examples, 112841 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:01,770 : INFO : EPOCH 5 - PROGRESS: at 32.63% examples, 113141 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:43:02,874 : INFO : EPOCH 5 - PROGRESS: at 34.64% examples, 110762 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:03,946 : INFO : EPOCH 5 - PROGRESS: at 36.84% examples, 109021 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:05,108 : INFO : EPOCH 5 - PROGRESS: at 39.42% examples, 107819 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:43:06,273 : INFO : EPOCH 5 - PROGRESS: at 41.86% examples, 106327 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:43:07,292 : INFO : EPOCH 5 - PROGRESS: at 44.50% examples, 106693 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:43:08,362 : INFO : EPOCH 5 - PROGRESS: at 47.40% examples, 107473 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:09,376 : INFO : EPOCH 5 - PROGRESS: at 50.02% examples, 107770 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:10,381 : INFO : EPOCH 5 - PROGRESS: at 52.53% examples, 107758 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:11,406 : INFO : EPOCH 5 - PROGRESS: at 55.48% examples, 108245 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:12,408 : INFO : EPOCH 5 - PROGRESS: at 57.88% examples, 107905 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:13,476 : INFO : EPOCH 5 - PROGRESS: at 60.94% examples, 108756 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:14,506 : INFO : EPOCH 5 - PROGRESS: at 63.93% examples, 109445 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:43:15,539 : INFO : EPOCH 5 - PROGRESS: at 67.00% examples, 109822 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:16,578 : INFO : EPOCH 5 - PROGRESS: at 70.20% examples, 110394 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:17,630 : INFO : EPOCH 5 - PROGRESS: at 73.14% examples, 110634 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:18,684 : INFO : EPOCH 5 - PROGRESS: at 76.00% examples, 110834 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:19,771 : INFO : EPOCH 5 - PROGRESS: at 79.16% examples, 111165 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:20,814 : INFO : EPOCH 5 - PROGRESS: at 82.27% examples, 111639 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:21,844 : INFO : EPOCH 5 - PROGRESS: at 85.01% examples, 111870 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:22,862 : INFO : EPOCH 5 - PROGRESS: at 87.48% examples, 111707 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:43:23,927 : INFO : EPOCH 5 - PROGRESS: at 90.54% examples, 112026 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:25,033 : INFO : EPOCH 5 - PROGRESS: at 93.38% examples, 112004 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:26,051 : INFO : EPOCH 5 - PROGRESS: at 96.28% examples, 112238 words/s, in_qsize 6, out_qsize 0\n",
      "2022-02-04 17:43:27,063 : INFO : EPOCH 5 - PROGRESS: at 98.91% examples, 112108 words/s, in_qsize 5, out_qsize 0\n",
      "2022-02-04 17:43:27,378 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-04 17:43:27,418 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-04 17:43:27,452 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-04 17:43:27,454 : INFO : EPOCH - 5 : training on 5844680 raw words (4269425 effective words) took 38.1s, 112164 effective words/s\n",
      "2022-02-04 17:43:27,456 : INFO : Word2Vec lifecycle event {'msg': 'training on 29223400 raw words (21345657 effective words) took 197.1s, 108304 effective words/s', 'datetime': '2022-02-04T17:43:27.456494', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'train'}\n",
      "2022-02-04 17:43:27,458 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=49345, vector_size=100, alpha=0.025)', 'datetime': '2022-02-04T17:43:27.458489', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "text = [t.split() for t,p in train]\n",
    "\n",
    "# the following configuration is the default configuration\n",
    "w2v = gensim.models.word2vec.Word2Vec(sentences=text,\n",
    "                                vector_size=100, window=5,     ### here we train a cbow model \n",
    "                                min_count=5,                      \n",
    "                                sample=0.001, workers=3,\n",
    "                                sg=1, hs=0, negative=5,        ### set sg to 1 to train a sg model\n",
    "                                cbow_mean=1,\n",
    "                                epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 17:43:27,500 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2022-02-04 17:43:27,502 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n",
      "2022-02-04 17:43:27,503 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\", 'datetime': '2022-02-04T17:43:27.503369', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'created'}\n",
      "2022-02-04 17:43:27,859 : INFO : KeyedVectors lifecycle event {'fname_or_handle': 'downloaded_vectors_path', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-02-04T17:43:27.859537', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'saving'}\n",
      "2022-02-04 17:43:27,948 : INFO : saved downloaded_vectors_path\n",
      "2022-02-04 17:43:27,949 : INFO : loading KeyedVectors object from downloaded_vectors_path\n",
      "2022-02-04 17:43:28,029 : INFO : KeyedVectors lifecycle event {'fname': 'downloaded_vectors_path', 'datetime': '2022-02-04T17:43:28.029571', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "# It's for later\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "# w2v = KeyedVectors.load_word2vec_format(datapath('downloaded_vectors_path'), binary=False)\n",
    "word_vectors = w2v.wv\n",
    "word_vectors.save(\"downloaded_vectors_path\")\n",
    "# Load back with memory-mapping = read-only, shared across processes.\n",
    "wv = KeyedVectors.load(\"downloaded_vectors_path\", mmap='r')\n",
    "\n",
    "vector = wv['car']  # Get numpy vector of a word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Gensim, embeddings are loaded and can be used via the [\"KeyedVectors\"](https://radimrehurek.com/gensim/models/keyedvectors.html) class\n",
    "\n",
    "> Since trained word vectors are independent from the way they were trained (Word2Vec, FastText, WordRank, VarEmbed etc), they can be represented by a standalone structure, as implemented in this module.\n",
    "\n",
    ">The structure is called “KeyedVectors” and is essentially a mapping between entities and vectors. Each entity is identified by its string id, so this is a mapping between {str => 1D numpy array}.\n",
    "\n",
    ">The entity typically corresponds to a word (so the mapping maps words to 1D vectors), but for some models, they key can also correspond to a document, a graph node etc. To generalize over different use-cases, this module calls the keys entities. Each entity is always represented by its string id, no matter whether the entity is a word, a document or a graph node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Test learnt embeddings\n",
    "\n",
    "The word embedding space directly encodes similarities between words: the vector coding for the word \"great\" will be closer to the vector coding for \"good\" than to the one coding for \"bad\". Generally, [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) is the distance used when considering distance between vectors.\n",
    "\n",
    "KeyedVectors have a built in [similarity](https://radimrehurek.com/gensim/models /keyedvectors.html#gensim.models.keyedvectors.BaseKeyedVectors.similarity) method to compute the cosine similarity between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great and good: 0.77765757\n",
      "great and bad: 0.49547234\n"
     ]
    }
   ],
   "source": [
    "# is great really closer to good than to bad ?\n",
    "print(\"great and good:\",w2v.wv.similarity(\"great\",\"good\"))\n",
    "print(\"great and bad:\",w2v.wv.similarity(\"great\",\"bad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since cosine distance encodes similarity, neighboring words are supposed to be similar. The [most_similar](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.BaseKeyedVectors.most_similar) method returns the `topn` words given a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('film', 0.9414064288139343), ('\"film\"', 0.84061199426651), ('\"movie\"', 0.7907540202140808), ('movie...', 0.7837522625923157), ('movie,', 0.7767480611801147)] \n",
      "\n",
      "[('amazing', 0.7784026265144348), ('excellent', 0.7351272106170654), ('incredible', 0.7315266132354736), ('awesome,', 0.7096130847930908), ('fantastic', 0.694219172000885)] \n",
      "\n",
      "[('actor,', 0.8408632874488831), ('actor.', 0.7756488919258118), ('comedian', 0.7745350003242493), ('actress', 0.7510592341423035), ('actor)', 0.7501669526100159)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The query can be as simple as a word, such as \"movie\"\n",
    "# Try changing the word\n",
    "print(w2v.wv.most_similar(\"movie\",topn=5),\"\\n\") # 5 most similar words\n",
    "print(w2v.wv.most_similar(\"awesome\",topn=5),\"\\n\")\n",
    "print(w2v.wv.most_similar(\"actor\",topn=5),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it can be a more complicated query\n",
    "Word embedding spaces tend to encode much more.\n",
    "\n",
    "The most famous exemple is: `vec(king) - vec(man) + vec(woman) => vec(queen)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('awful', 0.7432842254638672), ('unbelievably', 0.6427719593048096), ('unbelievable', 0.6403261423110962)] \n",
      "\n",
      "[('actress', 0.8484925031661987), ('actress,', 0.759199857711792), ('actress.', 0.7074642777442932)] \n",
      "\n",
      "[('man,', 0.7141423225402832), ('soldier', 0.7004864811897278), ('devil', 0.6913885474205017)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What is awesome - good + bad ?\n",
    "print(w2v.wv.most_similar(positive=[\"awesome\",\"bad\"],negative=[\"good\"],topn=3),\"\\n\")  \n",
    "print(w2v.wv.most_similar(positive=[\"actor\",\"woman\"],negative=[\"man\"],topn=3),\"\\n\") # do the famous exemple works for actor ?\n",
    "\n",
    "\n",
    "# Try other things like plurals for exemple.\n",
    "print(w2v.wv.most_similar(positive=[\"men\",\"man\"],negative=[\"women\"],topn=3),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test learnt \"synctactic\" and \"semantic\" similarities, Mikolov et al. introduced a special dataset containing a wide variety of three way similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 17:43:28,307 : INFO : Evaluating word analogies for top 300000 words in the model on data/questions-words.txt\n",
      "2022-02-04 17:43:28,784 : INFO : capital-common-countries: 1.3% (2/156)\n",
      "2022-02-04 17:43:29,155 : INFO : capital-world: 1.8% (2/111)\n",
      "2022-02-04 17:43:29,222 : INFO : currency: 0.0% (0/18)\n",
      "2022-02-04 17:43:30,166 : INFO : city-in-state: 0.0% (0/301)\n",
      "2022-02-04 17:43:31,345 : INFO : family: 31.0% (130/420)\n",
      "2022-02-04 17:43:34,066 : INFO : gram1-adjective-to-adverb: 1.7% (15/870)\n",
      "2022-02-04 17:43:35,829 : INFO : gram2-opposite: 2.9% (16/552)\n",
      "2022-02-04 17:43:39,609 : INFO : gram3-comparative: 21.1% (251/1190)\n",
      "2022-02-04 17:43:41,998 : INFO : gram4-superlative: 10.1% (76/756)\n",
      "2022-02-04 17:43:44,528 : INFO : gram5-present-participle: 18.1% (147/812)\n",
      "2022-02-04 17:43:47,134 : INFO : gram6-nationality-adjective: 1.4% (14/967)\n",
      "2022-02-04 17:43:50,691 : INFO : gram7-past-tense: 19.4% (244/1260)\n",
      "2022-02-04 17:43:53,020 : INFO : gram8-plural: 8.4% (68/812)\n",
      "2022-02-04 17:43:54,849 : INFO : gram9-plural-verbs: 28.2% (183/650)\n",
      "2022-02-04 17:43:54,852 : INFO : Quadruplets with out-of-vocabulary words: 54.6%\n",
      "2022-02-04 17:43:54,853 : INFO : NB: analogies containing OOV words were skipped from evaluation! To change this behavior, use \"dummy4unknown=True\"\n",
      "2022-02-04 17:43:54,854 : INFO : Total accuracy: 12.9% (1148/8875)\n"
     ]
    }
   ],
   "source": [
    "out = w2v.wv.evaluate_word_analogies(\"data/questions-words.txt\",case_insensitive=True)  # original semantic syntactic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training the w2v models on the review dataset, since it hasn't been learnt with a lot of data, it does not perform very well. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3:  sentiment classification\n",
    "\n",
    "In the previous practical session, we used a bag of word approach to transform text into vectors.\n",
    "Here, we propose to try to use word vectors (previously learnt or loaded).\n",
    "\n",
    "\n",
    "### <font color='green'> Since we have only word vectors and that sentences are made of multiple words, we need to aggregate them. </font>\n",
    "\n",
    "\n",
    "### (1) Vectorize reviews using word vectors:\n",
    "\n",
    "Word aggregation can be done in different ways:\n",
    "\n",
    "- Sum\n",
    "- Average\n",
    "- Min/feature\n",
    "- Max/feature\n",
    "\n",
    "#### a few pointers:\n",
    "\n",
    "- `w2v.wv.vocab` is a `set()` of the vocabulary (all existing words in your model)\n",
    "- `np.minimum(a,b) and np.maximum(a,b)` respectively return element-wise min/max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karna\\AppData\\Local\\Temp/ipykernel_43744/2987936085.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.array([vectorize(text) for text,pol in train])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7205323  0.33217111 0.76288635 0.71961647 0.81379908 0.7711339\n",
      " 0.58910245 0.8836444  0.31675652 0.97963476 0.87693894 0.59793925\n",
      " 0.72714204 0.63566655 0.6597085  0.78417248 0.78417248 0.48525462\n",
      " 0.74175191 0.7844258  0.61915094 0.98100191 0.76592702 1.12544572\n",
      " 0.         0.72236139 0.94140059 1.00824738 0.7440486  0.99137551\n",
      " 0.56536472 0.63652253 0.78923917 0.80187738 0.72668231 0.\n",
      " 0.8410598  0.95025527 1.04193282 0.58910245 0.80914617 0.62772691\n",
      " 0.63727248 0.6597085  0.6016956  0.65359098 0.6597085  0.63810831\n",
      " 0.72436208 0.71709609 0.83464044 0.56803608 0.70039725 0.52489817\n",
      " 0.41782096 0.59577477 0.98100191 0.58910245 0.5878877  0.5381825\n",
      " 0.94468892 0.6597085  0.82569003 0.73023117 0.95035326 1.00194156\n",
      " 0.66618431 0.76376259 0.72236139 0.77242357 0.52489817 0.74918562\n",
      " 0.73737693 0.44011602 0.96004492 0.8836444  0.31675652 0.4367055\n",
      " 0.90998125 0.6597085  0.79030973 0.76603657 0.72236139 0.69335282\n",
      " 0.75130635 0.94621289 0.98100191 0.84246939 0.81566602 0.7395559\n",
      " 0.67315263 0.66304499 0.76274461 0.73897392 0.82419503 0.71709609\n",
      " 0.73814559]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karna\\AppData\\Local\\Temp/ipykernel_43744/2987936085.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_test = np.array([vectorize(text) for text,pol in test])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# We first need to vectorize text:\n",
    "# First we propose to a sum of them\n",
    "\n",
    "def vectorize(text,types=\"max\"):\n",
    "    \"\"\"\n",
    "    This function should vectorize one review\n",
    "\n",
    "    input: str\n",
    "    output: np.array(float)\n",
    "    \"\"\"   \n",
    "    vec = []\n",
    "    for i in text.split():\n",
    "        try :\n",
    "            vec.append(wv[i])\n",
    "        except :\n",
    "            vec.append(np.zeros(100))\n",
    "    if types == \"mean\" :\n",
    "        return np.array(vec).mean(axis=1)\n",
    "    if types == \"sum\":    \n",
    "        return np.array(vec).sum(axis=1)\n",
    "    if types == \"max\" :\n",
    "        return np.array(vec).max(axis=1)\n",
    "    if types == \"min\" :\n",
    "        return np.array(vec).min(axis=1)\n",
    "\n",
    "classes = np.array([pol for text,pol in train])\n",
    "X = np.array([vectorize(text) for text,pol in train])\n",
    "X_test = np.array([vectorize(text) for text,pol in test])\n",
    "true = np.array([pol for text,pol in test])\n",
    "\n",
    "#let's see what a review vector looks like.\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "print(len(X[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Train a classifier \n",
    "as in the previous practical session, train a logistic regression to do sentiment classification with word vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2470\n",
      "25000 2470\n",
      "(25000, 2470)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8)\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(Y_train.shape)\n",
    "# print(Y_test.shape)\n",
    "\n",
    "maxi = 0\n",
    "for i in range(X.shape[0]):\n",
    "    if len(X[i]) > maxi:\n",
    "        maxi = len(X[i])\n",
    "print(maxi)\n",
    "\n",
    "padded_array = np.zeros((X.shape[0], maxi))\n",
    "n,m = padded_array.shape\n",
    "print(n, m)\n",
    "for i in range(n):\n",
    "    for j in range(m):\n",
    "        if j < len(X[i]):\n",
    "            padded_array[i][j] = X[i][j]\n",
    "print(padded_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 2470\n",
      "(25000, 2470)\n"
     ]
    }
   ],
   "source": [
    "padded_array_test = np.zeros((X_test.shape[0], maxi))\n",
    "n,m = padded_array_test.shape\n",
    "print(n, m)\n",
    "for i in range(n):\n",
    "    for j in range(m):\n",
    "        if j < len(X_test[i]):\n",
    "            padded_array_test[i][j] = X_test[i][j]\n",
    "print(padded_array_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karna\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(max_iter=1000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(max_iter=1000)\n",
    "clf.fit(padded_array, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.50      0.25      4135\n",
      "           1       0.83      0.50      0.62     20865\n",
      "\n",
      "    accuracy                           0.50     25000\n",
      "   macro avg       0.50      0.50      0.44     25000\n",
      "weighted avg       0.72      0.50      0.56     25000\n",
      "\n",
      "0.6249063389779709\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(padded_array_test)\n",
    "print(accuracy_score(preds, true))\n",
    "print(classification_report(preds, true))\n",
    "print(f1_score(preds, true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "performance should be worst than with bag of word (~80%). Sum/Mean aggregation does not work well on long reviews (especially with many frequent words). This adds a lot of noise.\n",
    "\n",
    "## **Todo** :  Try answering the following questions:\n",
    "\n",
    "- Which word2vec model works best: skip-gram or cbow\n",
    "- Do pretrained vectors work best than those learnt on the train dataset ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**(Bonus)** To have a better accuracy, we could try two things:\n",
    "- Better aggregation methods (weight by tf-idf ?)\n",
    "- Another word vectorizing method such as [fasttext](https://radimrehurek.com/gensim/models/fasttext.html)\n",
    "- A document vectorizing method such as [Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- Generate text with a recurrent neural network (Pytorch) ---\n",
    "### (Mostly Read & Run)\n",
    "\n",
    "The goal is to replicate the (famous) experiment from [Karpathy's blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "\n",
    "To learn to generate text, we train a recurrent neural network to do the following task:\n",
    "\n",
    "Given a \"chunk\" of text: `this is random text`\n",
    "\n",
    "the goal of the network is to predict each character in **`his is random text` ** sequentially given the following sequential input **`this is random tex`**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Input ->  Output\n",
    "--------------\n",
    "T    ->    H\n",
    "H    ->    I\n",
    "I    ->    S\n",
    "S    ->    \" \"\n",
    "\" \"  ->    I\n",
    "I    ->    S\n",
    "S    ->    \" \"\n",
    "[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load text (dataset/input.txt)\n",
    "\n",
    "Before building training batch, we load the full text in RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 1115394\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "file = unidecode.unidecode(open('data/input.txt').read()) #clean text => only ascii\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Helper functions:\n",
    "\n",
    "We have a text and we want to feed batch of chunks to a neural network:\n",
    "\n",
    "one chunk  A,B,C,D,E\n",
    "[input] A,B,C,D -> B,C,D,E [output]\n",
    "\n",
    "Note: we will use an embedding layer instead of a one-hot encoding scheme.\n",
    "\n",
    "for this, we have 3 functions:\n",
    "\n",
    "- One to get a random str chunk of size `chunk_len` : `random_chunk` \n",
    "- One to turn a chunk into a tensor of size `(1,chunk_len)` coding for each characters : `char_tensor`\n",
    "- One to return random input and output chunks of size `(batch_size,chunk_len)` : `random_training_set`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[94, 21, 10, 13, 34, 94, 10, 23, 13, 94],\n",
      "        [18, 21, 14, 28, 94, 28, 22, 24, 29, 14],\n",
      "        [18, 23, 16, 82, 94, 24, 68, 94, 42, 24],\n",
      "        [94, 10, 27, 14, 94, 29, 17, 24, 30, 94]]), tensor([[21, 10, 13, 34, 94, 10, 23, 13, 94, 22],\n",
      "        [21, 14, 28, 94, 28, 22, 24, 29, 14, 82],\n",
      "        [23, 16, 82, 94, 24, 68, 94, 42, 24, 13],\n",
      "        [10, 27, 14, 94, 29, 17, 24, 30, 94, 17]]))\n"
     ]
    }
   ],
   "source": [
    "import time, math\n",
    "\n",
    "\n",
    "#Get a piece of text\n",
    "def random_chunk(chunk_len):\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "\n",
    "# Turn string into list of longs\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(1,len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[0,c] = all_characters.index(string[c])\n",
    "    return tensor\n",
    "\n",
    "\n",
    "#Turn a piece of text in train/test\n",
    "def random_training_set(chunk_len=200, batch_size=8):\n",
    "    chunks = [random_chunk(chunk_len) for _ in range(batch_size)]\n",
    "    inp = torch.cat([char_tensor(chunk[:-1]) for chunk in chunks],dim=0)\n",
    "    target = torch.cat([char_tensor(chunk[1:]) for chunk in chunks],dim=0)\n",
    "    \n",
    "    return inp, target\n",
    "\n",
    "print(random_training_set(10,4))  ## should return 8 chunks of 10 letters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The actual RNN model (only thing to complete):\n",
    "\n",
    "It should be composed of three distinct modules:\n",
    "\n",
    "- an [embedding layer](https://pytorch.org/docs/stable/nn.html#embedding) (n_characters, hidden_size)\n",
    "\n",
    "```\n",
    "nn.Embedding(len_dic,size_vec)\n",
    "```\n",
    "- a [recurrent](https://pytorch.org/docs/stable/nn.html#recurrent-layers) layer (hidden_size, hidden_size)\n",
    "```\n",
    "nn.RNN(in_size,out_size) or nn.GRU() or nn.LSTM() => rnn_cell parameter\n",
    "```\n",
    "- a [prediction](https://pytorch.org/docs/stable/nn.html#linear) layer (hidden_size, output_size)\n",
    "\n",
    "```\n",
    "nn.Linear(in_size,out_size)\n",
    "```\n",
    "=> Complete the `init` function code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as f\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_char, hidden_size, output_size, n_layers=1,rnn_cell=nn.RNN):\n",
    "        \"\"\"\n",
    "        Create the network\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.n_char = n_char\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        #  (batch,chunk_len) -> (batch, chunk_len, hidden_size)  \n",
    "        self.embed = nn.Embedding(n_char, hidden_size)\n",
    "        \n",
    "        # (batch, chunk_len, hidden_size)  -> (batch, chunk_len, hidden_size)  \n",
    "        self.rnn = rnn_cell(hidden_size, hidden_size)\n",
    "        \n",
    "        #(batch, chunk_len, hidden_size) -> (batch, chunk_len, output_size)  \n",
    "        self.predict = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        batched forward: input is (batch > 1,chunk_len)\n",
    "        \"\"\"\n",
    "        input = self.embed(input)\n",
    "        output,_  = self.rnn(input)\n",
    "        output = self.predict(f.tanh(output))\n",
    "        return output\n",
    "    \n",
    "    def forward_seq(self, input,hidden=None):\n",
    "        \"\"\"\n",
    "        not batched forward: input is  (1,chunk_len)\n",
    "        \"\"\"\n",
    "        input = self.embed(input)\n",
    "        output,hidden  = self.rnn(input.unsqueeze(0),hidden)\n",
    "        output = self.predict(f.tanh(output))\n",
    "        return output,hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generation function\n",
    "\n",
    "Sample text from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model,prime_str='A', predict_len=100, temperature=0.8):\n",
    "    prime_input = char_tensor(prime_str).squeeze(0)\n",
    "    hidden = None\n",
    "    predicted = prime_str+\"\"\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "\n",
    "    for p in range(len(prime_str)-1):\n",
    "        _,hidden = model.forward_seq(prime_input[p].unsqueeze(0),hidden)\n",
    "            \n",
    "    #print(hidden.size())\n",
    "    for p in range(predict_len):\n",
    "        output, hidden = model.forward_seq(prime_input[-1].unsqueeze(0), hidden)\n",
    "                # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        #print(output_dist)\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        #print(top_i)\n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        prime_input = torch.cat([prime_input,char_tensor(predicted_char).squeeze(0)])\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop for net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 3s (100 1%) 2.6477]\n",
      "Whond finclou'ind whe,\n",
      "CYe lougousand:'dou ou ge ee ave the RSofe\n",
      "\n",
      "The he I'sold ome:\n",
      "Hindest tonds cl \n",
      "\n",
      "[0m 6s (200 2%) 2.6083]\n",
      "Whours o the t om tsp theverin t?\n",
      "Bold foul t nds G HO:\n",
      "CES:\n",
      "Ance thingonghayoty che hit d f ke fe ne  \n",
      "\n",
      "[0m 10s (300 3%) 2.5370]\n",
      "Whe\n",
      "\n",
      "Wh fo s t ngh; t totoute.\n",
      "Fouserghes ch hend e\n",
      "PELOROnd!\n",
      "But nget bess lfofithinghithid oror hesh \n",
      "\n",
      "[0m 13s (400 4%) 2.4856]\n",
      "Wheut I ed lighallloulltho he s thiate the, omencheyous beres wneours e t bly ll n shell f on seanthet \n",
      "\n",
      "[0m 17s (500 5%) 2.5186]\n",
      "Whyon pend o co'sthe supof thano f, al t me 's blespe me k t sif anomt, wit asut l than crtothod f aif \n",
      "\n",
      "[0m 20s (600 6%) 2.4362]\n",
      "Whe bithtare rswilern wac meyon y wswns bererdo hatory, t lellour bomas ma yoruce We? athare thesht wa \n",
      "\n",
      "[0m 24s (700 7%) 2.6074]\n",
      "Whean ma tr se\n",
      "\n",
      "Be vin athighe\n",
      "S:\n",
      "\n",
      "\n",
      "I nd l y thelyof s yoothe t s be whrd gen by la uper t wo m s s ti \n",
      "\n",
      "[0m 28s (800 8%) 2.5466]\n",
      "Whait, ind d,\n",
      "ped I t ched bloutor athatct wighe onnd I siovere,\n",
      "\n",
      "Wamo nder froved the, ON ar st t w d \n",
      "\n",
      "[0m 31s (900 9%) 2.4190]\n",
      "Whare y hee O:\n",
      "H:\n",
      "Thigice feve, avestad ale opus mert asthinghimeinst, hey, grd' torifertors thin\n",
      "\n",
      "Ang \n",
      "\n",
      "[0m 35s (1000 10%) 2.5029]\n",
      "Whan, thar m.\n",
      "I che acere at f din, lor su s at! tt ldeant wior w p speas.\n",
      "Theat are yore herd fruree  \n",
      "\n",
      "[0m 38s (1100 11%) 2.4349]\n",
      "Wh as ak, d os beit her f t llit mipronde the thodn:\n",
      "VIUKES:\n",
      "INGorour avierind masthan chinors ng t t  \n",
      "\n",
      "[0m 42s (1200 12%) 2.5095]\n",
      "Whimeref fo inoun fompel asar pathite s tis.\n",
      "So he wishese ARCORY:\n",
      "Sad manarod thint the w y s heanghe \n",
      "\n",
      "[0m 45s (1300 13%) 2.5131]\n",
      "Whothe anengh brea th wido oun te my o wan tut mun ncrincer ctind foome hat:\n",
      "ISCan s t s tamaindreld t \n",
      "\n",
      "[0m 48s (1400 14%) 2.5000]\n",
      "Wh br oundel stlones thond thienoouthaveld ce,\n",
      "CA tigret s, man t keang that s shale terakhe be mon me \n",
      "\n",
      "[0m 52s (1500 15%) 2.4354]\n",
      "Wheat tishay me at thay, ceeve malon, be he.\n",
      "\n",
      "F d.\n",
      "Th, s touthe: iates:\n",
      "\n",
      "Th thoure lllle her.\n",
      "Bid tove \n",
      "\n",
      "[0m 55s (1600 16%) 2.4717]\n",
      "Whoue pes tit wanse my,\n",
      "He eallethe pe ty hondentlle the, me A: the whe,\n",
      "\n",
      "Thank, tedeitccondarit th rs \n",
      "\n",
      "[0m 58s (1700 17%) 2.6152]\n",
      "Wh be t of canderee asenouisen ad aitr te sles m!\n",
      "Thalanthas thad fo s Than ouse on,\n",
      "Honthetheainstuat \n",
      "\n",
      "[1m 2s (1800 18%) 2.5415]\n",
      "What t th, e in cor t t'lis f t foopeyon isowhourcs, fre, ad mou aceru oud th e omenthelevennoon t t h \n",
      "\n",
      "[1m 5s (1900 19%) 2.5491]\n",
      "Whe ooort tend horer'd no ce s ghe as cinde cthy chanoly t carerd burnd andend my che wind h ant hathe \n",
      "\n",
      "[1m 8s (2000 20%) 2.5542]\n",
      "Wh ous in, nough I s be heranthandigere te eenoule it toweallo t ielowond orifait y PELEEdom ar yomedo \n",
      "\n",
      "[1m 11s (2100 21%) 2.4600]\n",
      "Whesone ithit ontous hathisindenthofofle d n sand,\n",
      "And thing bly o me th seeant s:\n",
      "AY wit be out d ou  \n",
      "\n",
      "[1m 15s (2200 22%) 2.5149]\n",
      "Whas LI my,\n",
      "HAnde,\n",
      "\n",
      "INTiswanthey.\n",
      "\n",
      "Pha baso disache wr mpurestch oie maprst heas plllo n jouts.\n",
      "\n",
      "Harrd \n",
      "\n",
      "[1m 18s (2300 23%) 2.4326]\n",
      "Whe sichime le, wacou m re with f we.\n",
      "\n",
      "Wher wneavem.\n",
      "\n",
      "I thithan:\n",
      "UCHAhe by, t hen wed theth beisone o  \n",
      "\n",
      "[1m 22s (2400 24%) 2.3617]\n",
      "Whesshe\n",
      "ABUCHAr I ake ngrand es Mousheag thepe pindo cer Isomeaincas isckisth there? s hatessse t w s  \n",
      "\n",
      "[1m 25s (2500 25%) 2.5272]\n",
      "Wh ace he we swhat my bus thamod pr rst buryildeerid yomf is f pour f whirve t wh ives bir limasthimen \n",
      "\n",
      "[1m 29s (2600 26%) 2.4151]\n",
      "Whof inis s:\n",
      "Man bath ad an h winyoms athe y sorind poddel yenol'd to s faf wan pil anotir y Ancoreer  \n",
      "\n",
      "[1m 32s (2700 27%) 2.4397]\n",
      "Whame\n",
      "Wheamuthaton f yor.\n",
      "\n",
      "INIZE:\n",
      "Far they her t, touthal witr akeas hivesedind hemartheay sangour gat \n",
      "\n",
      "[1m 35s (2800 28%) 2.3969]\n",
      "Whar ards ghe' mey the bur:\n",
      "Tone wedewheared rdeal f ll tho faten t the char o be I wis\n",
      "\n",
      "You men, ly,  \n",
      "\n",
      "[1m 39s (2900 28%) 2.5123]\n",
      "Whe,\n",
      "ANou tho ome ha wo, gre, wit f gne Cis yomy coureeme ouelange allse, s w d m me wemeand be g.\n",
      "MBa \n",
      "\n",
      "[1m 42s (3000 30%) 2.4932]\n",
      "Whele h A:\n",
      "HA win f me send orore lll mes,\n",
      "\n",
      "\n",
      "MELO:\n",
      "athencor,\n",
      "Whiofe chers or nor t we crerertonfe nd w \n",
      "\n",
      "[1m 45s (3100 31%) 2.4138]\n",
      "Whore bond pe d\n",
      "Therd, se ff\n",
      "\n",
      "Wis IOLAN:\n",
      "Wis t ar d best t.\n",
      "\n",
      "OMIf g mar Ifr ws angh teacurt the irer a \n",
      "\n",
      "[1m 48s (3200 32%) 2.5464]\n",
      "Whamy ghion ike ps, byour f arind wnd br.\n",
      "AR ouerind ay wacatinealgherer, 'd the t me thas in s me all \n",
      "\n",
      "[1m 52s (3300 33%) 2.4778]\n",
      "Wh thofoutthoutriloullll pesimive hablethe thameemereake.\n",
      "\n",
      "\n",
      "Y:\n",
      "\n",
      "\n",
      "Was IZAnellalller werdiend biliocist  \n",
      "\n",
      "[1m 55s (3400 34%) 2.4466]\n",
      "Whie cilede s sstisie eno su ilave thandit, te me cof t th mo mow an thend thisonourt g oo me thicomas \n",
      "\n",
      "[1m 59s (3500 35%) 2.4648]\n",
      "Whe Yostharethe he!\n",
      "Wisiowhe bous ncethe as ove ot aake os ICoisor br vea o ne d tt the Mad or as s wo \n",
      "\n",
      "[2m 2s (3600 36%) 2.4659]\n",
      "Whe m\n",
      "\n",
      "Wit tand r!\n",
      "Bu bul bealy m nt:\n",
      "The oo?\n",
      "Tethe y mod ppe mouloribel bou whawe, s a hingo Thethese \n",
      "\n",
      "[2m 5s (3700 37%) 2.3724]\n",
      "Wheangrates throner,\n",
      "Th blien, r ve ke\n",
      "Thindithir nghand tive thinghe alaut y thedins we mer Gourd, le \n",
      "\n",
      "[2m 8s (3800 38%) 2.5516]\n",
      "Whealld cand hathaco havingr, irdiespt w norrre s, me INsisstiat t bl asion st m as, wioureinghire. tt \n",
      "\n",
      "[2m 12s (3900 39%) 2.4858]\n",
      "Whouedr?\n",
      "Y ble,\n",
      "\n",
      "Ang ind nd our idrefod.\n",
      "\n",
      "The y paveitintor thanondes w\n",
      "\n",
      "\n",
      "MIVOWelld whe wis withabe co \n",
      "\n",
      "[2m 15s (4000 40%) 2.4231]\n",
      "Wh oromatheary wnd th ce outo ainer orois erth tho th thame tous, alf blouce hes ceseratoof akerat s\n",
      "S \n",
      "\n",
      "[2m 19s (4100 41%) 2.4879]\n",
      "Wh wisof us fo the,\n",
      "Wen in grt th ar a ghidert y owerld stoucouay wo ce d, anomsthalenth t OLOLAngeat  \n",
      "\n",
      "[2m 22s (4200 42%) 2.5139]\n",
      "Whimerican the: t cepe RDe helither t\n",
      "\n",
      "Ayoungont the d tr hed mith ongoollthamand ound stthanif he ut  \n",
      "\n",
      "[2m 26s (4300 43%) 2.5544]\n",
      "Whitrathe; ploctall en aches ma ardirsikite ar.\n",
      "ABA she t hile;\n",
      "ALERCoue wontond Yous h mangor, muces  \n",
      "\n",
      "[2m 29s (4400 44%) 2.4525]\n",
      "Whef on.\n",
      "CKANENou heng ldeswoust f arany wisithe andour ne, do tain, frke fou therole y!\n",
      "\n",
      "D h d spe,-t \n",
      "\n",
      "[2m 32s (4500 45%) 2.5625]\n",
      "Whathtesuller.\n",
      "\n",
      "Whe nscof amoupad 's n, wht ber m opon t INCI murouf.\n",
      "\n",
      "To d fin't hee withee lleds whe \n",
      "\n",
      "[2m 35s (4600 46%) 2.4690]\n",
      "Whet, are at\n",
      "THithoma lyoure hiouit--d fouror.\n",
      "CEThe bay RI ak y whe t atws ter nd f ourleet Duthet fo \n",
      "\n",
      "[2m 39s (4700 47%) 2.5434]\n",
      "Whe ajoounond:\n",
      "Banot ithise athiorofflorar lithit p e he,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Yo melange hangat ayounor ke ga oulyour \n",
      "\n",
      "[2m 42s (4800 48%) 2.4391]\n",
      "Whourt wh,\n",
      "MPEN my f g.\n",
      "S:\n",
      "\n",
      "Whein ty's owis wisthe mme four thathee,\n",
      "WAndourer was be wikenallerthowan \n",
      "\n",
      "[2m 45s (4900 49%) 2.4456]\n",
      "Whimag, tosashale thelorean s or waron kere I s.\n",
      "METh t ou ind cod bechakitinod s th bre tha te bo ore \n",
      "\n",
      "[2m 49s (5000 50%) 2.4860]\n",
      "Wheme ans h langhoyon hachist memplfon merlife thil wouler higereas her ake moower\n",
      "Thes mee furery an, \n",
      "\n",
      "[2m 52s (5100 51%) 2.5886]\n",
      "Whe s hanou nd LUFor cedy cke aindiniront s cod blit mpr; s I's d ghid foe he w:\n",
      "O:\n",
      "G\n",
      "Whe owolise here \n",
      "\n",
      "[2m 56s (5200 52%) 2.3789]\n",
      "Whano outosor al anous y inccean? harerunout wieall pat at Kas nel,\n",
      "\n",
      "Thoratre sure f maincharrar, bll  \n",
      "\n",
      "[2m 59s (5300 53%) 2.4685]\n",
      "Whay s s aghe ce it e I'lowhod han ththis t y hat, s w m, rd come s Sheror k berncu yof k that gounour \n",
      "\n",
      "[3m 2s (5400 54%) 2.4195]\n",
      "Whe tu me.\n",
      "Fr o a thelouror har d ne ond\n",
      "Theapowfig y LORe whe t ul,\n",
      "S:\n",
      "Thed t y w outhee r's thowhous \n",
      "\n",
      "[3m 5s (5500 55%) 2.4260]\n",
      "Whe m me.\n",
      "\n",
      "Th he a san, ha g thersherine pe the wingong otiothithonge tond unear Roe mad my ndsu her w \n",
      "\n",
      "[3m 9s (5600 56%) 2.6025]\n",
      "Whainghave sspow gingong we ind th y see sthathavere f areckioun sty t:\n",
      "Gour sth toulller,\n",
      "Frs,\n",
      "Is an  \n",
      "\n",
      "[3m 12s (5700 56%) 2.5165]\n",
      "Whin y prd brethibar merglennoorars haxtor r whe blo wh akee rd lf theroor r;\n",
      "Tot s wirey be; ho wan o \n",
      "\n",
      "[3m 15s (5800 57%) 2.4826]\n",
      "Whessthofatheey s irer thersower thr fulavery thitatucee oullaplererieiss tat sstlf so iswarstonche, e \n",
      "\n",
      "[3m 18s (5900 59%) 2.4796]\n",
      "Whoes horitrd bl th;\n",
      "MI's atho s at n il theshaversothome ther thes winor bamerk, d derorere therroun: \n",
      "\n",
      "[3m 22s (6000 60%) 2.5171]\n",
      "Whe is ndeanetethicond d ther mu he thikeraw to tf f bllint thempepa th hey me erise fave cuer akerat  \n",
      "\n",
      "[3m 25s (6100 61%) 2.4776]\n",
      "Wheg tin wanean t it, Goie haver nd te he tarerd t th bey inousthome m mayourcaran se, y bouly d is th \n",
      "\n",
      "[3m 28s (6200 62%) 2.3555]\n",
      "Whe\n",
      "\n",
      "Whet ane go wowhe w.'sthan t Beand t ly the?\n",
      "\n",
      "Tht go no,\n",
      "Wend has an t than, nche se Wer pas ouse \n",
      "\n",
      "[3m 31s (6300 63%) 2.4914]\n",
      "Whe yourkno,\n",
      "Fothere m w histos ges wawrengat melest toatyenis hed yo silest sous tatheatheaithind tha \n",
      "\n",
      "[3m 34s (6400 64%) 2.5701]\n",
      "Whavechet suceaknobarel therulvin me ghal bly hend heprerintrathon gree be athien t thind, theart y n  \n",
      "\n",
      "[3m 37s (6500 65%) 2.5132]\n",
      "Whe be fousshar,\n",
      "Y bend.\n",
      "And we Buth m iferth.\n",
      "\n",
      "\n",
      "Wir heth, t\n",
      "WIAstatrerkanous hen d\n",
      "Narer wofo ROrespe \n",
      "\n",
      "[3m 41s (6600 66%) 2.5361]\n",
      "Whrde athem tinthe miat os sthe veal\n",
      "And wearanthes in ghien n llffon den y h scee has oup wilord fr s \n",
      "\n",
      "[3m 44s (6700 67%) 2.4381]\n",
      "Whe wind t pot,\n",
      "Touth s t miry t'thond for al ur th t ithe rerein ce phoung manon m mend ou t ant,\n",
      "STh \n",
      "\n",
      "[3m 48s (6800 68%) 2.3706]\n",
      "Whas;\n",
      "\n",
      "OMELIOLLevelesis.\n",
      "IDouso as car s ig I the owa diear s t,\n",
      "Goware h I the int s is mathouinofon  \n",
      "\n",
      "[3m 51s (6900 69%) 2.3446]\n",
      "What ftour: my.' aind's hy thon an at ad thay My busenthy d ff ged waknend beno's;\n",
      "WAn t be hen ait se \n",
      "\n",
      "[3m 55s (7000 70%) 2.4520]\n",
      "Whimers ga t merus\n",
      "Ant andeind-d RII athieans ronungll, t he re facereaitotie hachend y with\n",
      "Thy ale:\n",
      " \n",
      "\n",
      "[3m 59s (7100 71%) 2.5414]\n",
      "Whe:\n",
      "PR:\n",
      "Ce me my teshy yonste d yowoulll myono hy mere STHARICo t fastorey sh houise whys y eroushe w \n",
      "\n",
      "[4m 2s (7200 72%) 2.5658]\n",
      "Whin sheloubtherse\n",
      "CAsimalavous, ooua, anouristh t my s g e, oundacoou alt aseteay nind nor bomerotist \n",
      "\n",
      "[4m 6s (7300 73%) 2.4900]\n",
      "What fe dinghereandine bin rave y hen yorand inotreco I hant l y we t cthas.\n",
      "Yow hor llllet he\n",
      "An canu \n",
      "\n",
      "[4m 9s (7400 74%) 2.5337]\n",
      "Whis manobe cowhil s me welyoule no INou the f w.\n",
      "STINoulf t:\n",
      "\n",
      "Lo herande hese,\n",
      "I'Thits vitheressere b \n",
      "\n",
      "[4m 13s (7500 75%) 2.4175]\n",
      "Wh is cheave thear heryalou?\n",
      "\n",
      "\n",
      "NTENG g nthowe e Eddathath thee in Hed. n atoum yoton, the ay tou hesst \n",
      "\n",
      "[4m 16s (7600 76%) 2.4847]\n",
      "Whanomormand, d m wind by t arshas thengear:\n",
      "\n",
      "Toy ut st the\n",
      "T:\n",
      "\n",
      "Thulll ps.\n",
      "Bupothiret lonthore thath.\n",
      " \n",
      "\n",
      "[4m 20s (7700 77%) 2.4028]\n",
      "Whenge th mint?\n",
      "F\n",
      "\n",
      "Thand eld ionort beren s bome ie wan MOn the ome m mo ngul besle bubures d an:\n",
      "I pl \n",
      "\n",
      "[4m 23s (7800 78%) 2.3587]\n",
      "Wh ll iven t e's at, fos as t arnd INon D:\n",
      "Tourenfer his ned s sishe stouce be rm, ist be calllomake m \n",
      "\n",
      "[4m 27s (7900 79%) 2.4475]\n",
      "Whenthe g be tares lcomerange sther be he serere harthe my hitene poe sere ce ghth me t hay t, me blen \n",
      "\n",
      "[4m 31s (8000 80%) 2.4984]\n",
      "Whyou winel n amer t y myouress d tinched t holorathengh cot thar athet yo t sth hen tithay malll ware \n",
      "\n",
      "[4m 34s (8100 81%) 2.5018]\n",
      "Whind l onen, thienendeffofeam wd whaithers;\n",
      "\n",
      "Thave d, an s whithan HEEThany s thated lllles the. nnd  \n",
      "\n",
      "[4m 38s (8200 82%) 2.4742]\n",
      "Whe t ho meomy IO: we s\n",
      "Tharer leve col sowanos minew ily if the r sideertimive, lef youske ghestharsh \n",
      "\n",
      "[4m 42s (8300 83%) 2.5347]\n",
      "Whave lr g f hanow and mis pleavere gigris notitownd ICHanaicay?\n",
      "MOFokerupur mind w hicaveand hillin s \n",
      "\n",
      "[4m 46s (8400 84%) 2.4847]\n",
      "Whe?\n",
      "\n",
      "ALI thupl thereakeamin mauspugheay bar t a upis\n",
      "\n",
      "TENo wr, tho ce inourngry the n cke n INGAllele \n",
      "\n",
      "[4m 49s (8500 85%) 2.5026]\n",
      "Wh bl t owar weise ist t k,\n",
      "Anomy pl thance ore s wind wifou ppof d, ton k nond hand yshantour tho tue \n",
      "\n",
      "[4m 54s (8600 86%) 2.4492]\n",
      "Who h sthenlso be wand s mepe! butheeaprusor thed theo maloure d bo, hetat t ad s hanoul t s thelis\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "[4m 58s (8700 87%) 2.4911]\n",
      "Wheshe y t KI be t I's thice hounocrin ises CE me s tecumat, hinof arr a t berach wat.\n",
      "Thisheras thoun \n",
      "\n",
      "[5m 1s (8800 88%) 2.6075]\n",
      "Whaishane lit in ald; baina Tind t ay powouncy althalo he s t\n",
      "HAnouthen withe prothe he:\n",
      "S: ENIf illit \n",
      "\n",
      "[5m 5s (8900 89%) 2.5279]\n",
      "Whost! he fot t y we y ay al at l w t ik s;\n",
      "Her be mof.\n",
      "br, hare,\n",
      "MI in'd k weldive g at I fando d he\n",
      " \n",
      "\n",
      "[5m 9s (9000 90%) 2.4584]\n",
      "Wheand t whent terbeth in be f whalouce G ar be omou ferthe we chakeshe wourt founerey bl f oulll s le \n",
      "\n",
      "[5m 13s (9100 91%) 2.4400]\n",
      "Whe waphathat h othee t fr ste hero soong he t thesthie GBind lo hin by st tonthiowindongre barsthitho \n",
      "\n",
      "[5m 17s (9200 92%) 2.3727]\n",
      "Whim t ang'd y'd dowinour tes yousiven thatokshaswe lifotofathither thatourere wiongay,\n",
      "NDo gro\n",
      "\n",
      "The,  \n",
      "\n",
      "[5m 21s (9300 93%) 2.5244]\n",
      "Whe theds hean cow? winourtrgiores blo cormull wall ther forowe, ane ain,\n",
      "IURUS:\n",
      "\n",
      "Mus d, arowhan\n",
      "\n",
      "Tour \n",
      "\n",
      "[5m 25s (9400 94%) 2.4514]\n",
      "Whed me, tis tlll s ll y smy te! t s lond oue 'dondemeasll tte ss, myon d She lds yonor me herour'd, o \n",
      "\n",
      "[5m 29s (9500 95%) 2.4283]\n",
      "Whemarerd shandatang owarshom h oror mal Se ke ncherenoxcer ditoorer sthane wineriet y ll u uf letheep \n",
      "\n",
      "[5m 34s (9600 96%) 2.4537]\n",
      "Whe we fofou d hous ay t bono he mevere cind then the IIO:\n",
      "The ETheld he thenths wne\n",
      "TI's on ses\n",
      "Pik s \n",
      "\n",
      "[5m 38s (9700 97%) 2.4565]\n",
      "Wher e I ale ole be me hane\n",
      "dakeay cilll wopuseay thomomearthot t s keime che t he ald cuthor tu t ith \n",
      "\n",
      "[5m 42s (9800 98%) 2.4703]\n",
      "Wheandse ity ot y wid an, or and t, arn'stis t arod yo mysthe t, ' y t imyond the dis wiker t he u the \n",
      "\n",
      "[5m 46s (9900 99%) 2.6293]\n",
      "Wheoureshetesoueackin awit bancat rens won thameand as'd y heges:\n",
      "\n",
      "Wild art sswnd mepo ththerone mis w \n",
      "\n",
      "[5m 50s (10000 100%) 2.4976]\n",
      "Whe t larind for's winupur:\n",
      "INCHOu gourethar s fle.\n",
      "YOn ay wime hene chy pe be ay IOMar s tourrlanecha \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "###Parameters\n",
    "n_epochs = 10000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 256\n",
    "n_layers = 2\n",
    "lr = 0.005\n",
    "batch_size = 16\n",
    "chunk_len = 20\n",
    "\n",
    "####\n",
    "\n",
    "model = RNN(n_characters, hidden_size, n_characters, n_layers, nn.LSTM) #create model\n",
    "model_optimizer = torch.optim.Adam(model.parameters(), lr=lr) #create Adam optimizer\n",
    "criterion = nn.CrossEntropyLoss() #chose criterion\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "\n",
    "def train(inp, target):\n",
    "    \"\"\"\n",
    "    Train sequence for one chunk:\n",
    "    \"\"\"\n",
    "    #reset gradients\n",
    "    model_optimizer.zero_grad() \n",
    "    \n",
    "    # predict output\n",
    "    output = model(inp)\n",
    "    \n",
    "    #compute loss\n",
    "    loss = criterion(output.view(batch_size*chunk_len,-1), target.view(-1)) \n",
    "\n",
    "    #compute gradients and backpropagate\n",
    "    loss.backward() \n",
    "    model_optimizer.step() \n",
    "\n",
    "    return loss.data.item() \n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(*random_training_set(chunk_len,batch_size))  #train on one chunk \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "        print(generate(model,'Wh', 100), '\\n')\n",
    "       \n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different temperatures\n",
    "\n",
    "Changing the distribution sharpness has an impact on character sampling:\n",
    "\n",
    "more or less probable things are sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tho'st:\n",
      "Ceds thaisthath withel e ad-wo'sowour ous; weryooret t.\n",
      "OMonge doul te ncthild the, thinds KEMalo h ake, sear MIS:\n",
      "Meayrdanen ondshe, f,\n",
      "Bsiow!\n",
      "\n",
      "RI poncercilfougor ad y ath by l talftheram tome\n",
      "----\n",
      "Thire t arlffun towa an o fl athatt ghey sthin pas withe? tofower touliliose be thathe ar,\n",
      "We othes brougher ilde f po nd's,\n",
      "WAsthes wil he mamanery y lldutha ola d s\n",
      "Anor f hy was.\n",
      "Yourgoy spe igen pim\n",
      "----\n",
      "The the I ind athand the athe Ise t ss t ar the s ter y the whe t therire ther parthe s s thathe knd the n we ce whe ave he the dis the I ay t the he wor cer t thee t t ar the bous wnd ar s be wime was \n",
      "----\n",
      "The the the than t and t y the the the w, the be the an the the t the there t wind the s the ard tourd the the f the be thand we ar thanour s the t the the t t be the the wand the the the the tho we the\n",
      "----\n",
      "The the the the the the the the the t the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the and the the the the the the the the \n"
     ]
    }
   ],
   "source": [
    "print(generate(model,'T', 200, temperature=1))\n",
    "print(\"----\")\n",
    "print(generate(model,'Th', 200, temperature=0.8))\n",
    "print(\"----\")\n",
    "print(generate(model,'Th', 200, temperature=0.5))\n",
    "print(\"----\")\n",
    "print(generate(model,'Th', 200, temperature=0.3))\n",
    "print(\"----\")\n",
    "print(generate(model,'Th', 200, temperature=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving this code:\n",
    "\n",
    "(a) Tinker with parameters:\n",
    "\n",
    "- Is it really necessary to have 100 dims character embeddings\n",
    "- Chunk length can be gradually increased\n",
    "- Try changing RNN cell type (GRUs - LSTMs)\n",
    "\n",
    "(b) Add GPU support to go faster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------ End of practical\n",
    "\n",
    "#### Legacy loading code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# from os.path import split as pathsplit\n",
    "\n",
    "# dir_train = \"data/aclImdb/train/\"\n",
    "# dir_test = \"data/aclImdb/test/\"\n",
    "\n",
    "# train_files = glob.glob(dir_train+'pos/*.txt') + glob.glob(dir_train+'neg/*.txt')\n",
    "# test_files = glob.glob(dir_test+'pos/*.txt') + glob.glob(dir_test+'neg/*.txt')\n",
    "\n",
    "\n",
    "# def get_polarity(f):\n",
    "#     \"\"\"\n",
    "#     Extracts polarity from filename:\n",
    "#     0 is negative (< 5)\n",
    "#     1 is positive (> 5)\n",
    "#     \"\"\"\n",
    "#     _,name = pathsplit(f)\n",
    "#     if int(name.split('_')[1].split('.')[0]) < 5:\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return 1\n",
    "\n",
    "\n",
    "# def open_one(f):\n",
    "    \n",
    "#     polarity = get_polarity(f)\n",
    "    \n",
    "#     with open(f,\"r\") as review:\n",
    "#         text = \" \".join(review.readlines()).strip()\n",
    "    \n",
    "#     return (text,polarity)\n",
    "\n",
    "# print(open_one(train_files[0]))\n",
    "\n",
    "# train = [open_one(x) for x in train_files] #contains (text,pol) couples\n",
    "# test = [open_one(x) for x in test_files]   #contains (text,pol) couples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
